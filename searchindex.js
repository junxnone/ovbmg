Search.setIndex({"docnames": ["about-openvino", "about-openvino/additional-resources", "about-openvino/additional-resources/glossary", "about-openvino/additional-resources/legal-information", "about-openvino/additional-resources/telemetry", "about-openvino/compatibility-and-support", "about-openvino/compatibility-and-support/supported-devices", "about-openvino/compatibility-and-support/supported-operations-framework-frontend", "about-openvino/compatibility-and-support/supported-operations-inference-devices", "about-openvino/performance-benchmarks", "about-openvino/performance-benchmarks/getting-performance-numbers", "about-openvino/performance-benchmarks/model-accuracy-int8-fp32", "about-openvino/performance-benchmarks/performance-benchmarks-faq", "about-openvino/release-notes-openvino", "about-openvino/release-notes-openvino/release-policy", "about-openvino/release-notes-openvino/system-requirements", "api/api_reference", "api/ie_python_api/_autosummary/openvino", "api/ie_python_api/_autosummary/openvino.frontend", "api/ie_python_api/_autosummary/openvino.preprocess", "api/ie_python_api/_autosummary/openvino.properties", "api/ie_python_api/_autosummary/openvino.properties.device", "api/ie_python_api/_autosummary/openvino.properties.hint", "api/ie_python_api/_autosummary/openvino.properties.intel_auto", "api/ie_python_api/_autosummary/openvino.properties.intel_cpu", "api/ie_python_api/_autosummary/openvino.properties.intel_gpu", "api/ie_python_api/_autosummary/openvino.properties.intel_gpu.hint", "api/ie_python_api/_autosummary/openvino.properties.log", "api/ie_python_api/_autosummary/openvino.properties.streams", "api/ie_python_api/_autosummary/openvino.runtime", "api/ie_python_api/_autosummary/openvino.runtime.op", "api/ie_python_api/_autosummary/openvino.runtime.op.util", "api/ie_python_api/_autosummary/openvino.runtime.opset1", "api/ie_python_api/_autosummary/openvino.runtime.opset10", "api/ie_python_api/_autosummary/openvino.runtime.opset11", "api/ie_python_api/_autosummary/openvino.runtime.opset12", "api/ie_python_api/_autosummary/openvino.runtime.opset13", "api/ie_python_api/_autosummary/openvino.runtime.opset14", "api/ie_python_api/_autosummary/openvino.runtime.opset2", "api/ie_python_api/_autosummary/openvino.runtime.opset3", "api/ie_python_api/_autosummary/openvino.runtime.opset4", "api/ie_python_api/_autosummary/openvino.runtime.opset5", "api/ie_python_api/_autosummary/openvino.runtime.opset6", "api/ie_python_api/_autosummary/openvino.runtime.opset7", "api/ie_python_api/_autosummary/openvino.runtime.opset8", "api/ie_python_api/_autosummary/openvino.runtime.opset9", "api/ie_python_api/_autosummary/openvino.runtime.passes", "api/ie_python_api/api", "api/nodejs_api/addon", "api/nodejs_api/nodejs_api", "api/nodejs_api/openvino-node/enums/element", "api/nodejs_api/openvino-node/enums/resizeAlgorithm", "api/nodejs_api/openvino-node/interfaces/CompiledModel", "api/nodejs_api/openvino-node/interfaces/Core", "api/nodejs_api/openvino-node/interfaces/CoreConstructor", "api/nodejs_api/openvino-node/interfaces/InferRequest", "api/nodejs_api/openvino-node/interfaces/InputInfo", "api/nodejs_api/openvino-node/interfaces/InputModelInfo", "api/nodejs_api/openvino-node/interfaces/InputTensorInfo", "api/nodejs_api/openvino-node/interfaces/Model", "api/nodejs_api/openvino-node/interfaces/Output", "api/nodejs_api/openvino-node/interfaces/OutputInfo", "api/nodejs_api/openvino-node/interfaces/OutputTensorInfo", "api/nodejs_api/openvino-node/interfaces/PartialShape", "api/nodejs_api/openvino-node/interfaces/PartialShapeConstructor", "api/nodejs_api/openvino-node/interfaces/PrePostProcessor", "api/nodejs_api/openvino-node/interfaces/PrePostProcessorConstructor", "api/nodejs_api/openvino-node/interfaces/PreProcessSteps", "api/nodejs_api/openvino-node/interfaces/Tensor", "api/nodejs_api/openvino-node/interfaces/TensorConstructor", "api/nodejs_api/openvino-node/types/Dimension", "api/nodejs_api/openvino-node/types/SupportedTypedArray", "api/nodejs_api/openvino-node/types/elementTypeString", "documentation", "documentation/legacy-features", "documentation/legacy-features/install-dev-tools", "documentation/legacy-features/model-zoo", "documentation/legacy-features/transition-legacy-conversion-api", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-compressing-model-to-fp16", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-convert-models-as-python-objects", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-cutting-parts-of-a-model", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-embedding-preprocessing-computation", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-model-optimizer-faq", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-setting-input-shapes", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-onnx-faster-r-cnn", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-onnx-gpt-2", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-onnx-mask-r-cnn", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-bert-ner", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-cascade-rcnn-r-101", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-f3-net", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-quartz-net", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-rcan", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-rnn-t", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-yolact", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-attention-ocr", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-bert", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-crnn", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-deep-speech", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-efficient-det", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-face-net", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-gnmt", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-language-1b", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-ncf", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-object-detection", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-retina-net", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-slim-library", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-wide-and-deep-family", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-xlnet", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-yolo", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-onnx", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-paddle", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-pytorch", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-tensorflow", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-tensorflow-lite", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-troubleshooting-reshape-errors", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-extending-model-optimizer-with-caffe-python-layers", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-graph-traversal-and-modification", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-model-optimizer-extensions", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-model-optimizer-extensions/[legacy]-graph-transformation-extensions", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-model-optimizer-extensions/[legacy]-model-optimizer-operation", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-model-optimizer-extensions/[legacy]-optimizer-extractor", "documentation/openvino-ecosystem", "documentation/openvino-ecosystem/datumaro", "documentation/openvino-ecosystem/openvino-security-add-on", "documentation/openvino-ecosystem/openvino-training-extensions", "documentation/openvino-extensibility", "documentation/openvino-extensibility/custom-gpu-operations", "documentation/openvino-extensibility/custom-openvino-operations", "documentation/openvino-extensibility/frontend-extensions", "documentation/openvino-extensibility/openvino-plugin-library", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/avg-pool-precision-preserved", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/intervals-alignment", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/precision-preserved", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/precisions", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/quantization-alignment", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/quantization-granularity", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites/convert-subtract-constant", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites/lin-op-sequence-fusion", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites/pull-reshape-through-dequantization", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites/pull-transpose-through-dequantization", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/align-quantization-intervals", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/align-quantization-parameters", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/create-attribute", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/create-precisions-dependent-attribute", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-avg-pool-precision-preserved", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-bias", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-can-be-quantized", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-per-tensor-quantization", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-precisions", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/propagate-precisions", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/propagate-shared-value", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/propagate-through-precision-preserved", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/propagate-to-input", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/update-shared-precision-preserved", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/activation/clamp", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/activation/prelu", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/activation/relu", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/arithmetic/add", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/arithmetic/multiply", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/arithmetic/multiply-partial", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/arithmetic/subtract", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/convolution/convolution", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/convolution/convolution-backprop-data", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/convolution/group-convolution", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/image/interpolate", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/matrix/mat-mul", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/concat", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/depth-to-space", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/gather", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/pad", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/shuffle-channels", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/split", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/strided-slice", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/transpose", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/variadic-split", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/normalization/mvn", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/normalization/normalize-l2", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/pooling/avg-pool", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/pooling/max-pool", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/quantization/fake-quantize", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/quantization/fold-fake-quantize", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/reduction/reduce-max", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/reduction/reduce-mean", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/reduction/reduce-min", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/reduction/reduce-sum", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/batch-to-space", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/reshape", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/space-to-batch", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/squeeze", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/unsqueeze", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/eliminate-fake-quantize", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fake-quantize-decomposition", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fold-convert", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fuse-convert", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fuse-multiply-to-fake-quantize", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fuse-subtract-to-fake-quantize", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/multiply-to-group-convolution", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/quantized-models", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/quantized-models/low-precision-model-representation", "documentation/openvino-extensibility/openvino-plugin-library/asynch-inference-request", "documentation/openvino-extensibility/openvino-plugin-library/build-plugin-using-cmake", "documentation/openvino-extensibility/openvino-plugin-library/compiled-model", "documentation/openvino-extensibility/openvino-plugin-library/plugin", "documentation/openvino-extensibility/openvino-plugin-library/plugin-api-references", "documentation/openvino-extensibility/openvino-plugin-library/plugin-properties", "documentation/openvino-extensibility/openvino-plugin-library/plugin-testing", "documentation/openvino-extensibility/openvino-plugin-library/remote-context", "documentation/openvino-extensibility/openvino-plugin-library/remote-tensor", "documentation/openvino-extensibility/openvino-plugin-library/synch-inference-request", "documentation/openvino-extensibility/transformation-api", "documentation/openvino-extensibility/transformation-api/graph-rewrite-pass", "documentation/openvino-extensibility/transformation-api/matcher-pass", "documentation/openvino-extensibility/transformation-api/model-pass", "documentation/openvino-ir-format", "documentation/openvino-ir-format/intermediate-representation-int8-inference", "documentation/openvino-ir-format/operation-sets", "documentation/openvino-ir-format/operation-sets/available-opsets", "documentation/openvino-ir-format/operation-sets/available-opsets/opset1", "documentation/openvino-ir-format/operation-sets/available-opsets/opset10", "documentation/openvino-ir-format/operation-sets/available-opsets/opset11", "documentation/openvino-ir-format/operation-sets/available-opsets/opset12", "documentation/openvino-ir-format/operation-sets/available-opsets/opset13", "documentation/openvino-ir-format/operation-sets/available-opsets/opset14", "documentation/openvino-ir-format/operation-sets/available-opsets/opset2", "documentation/openvino-ir-format/operation-sets/available-opsets/opset3", "documentation/openvino-ir-format/operation-sets/available-opsets/opset4", "documentation/openvino-ir-format/operation-sets/available-opsets/opset5", "documentation/openvino-ir-format/operation-sets/available-opsets/opset6", "documentation/openvino-ir-format/operation-sets/available-opsets/opset7", "documentation/openvino-ir-format/operation-sets/available-opsets/opset8", "documentation/openvino-ir-format/operation-sets/available-opsets/opset9", "documentation/openvino-ir-format/operation-sets/broadcast-rules", "documentation/openvino-ir-format/operation-sets/operation-specs", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/clamp-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/elu-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/exp-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/gelu-2", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/gelu-7", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/hard-sigmoid-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/hsigmoid-5", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/hswish-4", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/log-soft-max-5", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/mish-4", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/prelu-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/relu-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/selu-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/sigmoid-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/softmax-1", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/softmax-8", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/softplus-4", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/softsign-9", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/swish-4", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/abs-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/acos-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/acosh-3", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/add-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/asin-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/asinh-3", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/atan-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/atanh-3", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/ceiling-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/cos-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/cosh-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/cumsum-3", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/divide-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/erf-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/floor-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/floormod-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/log-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/maximum-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/minimum-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/mod-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/multiply-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/negative-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/power-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/round-5", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/sign-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/sin-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/sinh-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/sqrt-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/squared-difference-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/subtract-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/tan-1", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/tanh-1", "documentation/openvino-ir-format/operation-sets/operation-specs/bitwise/bitwise-and-13", "documentation/openvino-ir-format/operation-sets/operation-specs/bitwise/bitwise-not-13", "documentation/openvino-ir-format/operation-sets/operation-specs/bitwise/bitwise-or-13", "documentation/openvino-ir-format/operation-sets/operation-specs/bitwise/bitwise-xor-13", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/equal-1", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/greater-1", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/greater-equal-1", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/isfinite-10", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/isinf-10", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/isnan-10", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/less-1", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/lessequal-1", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/notequal-1", "documentation/openvino-ir-format/operation-sets/operation-specs/condition/bucketize-3", "documentation/openvino-ir-format/operation-sets/operation-specs/condition/if-8", "documentation/openvino-ir-format/operation-sets/operation-specs/condition/nonzero-3", "documentation/openvino-ir-format/operation-sets/operation-specs/condition/select-1", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/binary-convolution-1", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/convolution-1", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/convolution-backprop-data-1", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/deformable-convolution-1", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/deformable-convolution-8", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/group-convolution-1", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/group-convolution-backprop-data-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/deformable-psroi-pooling-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/detectionoutput-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/detectionoutput-8", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/experimental-detectron-detection-output-6", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/experimental-detectron-generate-proposals-single-image-6", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/experimental-detectron-prior-grid-generator-6", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/experimental-detectron-roi-feature-extractor-6", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/generate-proposals-9", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/prior-box-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/prior-box-8", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/prior-box-clustered-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/proposal-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/proposal-4", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/psroi-pooling-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/region-yolo-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/reorg-yolo-1", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/roi-align-3", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/roi-align-9", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/roi-align-rotated-14", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/roi-pooling-1", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/eye-9", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/multinomial-13", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/random-uniform-8", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/range-1", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/range-4", "documentation/openvino-ir-format/operation-sets/operation-specs/image/grid-sample-9", "documentation/openvino-ir-format/operation-sets/operation-specs/image/i420-to-bgr-8", "documentation/openvino-ir-format/operation-sets/operation-specs/image/i420-to-rgb-8", "documentation/openvino-ir-format/operation-sets/operation-specs/image/interpolate-1", "documentation/openvino-ir-format/operation-sets/operation-specs/image/interpolate-11", "documentation/openvino-ir-format/operation-sets/operation-specs/image/interpolate-4", "documentation/openvino-ir-format/operation-sets/operation-specs/image/nv12-to-bgr-8", "documentation/openvino-ir-format/operation-sets/operation-specs/image/nv12-to-rgb-8", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/assign-3", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/assign-6", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/constant-1", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/loop-5", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/parameter-1", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/read-value-3", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/read-value-6", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/result-1", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/tensor-iterator-1", "documentation/openvino-ir-format/operation-sets/operation-specs/internal/augru-cell", "documentation/openvino-ir-format/operation-sets/operation-specs/internal/augru-sequence", "documentation/openvino-ir-format/operation-sets/operation-specs/logical/logical-and-1", "documentation/openvino-ir-format/operation-sets/operation-specs/logical/logical-not-1", "documentation/openvino-ir-format/operation-sets/operation-specs/logical/logical-or-1", "documentation/openvino-ir-format/operation-sets/operation-specs/logical/logical-xor-1", "documentation/openvino-ir-format/operation-sets/operation-specs/matrix/einsum-7", "documentation/openvino-ir-format/operation-sets/operation-specs/matrix/inverse-14", "documentation/openvino-ir-format/operation-sets/operation-specs/matrix/matmul-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/batch-to-space-2", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/broadcast-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/broadcast-3", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/concat-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/depth-to-space-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/extract-image-patches-3", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-7", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-8", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-elements-6", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-nd-5", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-nd-8", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-tree-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/pad-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/pad-12", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/reverse-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/reverse-sequence-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/roll-7", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-elements-update-12", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-elements-update-3", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-nd-update-15", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-nd-update-3", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-update-3", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/shuffle-channels-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/slice-8", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/space-to-batch-2", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/space-to-depth-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/split-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/strided-slice-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/tile-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/transpose-1", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/unique-10", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/variadic-split-1", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/batch-norm-inference-1", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/batch-norm-inference-5", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/grn-1", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/group-normalization-12", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/lrn-1", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/mvn-1", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/mvn-6", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/normalize-l2-1", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/adaptive-avg-pool-8", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/adaptive-max-pool-8", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/avg-pool-1", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/avg-pool-14", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/max-pool-1", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/max-pool-14", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/max-pool-8", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/pooling_shape_rules", "documentation/openvino-ir-format/operation-sets/operation-specs/quantization/fake-convert-13", "documentation/openvino-ir-format/operation-sets/operation-specs/quantization/fake-quantize-1", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-l1-4", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-l2-4", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-logical-and-1", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-logical-or-1", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-max-1", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-mean-1", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-min-1", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-prod-1", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-sum-1", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/ctc-greedy-decoder-1", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/ctc-greedy-decoder-seq-len-6", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/ctc-loss-4", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/gru-cell-3", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/gru-sequence-5", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/lstm-cell-1", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/lstm-sequence-1", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/one-hot-1", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/rnn-cell-3", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/rnn-sequence-5", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/scaled-dot-product-attention", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/reshape-1", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/shape-of-1", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/shape-of-3", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/squeeze-1", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/unsqueeze-1", "documentation/openvino-ir-format/operation-sets/operation-specs/signals/dft-7", "documentation/openvino-ir-format/operation-sets/operation-specs/signals/idft-7", "documentation/openvino-ir-format/operation-sets/operation-specs/signals/irdft-9", "documentation/openvino-ir-format/operation-sets/operation-specs/signals/rdft-9", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/experimental-detectron-top-krois-6", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/matrix-non-max-suppression-8", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/multiclass-non-max-suppression-8", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/multiclass-non-max-suppression-9", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/nms-rotated-13", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/no-max-suppression-5", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/non-max-suppression-1", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/non-max-suppression-3", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/non-max-suppression-4", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/non-max-suppression-9", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/top-k-1", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/top-k-11", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/top-k-3", "documentation/openvino-ir-format/operation-sets/operation-specs/sparse/embedding-bag-offsets-sum-3", "documentation/openvino-ir-format/operation-sets/operation-specs/sparse/embedding-bag-packed-sum-3", "documentation/openvino-ir-format/operation-sets/operation-specs/sparse/embedding-segments-sum-3", "documentation/openvino-ir-format/operation-sets/operation-specs/type/convert-1", "documentation/openvino-ir-format/operation-sets/operation-specs/type/convert-like-1", "documentation/openvino-ir-format/operation-sets/operation-specs/type/convert-promote-types-14", "documentation/openvino-security", "documentation/openvino-security/openvino-encrypted-models", "get-started", "get-started/configurations", "get-started/configurations/configurations-intel-gpu", "get-started/configurations/configurations-intel-npu", "get-started/install-openvino", "get-started/install-openvino/install-openvino-apt", "get-started/install-openvino/install-openvino-archive-linux", "get-started/install-openvino/install-openvino-archive-macos", "get-started/install-openvino/install-openvino-archive-windows", "get-started/install-openvino/install-openvino-brew", "get-started/install-openvino/install-openvino-conan", "get-started/install-openvino/install-openvino-conda", "get-started/install-openvino/install-openvino-docker-linux", "get-started/install-openvino/install-openvino-linux", "get-started/install-openvino/install-openvino-macos", "get-started/install-openvino/install-openvino-npm", "get-started/install-openvino/install-openvino-pip", "get-started/install-openvino/install-openvino-vcpkg", "get-started/install-openvino/install-openvino-windows", "get-started/install-openvino/install-openvino-yum", "get-started/install-openvino/install-openvino-zypper", "get-started/troubleshooting-install-config", "index", "learn-openvino", "learn-openvino/interactive-tutorials-python", "learn-openvino/interactive-tutorials-python/notebooks-installation", "learn-openvino/llm_inference_guide", "learn-openvino/llm_inference_guide/llm-inference-hf", "learn-openvino/llm_inference_guide/llm-inference-native-ov", "learn-openvino/llm_inference_guide/ov-tokenizers", "learn-openvino/openvino-samples", "learn-openvino/openvino-samples/benchmark-tool", "learn-openvino/openvino-samples/bert-benchmark", "learn-openvino/openvino-samples/get-started-demos", "learn-openvino/openvino-samples/hello-classification", "learn-openvino/openvino-samples/hello-nv12-input-classification", "learn-openvino/openvino-samples/hello-query-device", "learn-openvino/openvino-samples/hello-reshape-ssd", "learn-openvino/openvino-samples/image-classification-async", "learn-openvino/openvino-samples/model-creation", "learn-openvino/openvino-samples/sync-benchmark", "learn-openvino/openvino-samples/throughput-benchmark", "openvino-workflow", "openvino-workflow/deployment-locally", "openvino-workflow/deployment-locally/local-distribution-libraries", "openvino-workflow/deployment-locally/optimial-binary-size-conditional-compilation", "openvino-workflow/model-optimization", "openvino-workflow/model-optimization-guide/compressing-models-during-training", "openvino-workflow/model-optimization-guide/compressing-models-during-training/filter-pruning", "openvino-workflow/model-optimization-guide/compressing-models-during-training/quantization-aware-training", "openvino-workflow/model-optimization-guide/quantizing-models-post-training", "openvino-workflow/model-optimization-guide/quantizing-models-post-training/basic-quantization-flow", "openvino-workflow/model-optimization-guide/quantizing-models-post-training/quantizing-with-accuracy-control", "openvino-workflow/model-optimization-guide/weight-compression", "openvino-workflow/model-preparation", "openvino-workflow/model-preparation/conversion-parameters", "openvino-workflow/model-preparation/convert-model-onnx", "openvino-workflow/model-preparation/convert-model-paddle", "openvino-workflow/model-preparation/convert-model-pytorch", "openvino-workflow/model-preparation/convert-model-tensorflow", "openvino-workflow/model-preparation/convert-model-tensorflow-lite", "openvino-workflow/model-preparation/convert-model-to-ir", "openvino-workflow/model-preparation/setting-input-shapes", "openvino-workflow/running-inference", "openvino-workflow/running-inference/changing-input-shape", "openvino-workflow/running-inference/dynamic-shapes", "openvino-workflow/running-inference/dynamic-shapes/openvino-without-dynamic-shapes-api", "openvino-workflow/running-inference/inference-devices-and-modes", "openvino-workflow/running-inference/inference-devices-and-modes/auto-device-selection", "openvino-workflow/running-inference/inference-devices-and-modes/auto-device-selection/debugging-auto-device", "openvino-workflow/running-inference/inference-devices-and-modes/automatic-batching", "openvino-workflow/running-inference/inference-devices-and-modes/cpu-device", "openvino-workflow/running-inference/inference-devices-and-modes/gpu-device", "openvino-workflow/running-inference/inference-devices-and-modes/gpu-device/remote-tensor-api-gpu-plugin", "openvino-workflow/running-inference/inference-devices-and-modes/hetero-execution", "openvino-workflow/running-inference/inference-devices-and-modes/multi-device", "openvino-workflow/running-inference/inference-devices-and-modes/npu-device", "openvino-workflow/running-inference/inference-devices-and-modes/query-device-properties", "openvino-workflow/running-inference/integrate-openvino-with-your-application", "openvino-workflow/running-inference/integrate-openvino-with-your-application/inference-request", "openvino-workflow/running-inference/integrate-openvino-with-your-application/model-representation", "openvino-workflow/running-inference/integrate-openvino-with-your-application/python-api-advanced-inference", "openvino-workflow/running-inference/integrate-openvino-with-your-application/python-api-exclusives", "openvino-workflow/running-inference/optimize-inference", "openvino-workflow/running-inference/optimize-inference/general-optimizations", "openvino-workflow/running-inference/optimize-inference/high-level-performance-hints", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing/integrate-save-preprocessing-use-case", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing/layout-api-overview", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing/preprocessing-api-details", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing/torchvision-preprocessing-converter", "openvino-workflow/running-inference/optimize-inference/optimizing-latency", "openvino-workflow/running-inference/optimize-inference/optimizing-latency/model-caching-overview", "openvino-workflow/running-inference/optimize-inference/optimizing-low-level-implementation", "openvino-workflow/running-inference/optimize-inference/optimizing-memory-usage", "openvino-workflow/running-inference/optimize-inference/optimizing-throughput", "openvino-workflow/running-inference/optimize-inference/optimizing-throughput/advanced_throughput_options", "openvino-workflow/running-inference/optimize-inference/precision-control", "openvino-workflow/running-inference/stateful-models", "openvino-workflow/running-inference/stateful-models/obtaining-stateful-openvino-model", "openvino-workflow/running-inference/string-tensors", "openvino-workflow/torch-compile"], "filenames": ["about-openvino.rst", "about-openvino/additional-resources.rst", "about-openvino/additional-resources/glossary.rst", "about-openvino/additional-resources/legal-information.rst", "about-openvino/additional-resources/telemetry.rst", "about-openvino/compatibility-and-support.rst", "about-openvino/compatibility-and-support/supported-devices.rst", "about-openvino/compatibility-and-support/supported-operations-framework-frontend.rst", "about-openvino/compatibility-and-support/supported-operations-inference-devices.rst", "about-openvino/performance-benchmarks.rst", "about-openvino/performance-benchmarks/getting-performance-numbers.rst", "about-openvino/performance-benchmarks/model-accuracy-int8-fp32.rst", "about-openvino/performance-benchmarks/performance-benchmarks-faq.rst", "about-openvino/release-notes-openvino.rst", "about-openvino/release-notes-openvino/release-policy.rst", "about-openvino/release-notes-openvino/system-requirements.rst", "api/api_reference.rst", "api/ie_python_api/_autosummary/openvino.rst", "api/ie_python_api/_autosummary/openvino.frontend.rst", "api/ie_python_api/_autosummary/openvino.preprocess.rst", "api/ie_python_api/_autosummary/openvino.properties.rst", "api/ie_python_api/_autosummary/openvino.properties.device.rst", "api/ie_python_api/_autosummary/openvino.properties.hint.rst", "api/ie_python_api/_autosummary/openvino.properties.intel_auto.rst", "api/ie_python_api/_autosummary/openvino.properties.intel_cpu.rst", "api/ie_python_api/_autosummary/openvino.properties.intel_gpu.rst", "api/ie_python_api/_autosummary/openvino.properties.intel_gpu.hint.rst", "api/ie_python_api/_autosummary/openvino.properties.log.rst", "api/ie_python_api/_autosummary/openvino.properties.streams.rst", "api/ie_python_api/_autosummary/openvino.runtime.rst", "api/ie_python_api/_autosummary/openvino.runtime.op.rst", "api/ie_python_api/_autosummary/openvino.runtime.op.util.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset1.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset10.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset11.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset12.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset13.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset14.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset2.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset3.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset4.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset5.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset6.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset7.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset8.rst", "api/ie_python_api/_autosummary/openvino.runtime.opset9.rst", "api/ie_python_api/_autosummary/openvino.runtime.passes.rst", "api/ie_python_api/api.rst", "api/nodejs_api/addon.rst", "api/nodejs_api/nodejs_api.rst", "api/nodejs_api/openvino-node/enums/element.rst", "api/nodejs_api/openvino-node/enums/resizeAlgorithm.rst", "api/nodejs_api/openvino-node/interfaces/CompiledModel.rst", "api/nodejs_api/openvino-node/interfaces/Core.rst", "api/nodejs_api/openvino-node/interfaces/CoreConstructor.rst", "api/nodejs_api/openvino-node/interfaces/InferRequest.rst", "api/nodejs_api/openvino-node/interfaces/InputInfo.rst", "api/nodejs_api/openvino-node/interfaces/InputModelInfo.rst", "api/nodejs_api/openvino-node/interfaces/InputTensorInfo.rst", "api/nodejs_api/openvino-node/interfaces/Model.rst", "api/nodejs_api/openvino-node/interfaces/Output.rst", "api/nodejs_api/openvino-node/interfaces/OutputInfo.rst", "api/nodejs_api/openvino-node/interfaces/OutputTensorInfo.rst", "api/nodejs_api/openvino-node/interfaces/PartialShape.rst", "api/nodejs_api/openvino-node/interfaces/PartialShapeConstructor.rst", "api/nodejs_api/openvino-node/interfaces/PrePostProcessor.rst", "api/nodejs_api/openvino-node/interfaces/PrePostProcessorConstructor.rst", "api/nodejs_api/openvino-node/interfaces/PreProcessSteps.rst", "api/nodejs_api/openvino-node/interfaces/Tensor.rst", "api/nodejs_api/openvino-node/interfaces/TensorConstructor.rst", "api/nodejs_api/openvino-node/types/Dimension.rst", "api/nodejs_api/openvino-node/types/SupportedTypedArray.rst", "api/nodejs_api/openvino-node/types/elementTypeString.rst", "documentation.rst", "documentation/legacy-features.rst", "documentation/legacy-features/install-dev-tools.rst", "documentation/legacy-features/model-zoo.rst", "documentation/legacy-features/transition-legacy-conversion-api.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-compressing-model-to-fp16.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-convert-models-as-python-objects.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-cutting-parts-of-a-model.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-embedding-preprocessing-computation.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-model-optimizer-faq.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-setting-input-shapes.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-onnx-faster-r-cnn.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-onnx-gpt-2.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-onnx-mask-r-cnn.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-bert-ner.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-cascade-rcnn-r-101.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-f3-net.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-quartz-net.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-rcan.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-rnn-t.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-pytorch-yolact.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-attention-ocr.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-bert.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-crnn.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-deep-speech.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-efficient-det.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-face-net.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-gnmt.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-language-1b.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-ncf.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-object-detection.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-retina-net.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-slim-library.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-wide-and-deep-family.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-xlnet.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-conversion-tutorials/convert-tensorflow-yolo.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-onnx.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-paddle.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-pytorch.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-tensorflow.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-supported-model-formats/[legacy]-convert-tensorflow-lite.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-conversion-api/[legacy]-troubleshooting-reshape-errors.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-extending-model-optimizer-with-caffe-python-layers.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-graph-traversal-and-modification.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-model-optimizer-extensions.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-model-optimizer-extensions/[legacy]-graph-transformation-extensions.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-model-optimizer-extensions/[legacy]-model-optimizer-operation.rst", "documentation/legacy-features/transition-legacy-conversion-api/legacy-model-optimizer-extensibility/[legacy]-model-optimizer-extensions/[legacy]-optimizer-extractor.rst", "documentation/openvino-ecosystem.rst", "documentation/openvino-ecosystem/datumaro.rst", "documentation/openvino-ecosystem/openvino-security-add-on.rst", "documentation/openvino-ecosystem/openvino-training-extensions.rst", "documentation/openvino-extensibility.rst", "documentation/openvino-extensibility/custom-gpu-operations.rst", "documentation/openvino-extensibility/custom-openvino-operations.rst", "documentation/openvino-extensibility/frontend-extensions.rst", "documentation/openvino-extensibility/openvino-plugin-library.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/avg-pool-precision-preserved.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/intervals-alignment.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/precision-preserved.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/precisions.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/quantization-alignment.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/lpt-attributes/quantization-granularity.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites/convert-subtract-constant.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites/lin-op-sequence-fusion.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites/pull-reshape-through-dequantization.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step1-prerequisites/pull-transpose-through-dequantization.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/align-quantization-intervals.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/align-quantization-parameters.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/create-attribute.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/create-precisions-dependent-attribute.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-avg-pool-precision-preserved.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-bias.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-can-be-quantized.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-per-tensor-quantization.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/markup-precisions.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/propagate-precisions.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/propagate-shared-value.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/propagate-through-precision-preserved.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/propagate-to-input.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step2-markup/update-shared-precision-preserved.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/activation/clamp.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/activation/prelu.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/activation/relu.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/arithmetic/add.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/arithmetic/multiply.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/arithmetic/multiply-partial.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/arithmetic/subtract.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/convolution/convolution.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/convolution/convolution-backprop-data.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/convolution/group-convolution.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/image/interpolate.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/matrix/mat-mul.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/concat.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/depth-to-space.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/gather.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/pad.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/shuffle-channels.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/split.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/strided-slice.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/transpose.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/movement/variadic-split.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/normalization/mvn.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/normalization/normalize-l2.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/pooling/avg-pool.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/pooling/max-pool.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/quantization/fake-quantize.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/quantization/fold-fake-quantize.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/reduction/reduce-max.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/reduction/reduce-mean.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/reduction/reduce-min.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/reduction/reduce-sum.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/batch-to-space.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/reshape.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/space-to-batch.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/squeeze.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step3-main/shape/unsqueeze.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/eliminate-fake-quantize.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fake-quantize-decomposition.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fold-convert.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fuse-convert.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fuse-multiply-to-fake-quantize.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/fuse-subtract-to-fake-quantize.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/low-precision-transformations/step4-cleanup/multiply-to-group-convolution.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/quantized-models.rst", "documentation/openvino-extensibility/openvino-plugin-library/advanced-guides/quantized-models/low-precision-model-representation.rst", "documentation/openvino-extensibility/openvino-plugin-library/asynch-inference-request.rst", "documentation/openvino-extensibility/openvino-plugin-library/build-plugin-using-cmake.rst", "documentation/openvino-extensibility/openvino-plugin-library/compiled-model.rst", "documentation/openvino-extensibility/openvino-plugin-library/plugin.rst", "documentation/openvino-extensibility/openvino-plugin-library/plugin-api-references.rst", "documentation/openvino-extensibility/openvino-plugin-library/plugin-properties.rst", "documentation/openvino-extensibility/openvino-plugin-library/plugin-testing.rst", "documentation/openvino-extensibility/openvino-plugin-library/remote-context.rst", "documentation/openvino-extensibility/openvino-plugin-library/remote-tensor.rst", "documentation/openvino-extensibility/openvino-plugin-library/synch-inference-request.rst", "documentation/openvino-extensibility/transformation-api.rst", "documentation/openvino-extensibility/transformation-api/graph-rewrite-pass.rst", "documentation/openvino-extensibility/transformation-api/matcher-pass.rst", "documentation/openvino-extensibility/transformation-api/model-pass.rst", "documentation/openvino-ir-format.rst", "documentation/openvino-ir-format/intermediate-representation-int8-inference.rst", "documentation/openvino-ir-format/operation-sets.rst", "documentation/openvino-ir-format/operation-sets/available-opsets.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset1.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset10.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset11.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset12.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset13.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset14.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset2.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset3.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset4.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset5.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset6.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset7.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset8.rst", "documentation/openvino-ir-format/operation-sets/available-opsets/opset9.rst", "documentation/openvino-ir-format/operation-sets/broadcast-rules.rst", "documentation/openvino-ir-format/operation-sets/operation-specs.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/clamp-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/elu-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/exp-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/gelu-2.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/gelu-7.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/hard-sigmoid-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/hsigmoid-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/hswish-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/log-soft-max-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/mish-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/prelu-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/relu-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/selu-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/sigmoid-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/softmax-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/softmax-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/softplus-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/softsign-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/activation/swish-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/abs-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/acos-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/acosh-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/add-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/asin-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/asinh-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/atan-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/atanh-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/ceiling-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/cos-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/cosh-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/cumsum-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/divide-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/erf-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/floor-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/floormod-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/log-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/maximum-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/minimum-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/mod-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/multiply-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/negative-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/power-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/round-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/sign-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/sin-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/sinh-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/sqrt-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/squared-difference-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/subtract-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/tan-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/arithmetic/tanh-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/bitwise/bitwise-and-13.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/bitwise/bitwise-not-13.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/bitwise/bitwise-or-13.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/bitwise/bitwise-xor-13.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/equal-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/greater-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/greater-equal-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/isfinite-10.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/isinf-10.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/isnan-10.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/less-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/lessequal-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/comparison/notequal-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/condition/bucketize-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/condition/if-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/condition/nonzero-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/condition/select-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/binary-convolution-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/convolution-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/convolution-backprop-data-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/deformable-convolution-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/deformable-convolution-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/group-convolution-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/convolution/group-convolution-backprop-data-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/deformable-psroi-pooling-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/detectionoutput-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/detectionoutput-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/experimental-detectron-detection-output-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/experimental-detectron-generate-proposals-single-image-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/experimental-detectron-prior-grid-generator-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/experimental-detectron-roi-feature-extractor-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/generate-proposals-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/prior-box-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/prior-box-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/prior-box-clustered-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/proposal-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/proposal-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/psroi-pooling-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/region-yolo-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/reorg-yolo-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/roi-align-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/roi-align-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/roi-align-rotated-14.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/detection/roi-pooling-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/eye-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/multinomial-13.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/random-uniform-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/range-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/generation/range-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/image/grid-sample-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/image/i420-to-bgr-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/image/i420-to-rgb-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/image/interpolate-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/image/interpolate-11.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/image/interpolate-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/image/nv12-to-bgr-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/image/nv12-to-rgb-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/assign-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/assign-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/constant-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/loop-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/parameter-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/read-value-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/read-value-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/result-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/infrastructure/tensor-iterator-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/internal/augru-cell.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/internal/augru-sequence.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/logical/logical-and-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/logical/logical-not-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/logical/logical-or-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/logical/logical-xor-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/matrix/einsum-7.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/matrix/inverse-14.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/matrix/matmul-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/batch-to-space-2.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/broadcast-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/broadcast-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/concat-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/depth-to-space-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/extract-image-patches-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-7.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-elements-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-nd-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-nd-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/gather-tree-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/pad-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/pad-12.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/reverse-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/reverse-sequence-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/roll-7.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-elements-update-12.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-elements-update-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-nd-update-15.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-nd-update-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/scatter-update-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/shuffle-channels-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/slice-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/space-to-batch-2.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/space-to-depth-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/split-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/strided-slice-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/tile-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/transpose-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/unique-10.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/movement/variadic-split-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/batch-norm-inference-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/batch-norm-inference-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/grn-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/group-normalization-12.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/lrn-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/mvn-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/mvn-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/normalization/normalize-l2-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/adaptive-avg-pool-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/adaptive-max-pool-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/avg-pool-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/avg-pool-14.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/max-pool-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/max-pool-14.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/max-pool-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/pooling/pooling_shape_rules.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/quantization/fake-convert-13.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/quantization/fake-quantize-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-l1-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-l2-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-logical-and-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-logical-or-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-max-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-mean-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-min-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-prod-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/reduction/reduce-sum-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/ctc-greedy-decoder-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/ctc-greedy-decoder-seq-len-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/ctc-loss-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/gru-cell-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/gru-sequence-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/lstm-cell-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/lstm-sequence-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/one-hot-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/rnn-cell-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/rnn-sequence-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sequence/scaled-dot-product-attention.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/reshape-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/shape-of-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/shape-of-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/squeeze-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/shape/unsqueeze-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/signals/dft-7.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/signals/idft-7.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/signals/irdft-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/signals/rdft-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/experimental-detectron-top-krois-6.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/matrix-non-max-suppression-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/multiclass-non-max-suppression-8.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/multiclass-non-max-suppression-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/nms-rotated-13.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/no-max-suppression-5.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/non-max-suppression-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/non-max-suppression-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/non-max-suppression-4.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/non-max-suppression-9.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/top-k-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/top-k-11.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sort/top-k-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sparse/embedding-bag-offsets-sum-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sparse/embedding-bag-packed-sum-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/sparse/embedding-segments-sum-3.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/type/convert-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/type/convert-like-1.rst", "documentation/openvino-ir-format/operation-sets/operation-specs/type/convert-promote-types-14.rst", "documentation/openvino-security.rst", "documentation/openvino-security/openvino-encrypted-models.rst", "get-started.rst", "get-started/configurations.rst", "get-started/configurations/configurations-intel-gpu.rst", "get-started/configurations/configurations-intel-npu.rst", "get-started/install-openvino.rst", "get-started/install-openvino/install-openvino-apt.rst", "get-started/install-openvino/install-openvino-archive-linux.rst", "get-started/install-openvino/install-openvino-archive-macos.rst", "get-started/install-openvino/install-openvino-archive-windows.rst", "get-started/install-openvino/install-openvino-brew.rst", "get-started/install-openvino/install-openvino-conan.rst", "get-started/install-openvino/install-openvino-conda.rst", "get-started/install-openvino/install-openvino-docker-linux.rst", "get-started/install-openvino/install-openvino-linux.rst", "get-started/install-openvino/install-openvino-macos.rst", "get-started/install-openvino/install-openvino-npm.rst", "get-started/install-openvino/install-openvino-pip.rst", "get-started/install-openvino/install-openvino-vcpkg.rst", "get-started/install-openvino/install-openvino-windows.rst", "get-started/install-openvino/install-openvino-yum.rst", "get-started/install-openvino/install-openvino-zypper.rst", "get-started/troubleshooting-install-config.rst", "index.rst", "learn-openvino.rst", "learn-openvino/interactive-tutorials-python.rst", "learn-openvino/interactive-tutorials-python/notebooks-installation.rst", "learn-openvino/llm_inference_guide.rst", "learn-openvino/llm_inference_guide/llm-inference-hf.rst", "learn-openvino/llm_inference_guide/llm-inference-native-ov.rst", "learn-openvino/llm_inference_guide/ov-tokenizers.rst", "learn-openvino/openvino-samples.rst", "learn-openvino/openvino-samples/benchmark-tool.rst", "learn-openvino/openvino-samples/bert-benchmark.rst", "learn-openvino/openvino-samples/get-started-demos.rst", "learn-openvino/openvino-samples/hello-classification.rst", "learn-openvino/openvino-samples/hello-nv12-input-classification.rst", "learn-openvino/openvino-samples/hello-query-device.rst", "learn-openvino/openvino-samples/hello-reshape-ssd.rst", "learn-openvino/openvino-samples/image-classification-async.rst", "learn-openvino/openvino-samples/model-creation.rst", "learn-openvino/openvino-samples/sync-benchmark.rst", "learn-openvino/openvino-samples/throughput-benchmark.rst", "openvino-workflow.rst", "openvino-workflow/deployment-locally.rst", "openvino-workflow/deployment-locally/local-distribution-libraries.rst", "openvino-workflow/deployment-locally/optimial-binary-size-conditional-compilation.rst", "openvino-workflow/model-optimization.rst", "openvino-workflow/model-optimization-guide/compressing-models-during-training.rst", "openvino-workflow/model-optimization-guide/compressing-models-during-training/filter-pruning.rst", "openvino-workflow/model-optimization-guide/compressing-models-during-training/quantization-aware-training.rst", "openvino-workflow/model-optimization-guide/quantizing-models-post-training.rst", "openvino-workflow/model-optimization-guide/quantizing-models-post-training/basic-quantization-flow.rst", "openvino-workflow/model-optimization-guide/quantizing-models-post-training/quantizing-with-accuracy-control.rst", "openvino-workflow/model-optimization-guide/weight-compression.rst", "openvino-workflow/model-preparation.rst", "openvino-workflow/model-preparation/conversion-parameters.rst", "openvino-workflow/model-preparation/convert-model-onnx.rst", "openvino-workflow/model-preparation/convert-model-paddle.rst", "openvino-workflow/model-preparation/convert-model-pytorch.rst", "openvino-workflow/model-preparation/convert-model-tensorflow.rst", "openvino-workflow/model-preparation/convert-model-tensorflow-lite.rst", "openvino-workflow/model-preparation/convert-model-to-ir.rst", "openvino-workflow/model-preparation/setting-input-shapes.rst", "openvino-workflow/running-inference.rst", "openvino-workflow/running-inference/changing-input-shape.rst", "openvino-workflow/running-inference/dynamic-shapes.rst", "openvino-workflow/running-inference/dynamic-shapes/openvino-without-dynamic-shapes-api.rst", "openvino-workflow/running-inference/inference-devices-and-modes.rst", "openvino-workflow/running-inference/inference-devices-and-modes/auto-device-selection.rst", "openvino-workflow/running-inference/inference-devices-and-modes/auto-device-selection/debugging-auto-device.rst", "openvino-workflow/running-inference/inference-devices-and-modes/automatic-batching.rst", "openvino-workflow/running-inference/inference-devices-and-modes/cpu-device.rst", "openvino-workflow/running-inference/inference-devices-and-modes/gpu-device.rst", "openvino-workflow/running-inference/inference-devices-and-modes/gpu-device/remote-tensor-api-gpu-plugin.rst", "openvino-workflow/running-inference/inference-devices-and-modes/hetero-execution.rst", "openvino-workflow/running-inference/inference-devices-and-modes/multi-device.rst", "openvino-workflow/running-inference/inference-devices-and-modes/npu-device.rst", "openvino-workflow/running-inference/inference-devices-and-modes/query-device-properties.rst", "openvino-workflow/running-inference/integrate-openvino-with-your-application.rst", "openvino-workflow/running-inference/integrate-openvino-with-your-application/inference-request.rst", "openvino-workflow/running-inference/integrate-openvino-with-your-application/model-representation.rst", "openvino-workflow/running-inference/integrate-openvino-with-your-application/python-api-advanced-inference.rst", "openvino-workflow/running-inference/integrate-openvino-with-your-application/python-api-exclusives.rst", "openvino-workflow/running-inference/optimize-inference.rst", "openvino-workflow/running-inference/optimize-inference/general-optimizations.rst", "openvino-workflow/running-inference/optimize-inference/high-level-performance-hints.rst", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing.rst", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing/integrate-save-preprocessing-use-case.rst", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing/layout-api-overview.rst", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing/preprocessing-api-details.rst", "openvino-workflow/running-inference/optimize-inference/optimize-preprocessing/torchvision-preprocessing-converter.rst", "openvino-workflow/running-inference/optimize-inference/optimizing-latency.rst", "openvino-workflow/running-inference/optimize-inference/optimizing-latency/model-caching-overview.rst", "openvino-workflow/running-inference/optimize-inference/optimizing-low-level-implementation.rst", "openvino-workflow/running-inference/optimize-inference/optimizing-memory-usage.rst", "openvino-workflow/running-inference/optimize-inference/optimizing-throughput.rst", "openvino-workflow/running-inference/optimize-inference/optimizing-throughput/advanced_throughput_options.rst", "openvino-workflow/running-inference/optimize-inference/precision-control.rst", "openvino-workflow/running-inference/stateful-models.rst", "openvino-workflow/running-inference/stateful-models/obtaining-stateful-openvino-model.rst", "openvino-workflow/running-inference/string-tensors.rst", "openvino-workflow/torch-compile.rst"], "titles": ["About OpenVINO", "Additional Resources", "Glossary", "Legal Information", "OpenVINO\u2122 Telemetry", "Compatibility and Support", "Inference Device Support", "Supported Operations - by Framework Frontend", "Supported Operations - by Inference Devices", "Performance Benchmarks", "Getting Performance Numbers", "Model Accuracy", "Performance Information F.A.Q.", "OpenVINO Release Notes", "Release Policy", "System Requirements", "API Reference", "openvino", "openvino.frontend", "openvino.preprocess", "openvino.properties", "openvino.properties.device", "openvino.properties.hint", "openvino.properties.intel_auto", "openvino.properties.intel_cpu", "openvino.properties.intel_gpu", "openvino.properties.intel_gpu.hint", "openvino.properties.log", "openvino.properties.streams", "openvino.runtime", "openvino.runtime.op", "openvino.runtime.op.util", "openvino.runtime.opset1", "openvino.runtime.opset10", "openvino.runtime.opset11", "openvino.runtime.opset12", "openvino.runtime.opset13", "openvino.runtime.opset14", "openvino.runtime.opset2", "openvino.runtime.opset3", "openvino.runtime.opset4", "openvino.runtime.opset5", "openvino.runtime.opset6", "openvino.runtime.opset7", "openvino.runtime.opset8", "openvino.runtime.opset9", "openvino.runtime.passes", "OpenVINO Python API", "Property addon", "OpenVINO\u2122 Node.js Bindings", "Enumeration element", "Enumeration resizeAlgorithm", "Interface CompiledModel", "Interface Core", "Interface CoreConstructor", "InferRequest", "Interface InputInfo", "Interface InputModelInfo", "Interface InputTensorInfo", "Interface Model", "Interface Output", "Interface OutputInfo", "Interface OutputTensorInfo", "Interface PartialShape", "Interface PartialShapeConstructor", "Interface PrePostProcessor", "Interface PrePostProcessorConstructor", "Interface PreProcessSteps", "Interface Tensor", "Interface TensorConstructor", "Type alias Dimension", "Type alias SupportedTypedArray", "Type alias elementTypeString", "Documentation", "Legacy Features and Components", "Install OpenVINO\u2122 Development Tools", "Model Zoo", "Transition from Legacy Conversion API", "Legacy Conversion API", "[LEGACY] Compressing a Model to FP16", "[LEGACY] Convert Models Represented as Python Objects", "[LEGACY] Cutting Off Parts of a Model", "[LEGACY] Embedding Preprocessing Computation", "[LEGACY] Model Optimizer Frequently Asked Questions", "[LEGACY] Setting Input Shapes", "[LEGACY] Supported Model Formats", "[LEGACY] Model Conversion Tutorials", "Converting an ONNX Faster R-CNN Model", "Converting an ONNX GPT-2 Model", "Converting an ONNX Mask R-CNN Model", "Converting a PyTorch BERT-NER Model", "Converting a PyTorch Cascade RCNN R-101 Model", "Converting a PyTorch F3Net Model", "Converting a PyTorch QuartzNet Model", "Converting a PyTorch RCAN Model", "Converting a PyTorch RNN-T Model", "Converting a PyTorch YOLACT Model", "Converting a TensorFlow Attention OCR Model", "Converting a TensorFlow BERT Model", "Converting a TensorFlow CRNN Model", "Converting a TensorFlow DeepSpeech Model", "Converting TensorFlow EfficientDet Models", "Converting TensorFlow FaceNet Models", "Converting a TensorFlow GNMT Model", "Converting a TensorFlow Language Model on One Billion Word Benchmark", "Converting a TensorFlow Neural Collaborative Filtering Model", "Converting TensorFlow Object Detection API Models", "Converting a TensorFlow RetinaNet Model", "Converting TensorFlow Slim Image Classification Model Library Models", "Converting TensorFlow Wide and Deep Family Models", "Converting a TensorFlow XLNet Model", "Converting TensorFlow YOLO Models", "[LEGACY] Converting an ONNX Model", "[LEGACY] Converting a PaddlePaddle Model", "[LEGACY] Converting a PyTorch Model", "[LEGACY] Converting a TensorFlow Model", "[LEGACY] Converting a TensorFlow Lite Model", "[LEGACY] Troubleshooting Reshape Errors", "Legacy Model Optimizer Extensibility", "[LEGACY] Extending Model Optimizer with Caffe Python Layers", "[LEGACY] Graph Traversal and Modification", "[LEGACY] Model Optimizer Extensions", "[LEGACY] Graph Transformation Extensions", "[LEGACY] Model Optimizer Operation", "[LEGACY] Operation Extractor", "OpenVINO\u2122 Ecosystem Overview", "Datumaro", "OpenVINO\u2122 Security Add-on", "OpenVINO\u2122 Training Extensions", "OpenVINO Extensibility Mechanism", "How to Implement Custom GPU Operations", "Custom OpenVINO Operations", "Frontend Extensions", "Overview of OpenVINO Plugin Library", "Advanced Topics", "OpenVINO\u2122 Low Precision Transformations", "Attributes", "AvgPoolPrecisionPreserved Attribute", "IntervalsAlignment Attribute", "PrecisionPreserved Attribute", "Precisions Attribute", "QuantizationAlignment Attribute", "QuantizationGranularity Attribute", "Step 1. Prerequisites Transformations", "ConvertSubtractConstant transformation", "LinOpSequenceFusion transformation", "PullReshapeThroughDequantization transformation", "PullTransposeThroughDequantization transformation", "Step 2. Markup Transformations", "AlignQuantizationIntervals transformation", "AlignQuantizationParameters transformation", "CreateAttribute transformation", "CreatePrecisionsDependentAttribute transformation", "MarkupAvgPoolPrecisionPreserved transformation", "MarkupBias transformation", "MarkupCanBeQuantized transformation", "MarkupPerTensorQuantization transformation", "MarkupPrecisions transformation", "PropagatePrecisions transformation", "PropagateSharedValue transformation", "PropagateThroughPrecisionPreserved transformation", "PropagateToInput transformation", "UpdateSharedPrecisionPreserved transformation", "Step 3. Main Transformations", "ClampTransformation transformation", "PReluTransformation transformation", "ReluTransformation transformation", "AddTransformation transformation", "MultiplyTransformation transformation", "MultiplyTransformation transformation", "SubtractTransformation transformation", "ConvolutionTransformation transformation", "ConvolutionBackpropDataTransformation transformation", "GroupConvolutionTransformation transformation", "InterpolateTransformation transformation", "MatMulTransformation transformation", "ConcatTransformation transformation", "DepthToSpaceTransformation transformation", "GatherTransformation transformation", "PadTransformation transformation", "ShuffleChannelsTransformation transformation", "SplitTransformation transformation", "StridedSliceTransformation transformation", "TransposeTransformation transformation", "VariadicSplitTransformation transformation", "MVNTransformation transformation", "NormalizeL2Transformation transformation", "AvgPoolTransformation transformation", "MaxPoolTransformation transformation", "FakeQuantizeTransformation transformation", "FoldFakeQuantizeTransformation transformation", "ReduceMaxTransformation transformation", "ReduceMeanTransformation transformation", "ReduceMinTransformation transformation", "ReduceSumTransformation transformation", "BatchToSpaceTransformation transformation", "ReshapeTransformation transformation", "SpaceToBatchTransformation transformation", "SqueezeTransformation transformation", "UnsqueezeTransformation transformation", "Step 4. Cleanup Transformations", "EliminateFakeQuantizeTransformation transformation", "FakeQuantizeDecompositionTransformation transformation", "FoldConvertTransformation transformation", "FuseConvertTransformation transformation", "FuseMultiplyToFakeQuantizeTransformation transformation", "FuseSubtractToFakeQuantizeTransformation transformation", "MultiplyToGroupConvolutionTransformation transformation", "Quantized models compute and restrictions", "Representation of low-precision models", "Asynchronous Inference Request", "Build Plugin Using CMake", "Compiled Model", "Plugin", "Plugin API Reference", "Plugin Properties", "Plugin Testing", "Remote Context", "Remote Tensor", "Synchronous Inference Request", "Overview of Transformations API", "OpenVINO Graph Rewrite Pass", "OpenVINO Matcher Pass", "OpenVINO Model Pass", "OpenVINO IR format", "Intermediate Representation Suitable for INT8 Inference", "Operation Sets in OpenVINO", "Available Operation Sets", "opset1", "opset10", "opset11", "opset12", "opset13", "opset14", "opset2", "opset3", "opset4", "opset5", "opset6", "opset7", "opset8", "opset9", "Broadcast Rules For Elementwise Operations", "Operation Specifications", "Clamp", "Elu", "Exp", "GELU", "GELU", "HardSigmoid", "HSigmoid", "HSwish", "LogSoftMax", "Mish", "PReLU", "ReLU", "Selu", "Sigmoid", "SoftMax", "SoftMax", "SoftPlus", "SoftSign", "Swish", "Abs", "Acos", "Acosh", "Add", "Asin", "Asinh", "Atan", "Atanh", "Ceiling", "Cos", "Cosh", "CumSum", "Divide", "Erf", "Floor", "FloorMod", "Log", "Maximum", "Minimum", "Mod", "Multiply", "Negative", "Power", "Round", "Sign", "Sin", "Sinh", "Sqrt", "SquaredDifference", "Subtract", "Tan", "Tanh", "BitwiseAnd", "BitwiseNot", "BitwiseOr", "BitwiseXor", "Equal", "Greater", "GreaterEqual", "IsFinite", "IsInf", "IsNaN", "Less", "LessEqual", "NotEqual", "Bucketize", "If", "NonZero", "Select", "BinaryConvolution", "Convolution", "ConvolutionBackpropData", "DeformableConvolution", "DeformableConvolution", "GroupConvolution", "GroupConvolutionBackpropData", "DeformablePSROIPooling", "DetectionOutput", "DetectionOutput", "ExperimentalDetectronDetectionOutput", "ExperimentalDetectronGenerateProposalsSingleImage", "ExperimentalDetectronPriorGridGenerator", "ExperimentalDetectronROIFeatureExtractor", "GenerateProposals", "PriorBox", "PriorBox", "PriorBoxClustered", "Proposal", "Proposal", "PSROIPooling", "RegionYolo", "ReorgYolo Layer", "ROIAlign", "ROIAlign", "ROIAlignRotated", "ROIPooling", "Eye", "Multinomial", "RandomUniform", "Range", "Range", "GridSample", "I420toBGR", "I420toRGB", "Interpolate", "Interpolate", "Interpolate", "NV12toBGR", "NV12toRGB", "Assign", "Assign", "Constant", "Loop", "Parameter", "ReadValue", "ReadValue", "Result", "TensorIterator", "AUGRUCell", "AUGRUSequence", "LogicalAnd", "LogicalNot", "LogicalOr", "LogicalXor", "Einsum", "Inverse", "MatMul", "BatchToSpace", "Broadcast", "Broadcast", "Concat", "DepthToSpace", "ExtractImagePatches", "Gather", "Gather", "Gather", "GatherElements", "GatherND", "GatherND", "GatherTree", "Pad", "Pad", "Reverse", "ReverseSequence", "Roll", "ScatterElementsUpdate", "ScatterElementsUpdate", "ScatterNDUpdate", "ScatterNDUpdate", "ScatterUpdate", "ShuffleChannels", "Slice", "SpaceToBatch", "SpaceToDepth", "Split", "StridedSlice", "Tile", "Transpose", "Unique", "VariadicSplit", "BatchNormInference", "BatchNormInference", "GRN", "GroupNormalization", "LRN", "MVN", "MVN", "NormalizeL2", "AdaptiveAvgPool", "AdaptiveMaxPool", "AvgPool", "AvgPool", "MaxPool", "MaxPool", "MaxPool", "Shape calculation rules for Pooling Operators", "FakeConvert", "FakeQuantize", "ReduceL1", "ReduceL2", "ReduceLogicalAnd", "ReduceLogicalOr", "ReduceMax", "ReduceMean", "ReduceMin", "ReduceProd", "ReduceSum", "CTCGreedyDecoder", "CTCGreedyDecoderSeqLen", "CTCLoss", "GRUCell", "GRUSequence", "LSTMCell", "LSTMSequence", "OneHot", "RNNCell", "RNNSequence", "ScaledDotProductAttention", "Reshape", "ShapeOf", "ShapeOf", "Squeeze", "Unsqueeze", "DFT", "Inverse Discrete Fourier Transformation (IDFT)", "Inverse Discrete complex-to-real Fourier Transformation (IRDFT)", "Discrete Fourier Transformation for real-valued input (RDFT)", "ExperimentalDetectronTopKROIs", "MatrixNonMaxSuppression", "MulticlassNonMaxSuppression", "MulticlassNonMaxSuppression", "NMSRotated", "NonMaxSuppression", "NonMaxSuppression", "NonMaxSuppression", "NonMaxSuppression", "NonMaxSuppression", "TopK", "TopK", "TopK", "EmbeddingBagOffsetsSum", "EmbeddingBagPackedSum", "EmbeddingSegmentsSum", "Convert", "ConvertLike", "ConvertPromoteTypes", "OpenVINO Security", "Using Encrypted Models with OpenVINO", "GET STARTED", "Additional Configurations For Hardware", "Configurations for Intel\u00ae Processor Graphics (GPU) with OpenVINO\u2122", "Configurations for Intel\u00ae NPU with OpenVINO\u2122", "Install OpenVINO\u2122 2024.0", "Install Intel\u00ae Distribution of OpenVINO\u2122 Toolkit for Linux Using APT Repository", "Install OpenVINO\u2122 Runtime on Linux from an Archive File", "Install OpenVINO\u2122 Runtime on macOS from an Archive File", "Install OpenVINO\u2122 Runtime on Windows from an Archive File", "Install OpenVINO\u2122 Runtime via Homebrew", "Install OpenVINO\u2122 Runtime from Conan Package Manager", "Install OpenVINO\u2122 Runtime from Conda Forge", "Install Intel\u00ae Distribution of OpenVINO\u2122 toolkit from a Docker Image", "Install OpenVINO\u2122 Runtime on Linux", "Install OpenVINO\u2122 Runtime for macOS", "Install Intel\u00ae Distribution of OpenVINO\u2122 Toolkit from npm Registry", "Install Intel\u00ae Distribution of OpenVINO\u2122 Toolkit from PyPI Repository", "Install OpenVINO\u2122 Runtime via vcpkg", "Install OpenVINO\u2122 Runtime on Windows", "Install OpenVINO\u2122 Runtime on Linux From YUM Repository", "Install OpenVINO\u2122 Runtime on Linux From ZYPPER Repository", "Troubleshooting Guide for OpenVINO\u2122 Installation &amp; Configuration", "OpenVINO 2024.2", "Learn OpenVINO", "Interactive Tutorials (Python)", "Installation of OpenVINO\u2122 Notebooks", "Large Language Model Inference Guide", "Inference with Hugging Face and Optimum Intel", "Inference with Native OpenVINO", "OpenVINO Tokenizers", "OpenVINO\u2122 Samples", "Benchmark Tool", "Bert Benchmark Python Sample", "Get Started with Samples", "Hello Classification Sample", "Hello NV12 Input Classification Sample", "Hello Query Device Sample", "Hello Reshape SSD Sample", "Image Classification Async Sample", "Model Creation Sample", "Sync Benchmark Sample", "Throughput Benchmark Sample", "OpenVINO Workflow", "Deploy Locally", "Libraries for Local Distribution", "OpenVINO Conditional Compilation for Optimal Binary Size", "Model Optimization Guide", "Compressing Models During Training", "Filter Pruning of Convolutional Models", "Quantization-aware Training (QAT)", "Quantizing Models Post-training", "Basic Quantization Flow", "Quantizing with Accuracy Control", "Weight Compression", "Model Preparation", "Conversion Parameters", "Converting an ONNX Model", "Converting a PaddlePaddle Model", "Converting a PyTorch Model", "Converting a TensorFlow Model", "Converting a TensorFlow Lite Model", "Convert to OpenVINO IR", "Setting Input Shapes", "Running Inference with OpenVINO\u2122", "Changing Input Shapes", "Dynamic Shapes", "When Dynamic Shapes API is Not Applicable", "Inference Devices and Modes", "Automatic Device Selection", "Debugging Auto-Device Plugin", "Automatic Batching", "CPU Device", "GPU Device", "Remote Tensor API of GPU Plugin", "Heterogeneous execution", "Multi-device execution", "NPU Device", "Query Device Properties - Configuration", "Integrate OpenVINO\u2122 with Your Application", "OpenVINO\u2122 Inference Request", "Model Representation in OpenVINO\u2122 Runtime", "OpenVINO\u2122 Runtime Python API Advanced Inference", "OpenVINO\u2122 Python API Exclusives", "Optimize Inference", "General Optimizations", "High-level Performance Hints", "Optimize Preprocessing", "Use Case - Integrate and Save Preprocessing Steps Into IR", "Layout API Overview", "Preprocessing API - details", "Torchvision preprocessing converter", "Optimizing for Latency", "Model Caching Overview", "Further Low-Level Implementation Details", "Optimizing memory usage", "Optimizing for Throughput", "Advanced Throughput Options: Streams and Batching", "Precision Control", "Stateful models and State API", "Obtaining a Stateful OpenVINO Model", "String Tensors", "PyTorch Deployment via \u201ctorch.compile\u201d"], "terms": {"i": [0, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 88, 89, 90, 91, 93, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 145, 148, 163, 167, 171, 208, 209, 210, 211, 212, 213, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 486, 488, 490, 491, 492, 493, 494, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572], "toolkit": [0, 3, 4, 6, 9, 12, 13, 14, 15, 16, 73, 75, 76, 83, 86, 93, 101, 109, 111, 125, 127, 128, 129, 135, 209, 224, 226, 227, 470, 471, 473, 475, 479, 480, 481, 488, 490, 491, 492, 493, 494, 504, 505, 507, 508, 509, 542, 543, 551], "simpl": [0, 10, 12, 14, 75, 76, 88, 96, 111, 209, 340, 348, 349, 368, 390, 440, 492, 494, 497, 500, 501, 502, 516, 522, 526, 538, 542, 549, 551, 553, 556, 558, 559, 560, 566], "effici": [0, 9, 13, 74, 84, 122, 130, 220, 221, 464, 471, 497, 498, 500, 509, 524, 525, 536, 539, 542, 545, 547, 555, 556, 560, 564, 567, 568, 569], "deploy": [0, 9, 12, 13, 83, 91, 127, 469, 493, 497, 498, 500, 513, 515, 516, 517, 519, 524, 525, 526, 554], "variou": [0, 2, 73, 78, 106, 122, 129, 226, 471, 493, 494, 495, 496, 497, 500, 502, 536, 547, 552, 553, 572], "deep": [0, 2, 6, 9, 73, 74, 76, 78, 86, 94, 100, 106, 118, 125, 126, 128, 135, 224, 226, 227, 317, 403, 404, 419, 469, 470, 476, 477, 478, 479, 480, 488, 490, 491, 493, 494, 495, 497, 501, 502, 513, 517, 526, 527, 534, 542, 543, 554, 557, 560, 562, 572], "learn": [0, 2, 3, 6, 9, 13, 15, 73, 74, 76, 78, 83, 84, 86, 106, 107, 115, 118, 125, 126, 128, 132, 135, 224, 226, 227, 403, 404, 419, 469, 470, 475, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 493, 495, 497, 499, 500, 501, 502, 504, 513, 517, 518, 519, 520, 526, 527, 529, 530, 533, 534, 542, 543, 549, 557, 560, 562, 571, 572], "model": [0, 1, 2, 4, 6, 9, 10, 12, 14, 16, 53, 56, 66, 73, 74, 75, 84, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 136, 143, 148, 163, 210, 211, 213, 216, 217, 219, 221, 222, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 330, 331, 353, 355, 356, 358, 359, 406, 451, 452, 453, 469, 472, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 493, 494, 496, 500, 501, 502, 503, 505, 506, 508, 509, 511, 512, 513, 514, 526, 533, 534, 535, 541, 544, 545, 546, 552, 554, 555, 556, 560, 561, 562, 564, 565, 566, 567, 568, 571, 572], "In": [0, 2, 10, 12, 13, 75, 77, 79, 80, 81, 82, 83, 84, 85, 99, 105, 106, 108, 111, 115, 118, 119, 122, 123, 124, 127, 129, 132, 135, 148, 167, 208, 209, 210, 212, 213, 216, 220, 221, 222, 224, 226, 244, 274, 286, 310, 312, 313, 314, 315, 316, 317, 318, 340, 341, 348, 358, 367, 368, 371, 372, 375, 380, 385, 391, 398, 402, 413, 414, 415, 416, 417, 420, 434, 436, 439, 440, 448, 468, 473, 478, 480, 493, 496, 497, 498, 499, 500, 502, 509, 515, 516, 517, 519, 520, 522, 523, 524, 526, 527, 529, 530, 533, 535, 536, 537, 539, 540, 541, 542, 543, 544, 545, 548, 549, 550, 551, 552, 555, 556, 557, 558, 560, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571], "thi": [0, 2, 6, 7, 8, 9, 10, 12, 13, 14, 15, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 135, 136, 148, 167, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 245, 247, 248, 252, 253, 254, 256, 261, 262, 275, 308, 314, 319, 320, 321, 324, 333, 339, 340, 341, 343, 344, 347, 348, 349, 352, 353, 355, 358, 360, 362, 367, 368, 369, 371, 372, 375, 377, 378, 379, 380, 381, 383, 384, 388, 393, 398, 401, 406, 411, 412, 416, 417, 418, 420, 431, 432, 434, 435, 436, 437, 439, 440, 441, 448, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 463, 464, 465, 468, 469, 470, 471, 474, 476, 477, 478, 479, 482, 483, 492, 493, 494, 496, 497, 498, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 535, 536, 537, 538, 539, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 562, 563, 564, 565, 567, 568, 569, 570, 571, 572], "section": [0, 9, 73, 74, 75, 82, 83, 86, 96, 101, 105, 106, 111, 112, 113, 115, 118, 120, 122, 123, 127, 129, 130, 132, 135, 216, 220, 222, 224, 355, 360, 469, 471, 473, 494, 495, 496, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 519, 520, 522, 530, 532, 536, 539, 541, 544, 546, 549, 551, 556, 558, 560, 564, 566, 567, 569, 570, 571], "you": [0, 2, 4, 6, 9, 10, 12, 13, 14, 15, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 128, 129, 130, 131, 132, 135, 210, 211, 212, 219, 220, 221, 222, 223, 367, 403, 404, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 516, 518, 519, 520, 522, 523, 525, 526, 527, 529, 530, 532, 534, 535, 536, 537, 538, 539, 540, 541, 542, 544, 545, 546, 547, 549, 550, 551, 553, 554, 555, 559, 560, 561, 563, 564, 565, 567, 568, 569, 570, 572], "find": [0, 2, 10, 12, 13, 14, 81, 86, 99, 106, 108, 111, 113, 115, 118, 122, 129, 132, 133, 211, 212, 220, 286, 330, 331, 368, 401, 421, 422, 425, 426, 427, 432, 454, 469, 474, 479, 494, 500, 504, 513, 514, 516, 524, 535, 567, 568, 569, 572], "inform": [0, 1, 2, 5, 8, 9, 10, 11, 77, 78, 79, 81, 82, 83, 84, 87, 89, 94, 98, 101, 103, 106, 107, 108, 111, 114, 115, 117, 118, 119, 120, 122, 123, 126, 127, 128, 130, 131, 133, 134, 135, 148, 212, 213, 219, 220, 224, 226, 320, 321, 322, 454, 455, 456, 457, 458, 459, 470, 474, 483, 492, 494, 495, 500, 504, 505, 506, 508, 509, 514, 515, 518, 519, 520, 525, 526, 529, 530, 533, 534, 535, 536, 538, 539, 540, 542, 543, 546, 548, 549, 551, 553, 554, 555, 556, 557, 559, 565, 567, 569, 570, 571], "product": [0, 3, 4, 8, 9, 12, 13, 14, 15, 118, 127, 313, 361, 362, 367, 370, 416, 417, 433, 435, 440, 441, 471, 476, 477, 479, 480, 481, 482, 487, 488, 490, 491, 497, 504, 513, 516, 525, 547, 554, 555, 556], "itself": [0, 82, 121, 213, 216, 262, 388, 389, 410, 529, 534, 541, 544, 556, 569], "well": [0, 2, 9, 10, 13, 14, 106, 108, 118, 129, 130, 132, 320, 321, 347, 348, 349, 420, 437, 470, 474, 475, 477, 478, 479, 482, 494, 510, 525, 529, 534, 536, 537, 539, 541, 542, 546, 553, 554, 563, 564, 569], "softwar": [0, 2, 3, 4, 9, 13, 14, 15, 125, 470, 472, 476, 477, 478, 479, 480, 481, 482, 486, 488, 490, 491, 496, 525, 534, 542, 552], "hardwar": [0, 1, 2, 3, 4, 5, 6, 9, 12, 13, 14, 15, 84, 114, 127, 209, 212, 213, 216, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 343, 470, 471, 473, 474, 477, 492, 493, 497, 502, 504, 516, 521, 533, 534, 535, 536, 538, 539, 542, 543, 544, 545, 546, 547, 549, 552, 554, 564, 567, 568, 572], "solut": [0, 6, 9, 12, 13, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 133, 368, 461, 470, 472, 492, 496, 497, 504, 513, 525, 529, 538, 546, 547, 556, 560, 569, 570], "support": [0, 2, 4, 10, 12, 15, 73, 74, 75, 78, 80, 84, 86, 87, 89, 96, 97, 100, 102, 103, 105, 106, 108, 109, 114, 118, 119, 122, 126, 127, 129, 130, 131, 132, 135, 148, 171, 208, 212, 213, 216, 217, 219, 220, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 245, 246, 247, 248, 251, 253, 254, 255, 256, 260, 261, 262, 269, 270, 275, 276, 284, 289, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 311, 316, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 332, 333, 335, 336, 337, 338, 340, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 367, 368, 369, 370, 374, 375, 377, 378, 379, 380, 381, 382, 385, 386, 387, 388, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 448, 449, 450, 454, 455, 459, 466, 467, 468, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 486, 487, 488, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 502, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 520, 521, 522, 523, 524, 525, 526, 532, 533, 534, 535, 536, 537, 538, 539, 541, 544, 545, 546, 548, 549, 550, 551, 553, 556, 561, 562, 563, 565, 566, 567, 568, 570, 571], "open": [0, 12, 13, 74, 75, 76, 77, 91, 98, 101, 116, 126, 127, 128, 130, 135, 216, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 487, 488, 490, 491, 493, 496, 504, 518, 529, 531, 540, 549, 572], "visual": [0, 2, 13, 15, 106, 115, 220, 225, 479, 504, 516, 529, 551], "infer": [0, 2, 5, 7, 9, 10, 12, 15, 55, 74, 75, 79, 80, 81, 82, 84, 85, 86, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 111, 112, 114, 115, 116, 120, 122, 123, 124, 125, 128, 129, 131, 133, 148, 167, 212, 213, 216, 217, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 327, 328, 333, 352, 353, 358, 369, 414, 416, 451, 452, 453, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481, 486, 487, 488, 490, 491, 492, 493, 494, 495, 496, 500, 501, 502, 503, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 537, 539, 541, 544, 545, 547, 548, 555, 557, 562, 563, 564, 565, 566, 567, 570, 571, 572], "neural": [0, 2, 4, 6, 9, 12, 73, 74, 75, 76, 78, 82, 97, 103, 108, 125, 129, 133, 208, 225, 253, 256, 312, 313, 317, 432, 472, 497, 498, 499, 517, 518, 520, 521, 524, 525, 542, 543, 547], "network": [0, 2, 4, 9, 12, 73, 74, 75, 76, 78, 82, 94, 95, 97, 102, 103, 108, 113, 114, 115, 118, 122, 125, 129, 130, 133, 134, 208, 219, 224, 225, 256, 309, 312, 313, 315, 316, 317, 325, 355, 360, 403, 404, 415, 432, 472, 492, 497, 498, 499, 501, 502, 508, 517, 518, 520, 521, 524, 525, 530, 536, 539, 541, 542, 543, 544, 547, 555, 562, 563, 564, 566, 567], "optim": [0, 4, 6, 9, 10, 12, 13, 14, 15, 73, 74, 75, 79, 82, 84, 85, 86, 104, 106, 109, 112, 113, 114, 115, 116, 120, 122, 124, 125, 128, 129, 131, 132, 136, 148, 167, 208, 209, 212, 220, 225, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 432, 470, 471, 493, 494, 495, 497, 499, 502, 513, 515, 518, 521, 522, 523, 524, 525, 526, 532, 533, 536, 539, 540, 543, 545, 547, 552, 558, 559, 561, 563, 564, 567, 568, 569, 572], "an": [0, 2, 9, 10, 11, 12, 13, 14, 73, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 97, 98, 99, 100, 103, 105, 106, 110, 111, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 128, 129, 130, 131, 132, 133, 135, 136, 139, 140, 148, 167, 208, 209, 210, 211, 212, 213, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 249, 263, 264, 267, 278, 279, 282, 288, 289, 312, 313, 314, 315, 316, 317, 318, 319, 323, 326, 327, 328, 333, 337, 339, 340, 344, 345, 346, 348, 349, 350, 351, 352, 353, 355, 357, 358, 360, 367, 368, 369, 371, 372, 375, 380, 381, 383, 384, 385, 386, 388, 389, 390, 392, 393, 397, 398, 399, 400, 402, 407, 408, 410, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 437, 440, 444, 446, 447, 448, 449, 451, 452, 453, 454, 455, 459, 460, 461, 462, 466, 467, 468, 470, 471, 472, 476, 482, 483, 484, 485, 487, 489, 492, 493, 494, 496, 498, 499, 500, 501, 502, 504, 505, 506, 508, 509, 510, 513, 515, 516, 517, 518, 519, 520, 523, 524, 525, 526, 529, 530, 531, 532, 533, 535, 536, 538, 539, 540, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 553, 555, 556, 558, 559, 560, 562, 563, 564, 565, 567, 568, 569, 570, 571, 572], "sourc": [0, 9, 10, 12, 13, 14, 15, 80, 83, 100, 116, 118, 119, 120, 121, 126, 127, 128, 132, 133, 208, 211, 220, 325, 360, 371, 372, 385, 400, 419, 440, 466, 473, 474, 475, 476, 477, 478, 487, 488, 492, 493, 496, 497, 499, 500, 503, 504, 510, 511, 512, 515, 517, 518, 520, 521, 523, 525, 531, 532, 536, 540, 541, 542, 543, 544, 548, 551, 555, 560, 566, 572], "design": [0, 6, 9, 13, 15, 117, 216, 468, 493, 500, 517, 524, 533, 535, 537, 556], "acceler": [0, 5, 6, 10, 13, 15, 75, 82, 127, 403, 404, 474, 483, 493, 494, 497, 516, 517, 518, 539, 545, 546, 549, 550, 555, 562, 564, 567, 568, 572], "deploi": [0, 9, 13, 14, 73, 75, 83, 100, 114, 128, 469, 470, 471, 483, 493, 497, 499, 513, 515, 518, 525, 534, 538, 539, 543], "user": [0, 10, 13, 15, 74, 75, 79, 83, 106, 111, 119, 122, 129, 130, 131, 132, 210, 219, 220, 466, 467, 470, 471, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 492, 494, 496, 501, 502, 504, 514, 528, 533, 536, 540, 541, 542, 544, 546, 547, 548, 552, 553, 555, 560, 564, 568, 569, 570, 571, 572], "applic": [0, 2, 3, 6, 9, 10, 12, 13, 49, 73, 75, 76, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 135, 213, 216, 242, 348, 361, 362, 434, 435, 436, 439, 441, 470, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 493, 494, 497, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 525, 527, 528, 529, 530, 531, 532, 534, 535, 536, 539, 540, 541, 542, 543, 545, 546, 547, 548, 550, 551, 553, 554, 555, 556, 557, 559, 560, 561, 562, 563, 564, 567, 568, 570, 571, 572], "wa": [0, 3, 10, 74, 75, 77, 81, 82, 92, 94, 95, 98, 111, 112, 115, 118, 122, 129, 132, 135, 148, 212, 219, 222, 223, 226, 352, 357, 468, 480, 487, 499, 502, 504, 508, 516, 519, 524, 530, 536, 542, 551, 556, 562, 565, 568], "develop": [0, 2, 4, 6, 9, 13, 14, 49, 74, 80, 85, 118, 125, 129, 131, 132, 133, 134, 135, 212, 213, 214, 216, 220, 470, 471, 473, 475, 477, 478, 479, 480, 483, 486, 487, 492, 496, 497, 514, 518, 522, 527, 537, 542, 543, 544, 547, 549, 551, 552, 567, 571], "intel": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 73, 74, 75, 76, 96, 127, 129, 135, 211, 212, 213, 219, 470, 471, 472, 479, 482, 490, 492, 493, 494, 496, 497, 499, 502, 504, 505, 507, 510, 515, 517, 524, 534, 539, 540, 543, 547, 548, 568, 569, 570, 572], "work": [0, 2, 9, 11, 12, 13, 15, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 210, 213, 218, 222, 360, 401, 471, 473, 476, 480, 481, 482, 488, 490, 491, 494, 496, 499, 500, 502, 504, 517, 523, 526, 529, 530, 536, 537, 542, 543, 545, 549, 554, 555, 565, 566, 569, 570, 571], "wide": [0, 13, 76, 77, 118, 471, 492, 497, 506, 521, 556, 559], "rang": [0, 7, 8, 10, 77, 82, 83, 108, 111, 130, 135, 208, 209, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 248, 252, 258, 259, 266, 274, 275, 278, 280, 281, 282, 283, 285, 286, 291, 292, 295, 297, 298, 299, 300, 301, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 344, 346, 347, 348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 365, 366, 367, 368, 369, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 390, 392, 393, 394, 396, 397, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 443, 444, 445, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 466, 467, 468, 497, 499, 500, 502, 519, 524, 536, 538, 553, 571], "platform": [0, 9, 10, 11, 12, 13, 14, 127, 135, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 473, 475, 516, 524, 534, 542, 543, 547, 568, 572], "includ": [0, 6, 9, 10, 12, 13, 14, 15, 16, 73, 74, 75, 76, 77, 81, 82, 83, 85, 97, 106, 111, 113, 115, 118, 127, 129, 130, 131, 132, 135, 138, 141, 143, 148, 163, 211, 212, 213, 216, 225, 226, 227, 274, 308, 342, 343, 369, 378, 394, 413, 414, 432, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 487, 488, 490, 491, 494, 497, 498, 499, 500, 501, 502, 514, 515, 516, 518, 524, 528, 529, 530, 539, 540, 541, 542, 544, 546, 547, 549, 551, 552, 555, 558, 560, 564, 567, 569, 571], "cpu": [0, 2, 6, 7, 8, 9, 10, 12, 95, 96, 103, 127, 135, 208, 210, 213, 225, 472, 475, 477, 478, 483, 486, 487, 488, 493, 496, 497, 498, 500, 502, 506, 507, 509, 511, 512, 515, 516, 518, 522, 524, 534, 538, 539, 541, 543, 545, 546, 547, 548, 554, 556, 557, 562, 566, 567, 568, 572], "x86": [0, 8, 15, 478, 479, 486, 497, 516], "arm": [0, 8, 13, 15, 135, 477, 478, 486, 497, 515, 542], "gpu": [0, 2, 6, 8, 96, 129, 135, 208, 213, 225, 472, 475, 477, 483, 492, 496, 497, 498, 502, 504, 505, 508, 509, 510, 514, 515, 518, 522, 524, 534, 538, 539, 540, 541, 542, 545, 546, 548, 554, 555, 556, 557, 562, 564, 567, 568, 572], "npu": [0, 2, 6, 15, 472, 475, 477, 480, 481, 482, 488, 490, 491, 492, 522, 538, 539, 541], "One": [0, 82, 208, 337, 355, 369, 440, 470, 512, 546, 565, 567, 569], "main": [0, 9, 13, 16, 103, 111, 118, 120, 132, 133, 210, 211, 220, 222, 339, 355, 361, 362, 431, 469, 473, 476, 497, 514, 515, 521, 527, 536, 537, 553, 555, 570], "purpos": [0, 3, 4, 9, 14, 123, 127, 208, 224, 242, 355, 398, 526, 529, 537, 539, 540, 542, 543, 545, 547, 550, 551, 557, 559, 560, 569], "streamlin": [0, 500, 547], "It": [0, 4, 6, 9, 10, 13, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 132, 135, 148, 171, 209, 210, 211, 212, 217, 220, 221, 222, 224, 226, 245, 247, 248, 262, 278, 282, 302, 311, 314, 318, 319, 320, 321, 332, 333, 337, 344, 360, 367, 368, 369, 370, 371, 372, 377, 378, 380, 381, 395, 397, 398, 402, 408, 410, 419, 420, 432, 434, 435, 436, 439, 452, 453, 460, 474, 482, 483, 492, 493, 494, 496, 497, 498, 499, 502, 517, 518, 519, 520, 522, 523, 524, 525, 526, 529, 530, 534, 535, 536, 537, 538, 539, 542, 543, 545, 546, 547, 549, 550, 551, 552, 553, 554, 555, 557, 559, 560, 561, 562, 563, 564, 565, 567, 569, 571, 572], "which": [0, 2, 7, 9, 13, 14, 15, 16, 48, 77, 78, 79, 80, 81, 82, 83, 84, 85, 97, 100, 102, 106, 108, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 135, 137, 140, 148, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 222, 225, 226, 242, 252, 258, 259, 274, 302, 304, 309, 314, 315, 316, 318, 327, 328, 329, 330, 331, 340, 341, 344, 349, 354, 355, 356, 358, 360, 361, 362, 367, 370, 375, 379, 380, 381, 383, 384, 386, 387, 388, 394, 397, 398, 402, 407, 408, 409, 410, 413, 414, 415, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 441, 451, 452, 453, 454, 455, 459, 460, 461, 462, 465, 466, 468, 479, 481, 483, 488, 492, 494, 498, 499, 501, 502, 504, 510, 512, 513, 514, 515, 516, 518, 519, 520, 522, 523, 524, 525, 526, 528, 529, 530, 532, 533, 534, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 553, 555, 557, 558, 559, 560, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572], "crucial": [0, 114, 482, 524, 526, 547], "domain": [0, 7, 540], "gener": [0, 8, 10, 12, 13, 15, 78, 81, 82, 83, 87, 88, 89, 90, 91, 92, 94, 98, 100, 101, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 115, 118, 123, 124, 127, 129, 130, 132, 208, 211, 212, 222, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 320, 321, 322, 324, 327, 328, 329, 330, 331, 339, 340, 341, 342, 343, 348, 369, 382, 383, 384, 388, 420, 446, 447, 448, 449, 454, 468, 469, 472, 481, 483, 492, 493, 494, 497, 498, 502, 504, 510, 511, 512, 514, 516, 518, 524, 526, 528, 529, 530, 535, 536, 541, 542, 543, 544, 545, 547, 556, 560, 564, 566, 567, 569, 572], "ai": [0, 9, 11, 12, 13, 493, 494, 497, 498, 499, 527, 561], "larg": [0, 10, 11, 12, 13, 74, 79, 88, 98, 126, 129, 494, 502, 516, 517, 519, 524, 532, 539, 541, 552, 564, 566, 571], "languag": [0, 9, 12, 13, 88, 106, 278, 282, 394, 493, 494, 514, 517, 524, 536, 543, 571], "us": [0, 1, 2, 3, 4, 6, 9, 10, 12, 13, 14, 15, 16, 49, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 136, 137, 138, 141, 148, 208, 209, 210, 212, 213, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 242, 244, 248, 262, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 303, 305, 306, 307, 311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 332, 333, 335, 336, 337, 338, 341, 344, 348, 349, 355, 358, 360, 363, 365, 366, 367, 368, 371, 372, 375, 377, 378, 380, 383, 384, 385, 387, 388, 390, 394, 398, 401, 407, 408, 411, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 435, 438, 440, 441, 444, 448, 451, 460, 461, 462, 464, 468, 469, 471, 472, 473, 474, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 489, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 541, 542, 543, 544, 547, 548, 549, 551, 552, 553, 554, 555, 557, 559, 560, 561, 562, 564, 565, 566, 567, 568, 569, 571], "like": [0, 10, 13, 16, 75, 80, 83, 95, 98, 100, 106, 111, 114, 118, 122, 124, 127, 129, 131, 132, 135, 213, 220, 224, 278, 282, 320, 321, 330, 331, 344, 355, 369, 388, 390, 431, 453, 467, 468, 470, 474, 481, 493, 497, 498, 499, 500, 501, 502, 504, 514, 515, 516, 517, 525, 532, 536, 538, 539, 540, 545, 546, 548, 549, 552, 553, 555, 557, 560, 565, 566, 567, 569, 571, 572], "object": [0, 2, 12, 75, 76, 77, 83, 85, 88, 92, 101, 109, 111, 114, 115, 117, 118, 120, 122, 123, 124, 129, 131, 132, 133, 212, 213, 219, 222, 226, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 367, 476, 477, 478, 479, 482, 490, 491, 500, 505, 506, 508, 509, 511, 512, 513, 519, 520, 522, 523, 525, 526, 528, 529, 530, 532, 535, 536, 543, 544, 545, 547, 550, 551, 552, 553, 555, 563, 571], "detect": [0, 2, 12, 13, 75, 76, 77, 83, 92, 96, 101, 108, 111, 115, 117, 122, 127, 148, 218, 220, 222, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 452, 453, 454, 455, 459, 476, 477, 478, 479, 482, 490, 491, 504, 508, 511, 512, 530, 536, 539, 541, 542, 543, 547, 550, 555, 569, 570], "classif": [0, 12, 13, 75, 76, 106, 115, 117, 122, 130, 317, 432, 471, 476, 477, 478, 479, 482, 487, 490, 491, 501, 504, 510, 519, 523, 525, 530, 539, 541, 547, 549, 550], "segment": [0, 12, 13, 76, 96, 465, 536], "mani": [0, 6, 83, 118, 120, 123, 130, 212, 213, 367, 375, 460, 461, 462, 481, 482, 497, 502, 532, 533, 536, 541, 542, 543, 545, 549, 555, 556, 558, 560, 562, 564, 567], "other": [0, 1, 2, 3, 4, 9, 10, 12, 15, 49, 74, 75, 76, 81, 85, 94, 98, 102, 106, 108, 109, 111, 113, 115, 118, 119, 120, 122, 127, 135, 143, 148, 163, 212, 213, 216, 218, 220, 226, 242, 254, 256, 302, 303, 304, 309, 311, 314, 347, 348, 349, 355, 358, 360, 368, 369, 383, 384, 394, 398, 402, 416, 417, 432, 437, 440, 446, 447, 448, 449, 465, 468, 469, 471, 474, 476, 477, 478, 479, 482, 490, 491, 498, 500, 502, 509, 511, 512, 513, 515, 516, 524, 527, 530, 533, 535, 536, 537, 539, 540, 542, 543, 545, 547, 548, 549, 551, 552, 553, 554, 555, 562, 566, 567, 568, 569, 570, 571], "provid": [0, 2, 9, 10, 13, 15, 73, 74, 75, 76, 77, 80, 81, 82, 84, 85, 86, 93, 99, 100, 101, 102, 103, 104, 106, 111, 112, 113, 114, 115, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 148, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 262, 311, 316, 319, 320, 321, 322, 323, 325, 326, 348, 355, 358, 371, 372, 383, 384, 388, 394, 398, 401, 408, 431, 432, 440, 444, 461, 463, 464, 465, 468, 469, 470, 471, 477, 479, 486, 488, 492, 493, 494, 496, 497, 498, 499, 501, 502, 504, 506, 514, 516, 518, 519, 520, 521, 523, 524, 525, 526, 527, 528, 529, 530, 533, 534, 536, 539, 540, 541, 542, 543, 544, 546, 548, 549, 551, 552, 553, 555, 558, 559, 564, 565, 566, 568, 569, 571], "multipl": [0, 6, 9, 10, 13, 14, 77, 78, 80, 84, 96, 98, 120, 126, 127, 130, 131, 167, 171, 212, 216, 220, 221, 222, 226, 262, 283, 309, 313, 317, 318, 319, 332, 335, 336, 337, 340, 355, 360, 361, 362, 367, 368, 369, 380, 387, 388, 389, 390, 392, 397, 398, 402, 428, 433, 434, 435, 436, 438, 439, 440, 461, 477, 478, 502, 509, 511, 512, 513, 526, 527, 529, 532, 533, 536, 538, 539, 541, 542, 543, 544, 545, 546, 548, 553, 554, 555, 560, 562, 564, 566, 567, 568, 569, 571, 572], "method": [0, 2, 7, 13, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 129, 130, 131, 132, 135, 209, 210, 212, 213, 217, 218, 219, 220, 222, 223, 320, 321, 333, 335, 336, 338, 383, 384, 406, 470, 479, 490, 491, 498, 513, 516, 517, 521, 523, 524, 527, 528, 529, 530, 531, 532, 533, 536, 537, 538, 539, 541, 542, 543, 548, 549, 550, 551, 552, 553, 555, 557, 563, 567, 568, 569, 570, 571], "both": [0, 2, 3, 9, 10, 13, 75, 76, 77, 80, 81, 82, 102, 103, 106, 115, 122, 126, 127, 129, 132, 135, 148, 167, 220, 222, 225, 226, 242, 303, 315, 316, 324, 329, 341, 344, 367, 369, 371, 372, 395, 432, 468, 476, 477, 478, 479, 480, 482, 483, 490, 491, 497, 498, 500, 502, 513, 523, 524, 530, 540, 541, 542, 543, 547, 550, 555, 562, 566, 567, 568, 569, 571], "train": [0, 2, 4, 13, 73, 74, 75, 76, 78, 79, 80, 81, 82, 85, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 114, 115, 118, 125, 126, 129, 225, 325, 403, 404, 440, 469, 470, 471, 476, 477, 478, 479, 480, 488, 490, 491, 493, 496, 498, 500, 502, 505, 506, 508, 509, 511, 512, 513, 517, 524, 525, 526, 530, 532, 534, 542, 568], "post": [0, 4, 9, 10, 12, 13, 74, 79, 81, 87, 89, 333, 493, 497, 513, 517, 518, 520, 524, 525, 526, 529, 544, 571], "stage": [0, 12, 84, 118, 133, 135, 210, 212, 219, 320, 321, 322, 323, 326, 488, 499, 502, 513, 515, 518, 533, 535, 539, 541, 542, 547, 555, 560, 563, 565], "weight": [0, 2, 13, 74, 77, 78, 79, 80, 81, 85, 95, 96, 100, 103, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 122, 130, 135, 148, 208, 209, 224, 312, 313, 314, 315, 316, 317, 322, 328, 337, 354, 361, 362, 433, 434, 435, 436, 438, 439, 470, 497, 498, 499, 510, 513, 517, 518, 519, 520, 521, 522, 523, 525, 526, 527, 528, 529, 530, 532, 543, 555, 565, 567, 568], "compress": [0, 4, 7, 74, 75, 77, 78, 83, 96, 106, 125, 208, 209, 493, 497, 498, 499, 513, 517, 519, 520, 521, 523, 526, 543, 568], "optimum": [0, 13, 494, 497, 499, 517, 524, 547, 569, 570], "integr": [0, 6, 13, 14, 74, 85, 126, 133, 226, 244, 270, 470, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 493, 496, 497, 500, 503, 505, 506, 507, 508, 509, 510, 511, 512, 518, 520, 532, 536, 542, 543, 551, 560, 563, 571, 572], "hug": [0, 13, 494, 497, 500, 524, 525, 570], "face": [0, 13, 103, 127, 494, 497, 500, 511, 512, 524, 525, 546, 555, 570], "convers": [0, 2, 4, 10, 12, 13, 16, 74, 75, 76, 79, 80, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 116, 117, 119, 120, 121, 122, 123, 124, 129, 132, 212, 219, 224, 225, 345, 346, 350, 351, 419, 466, 467, 468, 470, 496, 497, 498, 499, 500, 502, 504, 505, 506, 508, 509, 510, 513, 515, 519, 520, 523, 524, 525, 527, 528, 529, 530, 531, 533, 534, 535, 536, 542, 543, 544, 546, 551, 555, 557, 558, 559, 569, 570, 572], "framework": [0, 2, 4, 5, 10, 15, 16, 73, 74, 78, 81, 96, 98, 99, 103, 105, 110, 111, 112, 114, 115, 117, 118, 119, 121, 124, 125, 128, 132, 208, 211, 216, 225, 226, 227, 330, 331, 473, 483, 492, 493, 497, 498, 499, 513, 514, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 530, 532, 533, 536, 549, 551, 570], "compat": [0, 13, 15, 16, 75, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 132, 208, 226, 242, 252, 258, 259, 319, 348, 483, 490, 491, 493, 496, 497, 500, 504, 522, 525, 530, 532, 547, 556, 567, 571], "can": [0, 2, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 16, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 135, 136, 148, 167, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 222, 223, 225, 226, 260, 303, 309, 310, 312, 313, 314, 315, 316, 317, 319, 320, 321, 329, 340, 344, 346, 348, 351, 353, 355, 358, 360, 367, 368, 369, 380, 385, 388, 389, 390, 391, 392, 398, 401, 402, 403, 404, 407, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 430, 431, 432, 434, 436, 437, 439, 441, 442, 443, 444, 465, 468, 469, 470, 471, 473, 476, 477, 478, 479, 480, 481, 482, 483, 488, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 565, 566, 567, 568, 569, 570, 571, 572], "load": [0, 2, 9, 10, 77, 79, 81, 95, 96, 98, 103, 106, 111, 115, 123, 124, 130, 131, 132, 208, 212, 213, 471, 493, 494, 497, 499, 501, 502, 505, 506, 508, 509, 510, 515, 519, 520, 525, 526, 527, 528, 530, 531, 532, 536, 539, 540, 541, 542, 543, 546, 547, 548, 556, 557, 562, 563, 566, 567], "directli": [0, 13, 14, 74, 80, 83, 85, 86, 111, 112, 113, 115, 116, 129, 132, 220, 226, 252, 333, 347, 348, 349, 444, 446, 447, 448, 449, 493, 498, 499, 502, 504, 513, 525, 527, 528, 529, 530, 532, 534, 536, 541, 542, 544, 546, 555, 556, 572], "convert": [0, 2, 4, 7, 12, 13, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 117, 118, 122, 124, 125, 128, 135, 209, 219, 224, 225, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 295, 296, 297, 298, 340, 345, 346, 350, 351, 368, 419, 467, 468, 470, 471, 477, 478, 479, 487, 493, 496, 497, 502, 503, 505, 506, 508, 509, 510, 511, 512, 513, 515, 517, 518, 519, 522, 523, 526, 533, 534, 536, 541, 542, 545, 546, 547, 551, 553, 556, 557, 559, 568, 570, 572], "format": [0, 2, 7, 12, 13, 16, 74, 78, 82, 87, 89, 90, 91, 92, 93, 94, 97, 98, 101, 102, 103, 105, 106, 107, 112, 122, 123, 124, 126, 127, 128, 129, 132, 226, 227, 330, 331, 336, 341, 345, 346, 348, 349, 350, 351, 367, 383, 384, 419, 453, 455, 456, 457, 458, 459, 464, 470, 471, 493, 497, 498, 501, 502, 503, 504, 505, 506, 508, 509, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 524, 525, 526, 527, 528, 532, 534, 540, 542, 544, 547, 551, 558, 559, 560, 561, 563, 570], "achiev": [0, 10, 77, 120, 126, 132, 135, 212, 493, 502, 513, 516, 517, 518, 519, 523, 525, 541, 542, 543, 548, 553, 554, 562, 566], "better": [0, 10, 12, 13, 78, 118, 135, 212, 222, 226, 316, 333, 337, 343, 367, 432, 493, 497, 498, 502, 513, 518, 519, 524, 526, 529, 532, 539, 541, 542, 543, 546, 564, 567], "perform": [0, 1, 2, 3, 13, 15, 75, 77, 80, 82, 83, 84, 85, 96, 100, 101, 106, 108, 111, 118, 120, 122, 123, 126, 127, 128, 129, 132, 133, 135, 136, 148, 211, 212, 213, 220, 225, 242, 244, 245, 246, 247, 248, 253, 254, 256, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 309, 311, 316, 319, 320, 321, 322, 323, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 340, 344, 345, 346, 347, 348, 349, 350, 351, 355, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 376, 377, 378, 388, 389, 390, 398, 401, 403, 404, 406, 407, 408, 409, 410, 413, 414, 415, 416, 417, 419, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 434, 435, 436, 439, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 471, 493, 495, 497, 498, 499, 500, 501, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 529, 532, 533, 534, 536, 537, 538, 542, 544, 547, 548, 549, 553, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569], "onnx": [0, 2, 7, 11, 12, 15, 16, 73, 74, 75, 78, 82, 83, 84, 85, 86, 95, 96, 118, 122, 124, 129, 132, 225, 226, 355, 371, 372, 433, 434, 436, 439, 470, 493, 502, 503, 505, 506, 508, 509, 513, 514, 515, 517, 518, 519, 520, 521, 522, 523, 525, 526, 532, 533, 549, 558, 565, 570], "pytorch": [0, 7, 12, 73, 75, 78, 80, 85, 86, 125, 129, 132, 343, 418, 463, 464, 468, 471, 477, 478, 479, 487, 493, 497, 499, 502, 513, 515, 517, 518, 519, 520, 521, 522, 525, 526, 532, 533, 534], "tensorflow": [0, 2, 7, 9, 10, 15, 73, 74, 75, 78, 80, 81, 82, 84, 85, 86, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 132, 135, 225, 226, 330, 331, 343, 377, 378, 382, 431, 465, 468, 470, 471, 493, 500, 502, 504, 505, 506, 508, 509, 511, 512, 513, 514, 515, 517, 518, 519, 520, 521, 522, 525, 526, 532, 533, 534, 549, 558, 570], "lite": [0, 2, 7, 73, 77, 85, 118, 129, 132, 225, 470, 502, 513, 515, 525, 532, 549, 558], "kera": [0, 7, 13, 77, 80, 85, 107, 111, 520, 525, 532], "paddlepaddl": [0, 2, 7, 15, 73, 77, 78, 82, 85, 118, 122, 129, 132, 266, 275, 283, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 363, 365, 366, 420, 470, 493, 502, 513, 514, 515, 525, 532, 549, 558], "ensur": [0, 10, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 406, 470, 482, 500, 502, 517, 523, 544, 553, 555, 572], "real": [0, 1, 7, 9, 10, 12, 96, 106, 111, 126, 129, 132, 220, 312, 333, 340, 362, 398, 432, 434, 436, 439, 446, 447, 471, 536, 539, 568, 571], "time": [0, 2, 6, 9, 10, 12, 13, 14, 74, 75, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 131, 132, 213, 220, 222, 225, 226, 312, 313, 315, 316, 317, 340, 341, 355, 370, 375, 382, 395, 398, 399, 413, 414, 415, 416, 417, 430, 431, 432, 433, 435, 440, 464, 470, 477, 478, 487, 488, 493, 498, 502, 509, 511, 512, 516, 517, 521, 522, 523, 524, 526, 529, 532, 533, 534, 536, 537, 539, 540, 541, 542, 543, 544, 545, 547, 550, 556, 558, 562, 563, 564, 565, 567, 569, 571], "server": [0, 9, 493, 496, 497, 502, 513, 569], "A": [0, 2, 9, 10, 11, 13, 14, 73, 77, 81, 83, 106, 115, 118, 121, 123, 124, 125, 127, 129, 130, 132, 148, 211, 213, 216, 219, 224, 226, 242, 244, 245, 246, 247, 248, 249, 250, 253, 254, 256, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310, 322, 323, 324, 339, 340, 341, 342, 343, 344, 345, 346, 350, 351, 355, 359, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 380, 381, 382, 386, 394, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 410, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 434, 436, 437, 439, 446, 447, 448, 449, 450, 466, 467, 468, 474, 476, 479, 490, 491, 494, 497, 502, 516, 518, 521, 524, 525, 529, 530, 533, 536, 539, 541, 548, 555, 559, 562, 564, 565, 566, 569, 571], "either": [0, 15, 74, 82, 95, 120, 122, 132, 320, 321, 323, 326, 344, 348, 367, 368, 385, 401, 413, 414, 415, 416, 417, 440, 468, 479, 493, 499, 500, 502, 504, 515, 525, 527, 536, 542, 543, 544, 546, 549, 553, 566, 570, 572], "local": [0, 2, 9, 13, 74, 109, 127, 130, 220, 407, 479, 493, 495, 496, 499, 513, 540, 548, 564], "runtim": [0, 2, 6, 8, 9, 10, 12, 14, 74, 75, 79, 80, 81, 82, 83, 84, 85, 103, 106, 112, 113, 114, 115, 116, 117, 118, 122, 129, 132, 135, 136, 148, 209, 210, 211, 212, 213, 225, 470, 471, 473, 475, 483, 486, 492, 493, 496, 497, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 518, 524, 525, 527, 528, 530, 531, 532, 533, 534, 535, 536, 538, 540, 542, 543, 544, 546, 548, 550, 553, 554, 555, 556, 558, 567, 568, 569, 572], "set": [0, 2, 6, 7, 9, 10, 12, 13, 73, 74, 76, 77, 78, 80, 81, 82, 85, 86, 91, 96, 98, 99, 106, 109, 111, 112, 113, 114, 115, 118, 119, 120, 122, 123, 124, 129, 130, 131, 132, 135, 136, 167, 210, 211, 212, 213, 216, 218, 219, 220, 221, 222, 224, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 274, 286, 303, 309, 314, 320, 321, 327, 328, 333, 340, 341, 348, 349, 352, 353, 355, 357, 360, 361, 362, 367, 368, 371, 372, 383, 384, 385, 390, 394, 398, 408, 409, 410, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 437, 440, 441, 451, 452, 453, 454, 455, 459, 461, 468, 470, 471, 475, 477, 478, 479, 482, 483, 492, 496, 498, 499, 500, 501, 502, 504, 509, 510, 512, 514, 515, 518, 519, 520, 523, 524, 525, 526, 528, 529, 530, 534, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 552, 554, 555, 559, 560, 567, 569, 570, 571, 572], "c": [0, 2, 10, 11, 14, 16, 31, 73, 74, 76, 77, 82, 83, 85, 111, 117, 119, 127, 129, 130, 131, 132, 216, 220, 252, 258, 259, 282, 319, 320, 321, 332, 333, 334, 335, 336, 337, 338, 344, 345, 346, 349, 350, 351, 361, 362, 368, 371, 372, 374, 393, 396, 405, 406, 407, 408, 411, 412, 413, 414, 415, 416, 417, 423, 430, 431, 432, 433, 434, 435, 436, 438, 439, 466, 471, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 492, 493, 494, 496, 497, 499, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 516, 529, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 553, 555, 556, 557, 558, 559, 560, 563, 566, 568, 569, 570, 571], "librari": [0, 2, 9, 13, 14, 15, 75, 83, 118, 120, 122, 131, 132, 135, 208, 211, 212, 213, 216, 217, 218, 219, 220, 469, 470, 472, 473, 477, 478, 479, 482, 486, 487, 496, 498, 500, 502, 514, 516, 518, 524, 534, 538, 542, 551, 561], "python": [0, 2, 10, 14, 15, 16, 49, 73, 74, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 118, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 278, 394, 398, 471, 476, 477, 478, 479, 480, 482, 490, 491, 492, 493, 494, 496, 497, 498, 499, 501, 502, 504, 505, 507, 508, 509, 510, 511, 512, 513, 514, 516, 518, 520, 521, 522, 526, 527, 529, 531, 532, 533, 534, 535, 536, 539, 540, 541, 542, 543, 545, 546, 547, 548, 549, 550, 551, 555, 556, 557, 558, 559, 560, 563, 566, 568, 571, 572], "bind": [0, 13, 118, 124, 127, 470, 502, 534, 539, 546], "common": [0, 12, 16, 117, 118, 122, 123, 124, 145, 148, 208, 211, 212, 213, 216, 224, 242, 262, 367, 454, 468, 496, 516, 518, 526, 534, 542, 543, 544, 547, 548, 562, 563, 566, 567], "api": [0, 2, 4, 9, 10, 31, 49, 73, 74, 75, 76, 80, 82, 83, 84, 85, 86, 87, 89, 96, 97, 100, 102, 103, 105, 107, 108, 109, 111, 112, 114, 116, 117, 118, 120, 122, 123, 126, 127, 128, 129, 131, 132, 135, 210, 211, 212, 213, 215, 216, 217, 219, 224, 225, 330, 331, 353, 470, 471, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 493, 494, 497, 498, 499, 500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 521, 522, 523, 524, 525, 526, 527, 528, 531, 532, 533, 534, 535, 536, 538, 539, 540, 542, 546, 547, 549, 554, 558, 563, 564, 566, 571, 572], "deliv": [0, 9, 76, 502, 556, 562, 566, 567], "The": [0, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 48, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 148, 163, 167, 171, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220, 222, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 357, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 410, 411, 412, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 434, 436, 437, 439, 441, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 466, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 479, 483, 486, 487, 490, 491, 492, 494, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 536, 537, 538, 539, 540, 541, 542, 543, 544, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 559, 560, 561, 562, 565, 566, 567, 568, 569, 570, 571, 572], "enabl": [0, 3, 6, 9, 10, 13, 14, 15, 74, 83, 85, 96, 103, 118, 119, 121, 123, 124, 127, 129, 130, 131, 132, 213, 216, 220, 369, 371, 372, 388, 468, 471, 477, 488, 490, 493, 496, 497, 502, 514, 515, 522, 524, 525, 526, 527, 532, 535, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 551, 552, 558, 561, 569, 572], "quick": [0, 12, 75, 127, 476, 477, 478, 479, 482, 487, 490, 491, 497, 499, 500, 513], "extern": [0, 74, 127, 219, 470, 493, 513, 549, 561], "resourc": [0, 13, 74, 125, 212, 213, 497, 513, 565, 566, 567], "To": [0, 2, 3, 4, 6, 9, 13, 14, 75, 78, 79, 80, 81, 82, 83, 84, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 122, 126, 128, 129, 130, 131, 132, 211, 212, 213, 216, 220, 222, 225, 226, 274, 337, 341, 355, 368, 394, 472, 473, 474, 476, 477, 478, 479, 480, 481, 482, 483, 487, 488, 490, 491, 492, 496, 497, 498, 499, 500, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 515, 516, 518, 519, 520, 522, 523, 524, 525, 527, 528, 529, 530, 531, 532, 533, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 548, 549, 550, 551, 553, 554, 555, 556, 557, 559, 560, 562, 563, 565, 567, 569, 571, 572], "more": [0, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 49, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 87, 89, 94, 98, 101, 103, 106, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 123, 125, 126, 127, 128, 130, 131, 132, 135, 167, 208, 213, 220, 222, 225, 226, 252, 260, 312, 313, 314, 315, 316, 317, 318, 322, 325, 353, 355, 358, 380, 381, 383, 384, 387, 399, 407, 418, 440, 441, 446, 447, 448, 449, 464, 468, 470, 471, 475, 476, 477, 478, 479, 480, 481, 482, 483, 486, 487, 488, 490, 491, 492, 493, 495, 497, 498, 499, 500, 504, 505, 506, 508, 509, 514, 516, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 553, 554, 555, 556, 557, 559, 560, 562, 563, 565, 566, 567, 569, 570, 571, 572], "how": [0, 4, 10, 12, 13, 73, 74, 75, 76, 78, 79, 81, 82, 85, 86, 90, 91, 93, 97, 99, 101, 103, 105, 106, 107, 108, 111, 113, 114, 115, 118, 119, 120, 122, 129, 131, 132, 135, 209, 212, 213, 222, 225, 312, 313, 314, 315, 316, 317, 320, 321, 330, 331, 333, 336, 344, 348, 349, 360, 367, 371, 372, 374, 375, 380, 381, 383, 384, 385, 396, 401, 410, 413, 414, 415, 416, 417, 418, 441, 460, 461, 462, 470, 471, 473, 476, 477, 478, 479, 482, 483, 486, 487, 490, 491, 493, 494, 495, 496, 497, 498, 500, 501, 502, 504, 513, 514, 518, 520, 523, 524, 525, 526, 528, 529, 530, 532, 534, 535, 536, 538, 540, 542, 543, 547, 548, 549, 554, 557, 559, 562, 568, 569, 570, 571], "read": [0, 2, 13, 77, 85, 104, 106, 108, 111, 112, 113, 115, 116, 117, 118, 127, 128, 129, 132, 353, 354, 357, 358, 470, 475, 481, 497, 499, 500, 502, 503, 504, 505, 506, 508, 509, 510, 513, 514, 525, 532, 534, 536, 539, 547, 548, 549, 553, 555, 557, 558, 560, 562, 563, 565, 569, 571], "document": [0, 2, 12, 13, 15, 49, 74, 78, 85, 89, 96, 106, 111, 115, 122, 123, 125, 126, 127, 128, 129, 131, 132, 133, 135, 208, 209, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 353, 358, 398, 433, 434, 470, 471, 473, 477, 478, 479, 483, 495, 498, 504, 516, 519, 520, 522, 526, 529, 530, 535, 539, 542, 543, 548, 549, 553, 556, 558, 562, 566, 572], "its": [0, 2, 3, 9, 10, 12, 73, 74, 75, 81, 82, 85, 111, 114, 117, 118, 127, 130, 132, 133, 135, 209, 211, 213, 216, 219, 220, 224, 254, 315, 316, 324, 337, 339, 340, 344, 367, 368, 390, 391, 418, 419, 453, 469, 471, 473, 478, 499, 515, 518, 519, 520, 524, 525, 526, 532, 534, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 551, 555, 556, 559, 560, 562, 564, 565, 567, 569], "core": [0, 2, 11, 12, 13, 15, 48, 49, 54, 73, 85, 112, 118, 121, 127, 130, 470, 471, 472, 473, 487, 488, 492, 496, 499, 500, 501, 502, 505, 506, 507, 508, 509, 510, 511, 512, 515, 516, 527, 528, 530, 531, 532, 536, 539, 541, 542, 543, 544, 545, 547, 553, 556, 558, 562, 563, 564, 565, 566, 571], "compon": [0, 2, 3, 9, 13, 14, 15, 49, 73, 75, 118, 133, 211, 446, 447, 448, 472, 475, 476, 480, 482, 487, 488, 490, 491, 501, 516, 534, 554, 557, 560], "along": [0, 77, 81, 82, 118, 127, 252, 258, 259, 274, 312, 313, 314, 315, 316, 317, 355, 367, 370, 371, 372, 373, 379, 383, 385, 386, 387, 388, 389, 392, 394, 395, 397, 398, 399, 401, 402, 407, 410, 413, 414, 415, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 434, 436, 439, 451, 460, 461, 462, 506, 508, 519, 522, 537, 543], "primari": [0, 10, 120, 502, 524, 545, 567], "also": [0, 9, 10, 11, 13, 75, 77, 81, 82, 83, 91, 95, 103, 106, 107, 111, 113, 114, 115, 118, 120, 121, 122, 127, 130, 131, 132, 208, 210, 213, 225, 226, 309, 314, 316, 319, 333, 337, 344, 346, 351, 355, 360, 367, 377, 378, 388, 401, 419, 432, 473, 474, 476, 477, 478, 479, 483, 488, 490, 491, 492, 496, 497, 498, 499, 500, 502, 504, 506, 514, 515, 516, 517, 518, 520, 524, 526, 536, 539, 541, 542, 543, 545, 548, 551, 553, 554, 555, 556, 557, 558, 560, 567, 568, 570, 571, 572], "nncf": [0, 13, 14, 74, 75, 125, 128, 135, 208, 225, 471, 493, 497, 498, 499, 517, 521, 524, 525, 547], "tool": [0, 2, 4, 10, 12, 13, 14, 73, 74, 77, 78, 80, 81, 82, 83, 84, 85, 86, 91, 99, 106, 108, 111, 112, 113, 114, 115, 119, 122, 124, 125, 127, 129, 211, 212, 469, 470, 471, 475, 476, 478, 479, 480, 494, 496, 497, 498, 499, 500, 501, 505, 506, 508, 509, 510, 516, 518, 519, 522, 524, 525, 526, 532, 539, 546, 547, 549, 553, 565, 568, 569], "enhanc": [0, 13, 472, 493, 497, 518, 524, 553], "get": [0, 2, 9, 12, 13, 74, 76, 77, 78, 95, 96, 97, 99, 100, 103, 105, 108, 110, 111, 118, 119, 120, 122, 123, 124, 127, 130, 131, 132, 135, 136, 208, 212, 213, 218, 219, 220, 225, 323, 326, 349, 355, 367, 399, 451, 463, 465, 473, 476, 477, 478, 479, 482, 483, 490, 491, 493, 494, 495, 496, 499, 500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 516, 517, 518, 519, 520, 521, 522, 526, 529, 535, 536, 540, 541, 542, 543, 545, 547, 549, 550, 551, 553, 555, 560, 562, 564, 569, 570], "boost": [0, 12, 83, 367, 493, 542], "minim": [0, 13, 85, 125, 138, 468, 493, 496, 497, 502, 515, 518, 522, 524, 525, 542, 543, 545, 556, 558, 562, 566, 568], "accuraci": [0, 4, 10, 12, 13, 74, 75, 79, 106, 117, 125, 135, 343, 471, 498, 500, 517, 518, 519, 520, 521, 522, 524, 526, 537, 542, 545, 548, 554, 568], "drop": [0, 11, 13, 79, 125, 348, 349, 473, 477, 523, 542, 543, 564], "notebook": [0, 14, 75, 80, 86, 126, 477, 478, 479, 483, 487, 493, 494, 495, 497, 500, 518, 539, 547, 569], "jupyt": [0, 14, 75, 80, 86, 126, 477, 478, 479, 487, 494, 495, 518], "demonstr": [0, 13, 86, 106, 108, 127, 129, 132, 133, 135, 210, 219, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 529, 533, 536, 542, 543, 548, 549, 551, 569, 571], "kei": [0, 9, 14, 16, 53, 83, 95, 96, 111, 114, 118, 120, 122, 130, 132, 148, 213, 341, 440, 473, 476, 490, 498, 502, 529, 535, 541, 545, 547, 548, 555, 556, 572], "scalabl": [0, 13, 15, 493, 515, 542, 554, 555, 556, 562, 564, 566], "via": [0, 8, 9, 74, 75, 84, 112, 113, 115, 116, 117, 135, 148, 163, 211, 212, 213, 220, 222, 223, 309, 325, 473, 476, 477, 479, 482, 483, 490, 491, 492, 493, 498, 504, 515, 518, 535, 539, 540, 541, 542, 544, 545, 551, 553, 555, 558, 562, 566], "serv": [0, 9, 13, 14, 123, 127, 221, 224, 432, 493, 497, 529, 545, 561, 562, 564, 566, 567, 569], "microservic": [0, 493], "extens": [0, 2, 6, 8, 13, 73, 77, 78, 80, 103, 106, 111, 112, 113, 115, 116, 119, 120, 123, 124, 125, 126, 130, 131, 213, 216, 220, 470, 497, 500, 502, 524, 526, 527, 535, 547, 551, 553, 565, 568], "conveni": [0, 9, 14, 81, 118, 123, 125, 504, 513, 525, 533, 534, 563], "environ": [0, 6, 9, 12, 14, 80, 83, 91, 96, 98, 99, 100, 115, 122, 125, 127, 220, 471, 473, 482, 483, 486, 492, 493, 497, 498, 499, 500, 502, 504, 516, 518, 524, 532, 539, 540, 545, 549, 551, 572], "them": [0, 13, 73, 74, 75, 76, 80, 81, 84, 85, 108, 109, 114, 115, 118, 122, 124, 125, 126, 128, 129, 132, 135, 209, 210, 211, 212, 220, 222, 224, 225, 242, 286, 309, 314, 317, 318, 323, 324, 326, 368, 372, 375, 451, 454, 469, 470, 471, 476, 477, 478, 479, 480, 482, 487, 488, 490, 491, 493, 496, 500, 502, 504, 516, 518, 528, 530, 532, 533, 535, 536, 538, 539, 541, 542, 544, 545, 546, 549, 550, 551, 553, 556, 561, 562, 572], "dataset": [0, 11, 82, 92, 101, 103, 106, 111, 125, 126, 128, 498, 503, 518, 520, 521, 524], "manag": [0, 2, 13, 102, 125, 127, 221, 222, 223, 473, 474, 484, 485, 489, 493, 495, 497, 514, 515, 518, 542, 547, 549, 563, 566, 569], "datumaro": [0, 125], "build": [0, 3, 10, 13, 14, 15, 65, 75, 76, 77, 83, 109, 118, 122, 125, 129, 131, 132, 133, 135, 213, 216, 313, 371, 372, 471, 475, 476, 477, 478, 479, 481, 482, 483, 488, 490, 491, 496, 500, 502, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 525, 547, 553, 570], "transform": [0, 12, 13, 81, 83, 88, 96, 98, 102, 103, 106, 109, 110, 111, 117, 118, 120, 121, 125, 126, 129, 133, 134, 136, 208, 209, 212, 213, 214, 221, 222, 223, 319, 323, 326, 336, 348, 349, 360, 361, 362, 374, 393, 395, 396, 403, 404, 406, 419, 446, 454, 497, 498, 500, 501, 519, 520, 521, 522, 524, 525, 529, 542, 543, 551, 557, 561, 569], "analyz": [0, 2, 108, 125, 213, 330, 331], "plai": [0, 9, 127, 371, 372, 567], "vital": 0, "role": [0, 2, 9, 74], "growth": [0, 541], "contribut": [0, 3, 14, 216, 518, 562], "follow": [0, 4, 6, 9, 10, 11, 13, 14, 15, 16, 48, 74, 75, 78, 80, 81, 82, 84, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 135, 148, 167, 208, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 225, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 260, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 273, 276, 277, 279, 280, 284, 287, 288, 289, 290, 293, 294, 295, 296, 297, 298, 299, 300, 301, 305, 306, 307, 313, 314, 315, 316, 322, 323, 325, 326, 327, 328, 330, 331, 333, 335, 336, 337, 338, 340, 341, 342, 343, 346, 349, 351, 355, 363, 364, 365, 366, 367, 369, 370, 371, 372, 374, 375, 379, 380, 381, 382, 383, 384, 390, 393, 394, 395, 396, 398, 399, 403, 404, 405, 406, 411, 412, 413, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 435, 437, 440, 446, 447, 448, 449, 451, 454, 455, 459, 460, 461, 462, 464, 466, 467, 468, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 495, 496, 498, 499, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 522, 523, 524, 525, 526, 528, 529, 530, 533, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 553, 554, 557, 560, 561, 563, 564, 565, 566, 570, 571, 572], "channel": [0, 2, 13, 77, 94, 101, 106, 108, 111, 136, 208, 254, 312, 313, 314, 315, 316, 317, 318, 319, 324, 325, 332, 345, 346, 350, 351, 393, 403, 404, 405, 406, 407, 408, 409, 410, 415, 416, 417, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 502, 505, 506, 508, 509, 524, 542, 547, 557, 558, 559, 560], "github": [0, 12, 13, 14, 74, 76, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 108, 109, 110, 111, 125, 126, 127, 128, 474, 475, 477, 478, 479, 483, 495, 496, 500, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 518, 519, 521, 524, 548, 565], "issu": [0, 14, 75, 81, 83, 96, 103, 111, 113, 114, 115, 117, 118, 127, 418, 468, 469, 492, 495, 496, 526, 543, 546, 565], "discuss": [0, 83, 418, 495, 496, 556], "pull": [0, 95, 567], "request": [0, 2, 6, 9, 10, 13, 15, 84, 118, 133, 212, 213, 216, 471, 501, 502, 503, 505, 506, 509, 510, 511, 512, 516, 529, 533, 536, 539, 541, 542, 543, 544, 547, 548, 554, 555, 562, 564, 565, 566, 567, 569], "blog": 0, "forum": [0, 12, 83], "video": [0, 10, 13, 226, 474, 493, 502, 504, 529, 539, 541, 550, 555, 556, 566], "ha": [0, 1, 4, 6, 12, 13, 74, 75, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 130, 132, 135, 136, 148, 167, 210, 212, 213, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 242, 246, 247, 249, 250, 251, 253, 254, 255, 256, 257, 260, 262, 265, 268, 269, 270, 271, 272, 273, 276, 277, 284, 287, 289, 290, 293, 294, 296, 302, 304, 309, 310, 311, 314, 317, 318, 320, 321, 330, 331, 340, 353, 355, 358, 360, 364, 367, 368, 370, 375, 376, 379, 380, 381, 382, 385, 387, 388, 394, 397, 400, 401, 402, 410, 413, 414, 415, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 437, 442, 444, 446, 447, 448, 449, 453, 463, 464, 465, 467, 468, 473, 474, 475, 492, 493, 496, 497, 498, 502, 506, 507, 508, 509, 510, 511, 512, 514, 515, 522, 523, 524, 526, 529, 533, 535, 536, 539, 542, 543, 544, 545, 548, 550, 551, 553, 557, 559, 560, 563, 565, 568, 570], "been": [0, 6, 13, 14, 74, 75, 76, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 226, 321, 340, 353, 358, 473, 474, 475, 492, 493, 498, 504, 508, 509, 510, 511, 512, 524, 536, 542, 544, 548, 557, 558, 565, 568], "emploi": [0, 9, 13, 500], "across": [0, 127, 327, 328, 355, 405, 408, 440, 451, 452, 453, 454, 455, 456, 457, 458, 459, 471, 493, 497, 500, 543, 547, 548, 550, 567], "industri": [0, 9, 12, 539], "healthcar": [0, 9], "retail": [0, 9, 13, 15, 127, 508], "safeti": [0, 542, 553], "secur": [0, 3, 9, 13, 14, 15, 73, 125, 496], "transport": 0, "differ": [0, 9, 10, 11, 12, 13, 14, 77, 78, 81, 82, 83, 85, 87, 89, 94, 101, 103, 106, 108, 109, 111, 113, 115, 118, 119, 120, 122, 124, 127, 129, 131, 132, 133, 135, 136, 148, 208, 212, 213, 220, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 248, 260, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 309, 311, 320, 321, 338, 340, 341, 344, 348, 349, 355, 361, 362, 363, 365, 366, 367, 368, 369, 398, 420, 430, 431, 432, 434, 436, 439, 446, 447, 448, 449, 466, 467, 468, 471, 475, 477, 478, 479, 492, 494, 497, 498, 500, 502, 503, 511, 512, 514, 515, 523, 524, 525, 527, 528, 530, 532, 535, 536, 537, 538, 539, 541, 542, 543, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 567, 568, 569, 571], "sector": [0, 9], "success": [0, 78, 128, 129, 220, 471, 474, 480, 482, 487, 526, 565], "stori": [0, 471], "page": [0, 7, 8, 9, 13, 15, 75, 81, 83, 112, 113, 114, 115, 116, 118, 119, 132, 353, 358, 470, 471, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 497, 498, 502, 504, 518, 519, 525, 526, 527, 528, 529, 530, 531, 536, 539, 549], "benchmark": [1, 6, 10, 12, 13, 74, 75, 87, 89, 103, 135, 471, 493, 501, 524, 536, 547, 555], "contain": [1, 2, 7, 9, 10, 13, 14, 15, 48, 81, 84, 97, 98, 100, 102, 103, 105, 106, 107, 108, 109, 110, 115, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 209, 210, 211, 213, 216, 218, 219, 220, 224, 226, 242, 309, 310, 319, 320, 321, 322, 324, 327, 328, 330, 331, 332, 344, 348, 367, 371, 372, 375, 382, 385, 388, 390, 398, 400, 401, 402, 406, 410, 412, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 440, 441, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 463, 464, 465, 468, 477, 478, 479, 483, 496, 501, 502, 504, 514, 519, 520, 524, 526, 529, 530, 533, 534, 542, 544, 548, 551, 569, 570], "result": [1, 2, 3, 9, 10, 11, 12, 13, 74, 79, 81, 83, 95, 100, 104, 106, 108, 111, 117, 118, 120, 121, 122, 126, 127, 128, 129, 130, 132, 136, 148, 163, 167, 171, 208, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 309, 311, 312, 316, 317, 318, 320, 321, 328, 331, 340, 341, 347, 348, 349, 355, 360, 363, 364, 365, 366, 367, 368, 369, 375, 376, 377, 378, 386, 391, 398, 399, 403, 404, 405, 410, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 440, 446, 447, 448, 449, 452, 453, 454, 455, 459, 461, 466, 467, 468, 471, 497, 498, 499, 500, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 518, 519, 523, 524, 525, 526, 527, 529, 530, 533, 535, 536, 537, 539, 541, 542, 543, 545, 550, 551, 552, 554, 555, 556, 558, 562, 563, 564, 566, 569, 570], "from": [1, 2, 4, 9, 10, 11, 13, 14, 15, 16, 73, 74, 75, 76, 78, 79, 80, 82, 84, 85, 87, 89, 90, 92, 94, 95, 96, 98, 99, 101, 103, 104, 105, 106, 108, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 130, 131, 133, 135, 148, 167, 208, 209, 210, 211, 212, 213, 216, 217, 218, 219, 220, 221, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 249, 250, 251, 252, 254, 255, 257, 259, 262, 271, 274, 277, 286, 294, 295, 296, 297, 298, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 323, 324, 325, 326, 330, 331, 332, 335, 336, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 360, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 392, 394, 396, 397, 398, 399, 402, 408, 409, 413, 414, 415, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 434, 436, 437, 439, 440, 441, 444, 445, 446, 447, 448, 449, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 470, 471, 473, 475, 480, 488, 492, 493, 497, 498, 499, 500, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 535, 536, 537, 540, 541, 542, 543, 545, 546, 547, 549, 550, 551, 552, 555, 557, 560, 561, 564, 565, 566, 567, 569, 570, 571, 572], "openvino": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 48, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 90, 99, 101, 102, 103, 105, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 122, 123, 124, 126, 130, 134, 136, 145, 208, 209, 210, 212, 213, 214, 215, 217, 218, 219, 220, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 344, 401, 440, 468, 472, 495, 497, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 533, 535, 536, 538, 540, 541, 542, 543, 544, 545, 548, 554, 556, 559, 560, 561, 562, 563, 564, 565, 566, 568, 571, 572], "glossari": 1, "term": [1, 15, 84, 127, 226, 435, 475, 514, 517, 519, 521, 524, 529, 533, 541, 542, 543], "legal": [1, 9, 10, 11, 12], "trademark": [1, 3, 13, 15], "statement": [1, 572], "telemetri": 1, "detail": [1, 2, 3, 6, 8, 9, 10, 12, 13, 14, 15, 49, 75, 77, 78, 79, 80, 82, 83, 85, 112, 113, 114, 115, 116, 118, 119, 120, 122, 127, 129, 130, 131, 132, 135, 148, 208, 213, 216, 225, 244, 245, 246, 247, 248, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 265, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 349, 350, 351, 352, 353, 355, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 471, 472, 475, 477, 492, 494, 498, 499, 500, 502, 513, 514, 515, 516, 519, 520, 525, 526, 527, 528, 529, 530, 531, 532, 534, 539, 542, 543, 544, 546, 547, 549, 550, 551, 554, 555, 557, 558, 565, 566, 570, 572], "data": [1, 2, 9, 10, 12, 13, 15, 68, 73, 78, 79, 81, 82, 84, 88, 97, 98, 99, 101, 103, 104, 105, 106, 108, 111, 113, 115, 117, 118, 120, 122, 123, 124, 126, 127, 132, 135, 167, 208, 209, 212, 213, 218, 224, 225, 226, 244, 245, 248, 252, 254, 256, 258, 259, 260, 261, 262, 266, 275, 278, 280, 281, 282, 283, 285, 286, 291, 292, 299, 300, 303, 306, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 347, 348, 349, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 443, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 471, 493, 496, 497, 498, 499, 500, 502, 505, 506, 508, 509, 510, 511, 512, 516, 522, 523, 524, 526, 528, 530, 533, 535, 540, 541, 545, 546, 547, 549, 550, 551, 552, 553, 555, 560, 561, 563, 564, 565, 566, 568, 569, 571], "collect": [1, 2, 15, 73, 74, 86, 93, 110, 135, 148, 213, 310, 375, 452, 453, 454, 455, 459, 494, 502, 504, 505, 506, 508, 509, 526, 541, 548, 551, 564, 566, 567], "case": [1, 7, 10, 11, 12, 14, 75, 79, 80, 81, 82, 84, 85, 86, 98, 106, 110, 112, 113, 115, 116, 118, 122, 123, 124, 126, 129, 132, 167, 208, 212, 213, 216, 219, 220, 222, 244, 254, 260, 286, 312, 313, 314, 315, 316, 317, 318, 319, 348, 349, 355, 358, 367, 368, 371, 372, 375, 379, 380, 385, 388, 389, 390, 391, 392, 398, 410, 411, 412, 413, 414, 415, 416, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 434, 436, 437, 439, 440, 441, 446, 447, 448, 449, 463, 464, 468, 472, 476, 477, 478, 479, 480, 482, 487, 488, 490, 491, 493, 494, 497, 498, 499, 502, 513, 516, 517, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 533, 534, 535, 536, 537, 539, 540, 541, 542, 543, 544, 545, 550, 551, 553, 555, 556, 557, 559, 560, 562, 563, 565, 566, 567, 568, 569, 570, 571], "studi": [1, 86], "ar": [1, 2, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 89, 93, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 136, 138, 141, 143, 148, 163, 167, 208, 209, 210, 211, 212, 213, 216, 218, 220, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 266, 274, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 357, 358, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 382, 383, 384, 386, 387, 388, 389, 390, 392, 393, 394, 395, 396, 398, 400, 401, 402, 403, 404, 406, 408, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 439, 440, 441, 446, 447, 448, 449, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 475, 477, 478, 479, 481, 482, 483, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 508, 509, 511, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 555, 556, 557, 559, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572], "articl": [1, 2, 73, 75, 77, 78, 79, 80, 82, 84, 85, 87, 90, 91, 102, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 130, 226, 245, 247, 248, 250, 251, 253, 254, 256, 261, 262, 320, 321, 348, 349, 401, 403, 404, 415, 438, 504, 514, 525, 527, 532, 534, 535, 536, 537, 539, 541, 542, 546, 548, 549, 554, 555, 556, 560, 569, 570], "about": [1, 9, 10, 13, 15, 75, 78, 79, 82, 83, 84, 87, 89, 94, 98, 101, 103, 106, 111, 115, 118, 120, 122, 123, 125, 128, 130, 131, 132, 133, 134, 135, 208, 210, 213, 220, 320, 321, 415, 454, 455, 456, 457, 458, 459, 471, 476, 477, 478, 479, 480, 481, 482, 483, 486, 487, 488, 490, 491, 497, 502, 505, 506, 508, 509, 513, 514, 515, 518, 519, 524, 525, 526, 529, 530, 532, 533, 535, 536, 542, 543, 547, 548, 549, 551, 553, 557, 566, 571], "world": [1, 12, 471], "exampl": [1, 2, 6, 9, 10, 12, 13, 49, 75, 77, 80, 81, 82, 83, 84, 85, 96, 103, 106, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 128, 129, 132, 135, 136, 148, 163, 167, 209, 210, 212, 213, 216, 217, 218, 219, 220, 221, 222, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 472, 473, 476, 477, 478, 479, 481, 482, 487, 488, 490, 491, 492, 499, 500, 507, 514, 516, 517, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 545, 546, 548, 551, 552, 553, 554, 555, 556, 559, 560, 562, 564, 565, 566, 567, 568, 570, 571, 572], "usag": [1, 4, 6, 9, 10, 12, 13, 83, 118, 121, 131, 135, 136, 220, 222, 398, 497, 509, 529, 535, 541, 542, 543, 544, 551, 552, 560, 569, 570], "descript": [2, 9, 10, 12, 13, 77, 78, 83, 85, 106, 118, 122, 123, 124, 127, 130, 132, 135, 209, 224, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 477, 478, 479, 482, 496, 502, 503, 505, 506, 508, 509, 510, 511, 512, 519, 522, 526, 539, 541, 542, 543, 544, 545, 546], "program": [2, 9, 13, 75, 130, 278, 282, 471, 477, 478, 479, 487, 508, 515, 516, 520, 526, 530, 541, 544, 545, 564], "interfac": [2, 48, 55, 83, 127, 128, 211, 212, 215, 217, 218, 219, 481, 493, 497, 498, 502, 522, 542, 544, 552, 559, 572], "avx": [2, 12, 542], "advanc": [2, 13, 74, 83, 106, 125, 126, 128, 220, 497, 517, 519, 521, 522, 523, 542, 560, 568, 572], "vector": [2, 129, 131, 132, 135, 210, 218, 219, 337, 367, 368, 369, 375, 451, 542, 544, 548, 551, 569, 571], "cldnn": [2, 213], "comput": [2, 6, 10, 13, 15, 75, 78, 115, 118, 127, 135, 210, 212, 213, 219, 252, 278, 280, 281, 282, 285, 291, 308, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 325, 327, 328, 332, 333, 340, 348, 349, 355, 367, 368, 380, 392, 398, 405, 412, 413, 414, 415, 416, 417, 432, 433, 435, 438, 451, 460, 461, 462, 463, 464, 465, 472, 473, 479, 482, 496, 498, 505, 506, 508, 509, 512, 518, 519, 521, 523, 524, 530, 541, 542, 546, 547, 552, 554, 556, 558, 559, 560, 564, 567, 568], "cli": [2, 77, 78, 79, 81, 82, 83, 84, 85, 112, 125, 126, 128, 224, 498, 499, 500, 505, 508, 509, 511, 512, 526, 527, 528, 530, 531, 532, 533], "command": [2, 4, 10, 14, 75, 77, 78, 80, 81, 82, 83, 85, 86, 87, 89, 92, 95, 96, 97, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 122, 127, 129, 130, 211, 216, 473, 474, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 492, 496, 498, 499, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 518, 519, 522, 524, 525, 526, 528, 532, 533, 539, 540, 541, 544, 546, 549, 555, 558, 570], "line": [2, 4, 10, 13, 77, 78, 80, 81, 82, 85, 86, 87, 89, 96, 97, 98, 99, 101, 103, 105, 106, 107, 108, 109, 111, 112, 117, 118, 122, 127, 130, 148, 477, 478, 479, 480, 492, 493, 496, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 518, 525, 526, 532, 533, 539, 540, 555, 558, 570, 572], "cnn": [2, 12, 13, 97, 106, 112, 119, 564], "convolut": [2, 7, 8, 10, 13, 78, 81, 96, 97, 106, 118, 122, 135, 148, 167, 171, 208, 209, 216, 222, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 312, 314, 315, 316, 317, 318, 328, 375, 415, 518, 543, 555], "central": [2, 514], "process": [2, 4, 9, 10, 12, 13, 74, 78, 81, 85, 87, 89, 108, 111, 112, 113, 114, 115, 116, 118, 124, 208, 209, 213, 219, 220, 223, 224, 226, 333, 341, 344, 345, 346, 347, 348, 349, 350, 351, 360, 361, 362, 368, 398, 401, 402, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 446, 447, 448, 449, 451, 452, 453, 454, 455, 456, 457, 458, 459, 471, 472, 479, 488, 497, 498, 499, 500, 501, 502, 503, 505, 508, 510, 511, 512, 518, 521, 522, 523, 524, 526, 529, 534, 535, 536, 537, 539, 541, 542, 543, 544, 545, 547, 548, 550, 552, 554, 556, 563, 564, 566, 567, 569, 571], "unit": [2, 13, 211, 220, 245, 247, 248, 254, 256, 446, 447, 448, 472, 516, 539, 547], "cv": [2, 99, 516], "vision": [2, 6, 77, 113, 126, 472, 496, 504, 512, 528, 529, 547, 559, 560], "dl": [2, 12, 15, 74, 209, 517, 520, 521, 522, 536, 542], "dll": [2, 83, 500, 502, 515], "dynam": [2, 6, 8, 10, 13, 81, 83, 84, 103, 114, 127, 131, 132, 133, 326, 353, 358, 401, 440, 454, 455, 459, 471, 497, 498, 502, 503, 515, 524, 526, 529, 533, 535, 539, 541, 551, 554, 557, 567, 570, 572], "link": [2, 9, 12, 14, 95, 106, 111, 113, 115, 120, 122, 127, 132, 216, 226, 227, 341, 471, 477, 478, 479, 482, 493, 514, 515, 551], "dnn": [2, 109], "elu": [2, 7, 8, 132, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 522], "exponenti": [2, 245, 246, 256, 340, 468], "linear": [2, 7, 77, 109, 132, 208, 245, 247, 248, 254, 256, 260, 347, 348, 349, 361, 362, 367, 368, 403, 404, 420, 451, 522, 524], "rectif": 2, "fcn": [2, 106], "fulli": [2, 13, 15, 74, 84, 96, 106, 118, 122, 129, 132, 133, 208, 212, 213, 227, 502, 524, 525, 529, 533, 539, 543, 546, 551, 556, 559, 561, 567], "fp": [2, 9, 502, 511, 512], "float": [2, 79, 96, 130, 131, 132, 208, 224, 225, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 260, 261, 262, 270, 290, 302, 303, 304, 312, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 361, 362, 368, 369, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 414, 415, 416, 417, 419, 420, 430, 431, 432, 433, 434, 435, 436, 438, 439, 440, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 518, 524, 543, 547, 560, 568, 571], "point": [2, 79, 81, 103, 118, 124, 127, 129, 130, 208, 225, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 260, 261, 262, 302, 303, 304, 312, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 360, 361, 362, 368, 369, 388, 389, 390, 392, 393, 401, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 414, 415, 416, 417, 419, 420, 430, 431, 432, 433, 434, 435, 436, 438, 439, 440, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 468, 471, 500, 504, 518, 524, 537, 543, 545, 547, 555, 560, 562, 565, 568, 570, 571], "gcc": [2, 15, 474, 476, 477, 480, 490, 491], "gnu": [2, 15, 473, 515, 565], "compil": [2, 9, 10, 13, 15, 74, 77, 80, 83, 85, 112, 113, 114, 115, 116, 127, 129, 130, 132, 133, 210, 211, 213, 216, 217, 219, 472, 473, 476, 477, 478, 479, 481, 488, 493, 500, 502, 503, 510, 511, 512, 513, 515, 522, 523, 524, 525, 532, 534, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 560, 562, 563, 565, 566, 567], "graphic": [2, 15, 476, 477, 479, 480, 481, 482, 487, 488, 490, 491, 496, 497, 504, 539, 543, 572], "hd": [2, 15], "high": [2, 10, 13, 14, 120, 208, 220, 471, 497, 502, 518, 524, 535, 539, 542, 544, 545, 546, 554, 562, 564, 566, 567, 568], "definit": [2, 9, 13, 84, 106, 132, 137, 208, 216, 220, 314, 318, 340, 542], "ir": [2, 10, 13, 77, 78, 79, 80, 81, 82, 85, 87, 89, 95, 99, 105, 106, 107, 108, 112, 113, 114, 115, 116, 118, 122, 123, 124, 127, 129, 130, 208, 209, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 309, 341, 355, 360, 470, 488, 502, 504, 505, 506, 508, 509, 513, 514, 515, 517, 518, 519, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 534, 535, 539, 542, 543, 546, 547, 549, 551, 565, 568, 570, 572], "intermedi": [2, 13, 77, 78, 81, 83, 85, 87, 88, 89, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 114, 115, 117, 126, 127, 209, 213, 224, 226, 362, 367, 434, 436, 439, 463, 464, 465, 470, 502, 505, 506, 508, 509, 517, 519, 520, 522, 523, 532, 535, 536, 545, 555, 558, 563, 567, 569], "represent": [2, 11, 77, 78, 81, 83, 85, 87, 88, 89, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 114, 115, 119, 120, 123, 124, 127, 129, 132, 208, 212, 213, 219, 220, 224, 254, 256, 295, 296, 297, 298, 338, 341, 470, 498, 499, 502, 505, 506, 508, 509, 517, 519, 520, 521, 522, 523, 525, 526, 527, 529, 532, 535, 542, 547, 549, 558, 563, 572], "jit": [2, 80, 85, 96, 114, 130, 502, 516, 529, 532, 572], "just": [2, 13, 83, 114, 118, 120, 121, 122, 123, 124, 125, 132, 211, 212, 222, 226, 368, 385, 476, 480, 482, 487, 488, 490, 491, 493, 494, 495, 502, 525, 526, 537, 538, 540, 546, 550, 557, 559, 565, 566, 567], "jtag": 2, "joint": [2, 95], "test": [2, 3, 8, 9, 10, 12, 14, 83, 88, 90, 92, 94, 98, 110, 111, 114, 126, 127, 133, 211, 302, 471, 483, 500, 502, 529, 539, 546, 565, 567], "action": [2, 9, 13, 222, 539, 541, 555], "group": [2, 6, 8, 81, 122, 127, 135, 136, 209, 216, 220, 226, 315, 316, 317, 318, 319, 332, 393, 406, 420, 471, 483, 497, 498, 502, 524, 541, 542, 543, 564], "lpr": 2, "licens": [2, 13, 15, 76], "plate": 2, "recognit": [2, 13, 76, 100, 106, 502, 569], "lrn": [2, 7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "respons": [2, 9, 12, 118, 127, 135, 136, 148, 208, 210, 213, 355, 405, 407, 524, 538, 539, 542, 544, 556], "normal": [2, 7, 8, 78, 81, 82, 101, 108, 117, 118, 122, 256, 319, 320, 321, 326, 329, 330, 331, 332, 338, 340, 344, 377, 378, 388, 390, 398, 403, 404, 405, 406, 407, 408, 409, 410, 441, 451, 452, 453, 490, 502, 539, 542, 545, 555, 557, 561, 563, 564], "map": [2, 11, 13, 81, 97, 108, 117, 123, 208, 209, 213, 220, 221, 287, 302, 303, 304, 309, 312, 313, 315, 316, 317, 319, 320, 321, 324, 325, 326, 331, 332, 333, 335, 336, 337, 338, 344, 347, 348, 349, 355, 360, 371, 372, 375, 401, 413, 414, 415, 416, 417, 446, 447, 448, 449, 502, 526, 533, 535, 544, 551, 554, 555, 556, 562, 565], "mean": [2, 7, 9, 10, 11, 13, 77, 78, 85, 96, 100, 101, 102, 104, 106, 115, 117, 118, 122, 127, 171, 208, 209, 221, 222, 226, 252, 259, 274, 286, 309, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 326, 327, 328, 329, 330, 331, 337, 338, 344, 347, 353, 354, 355, 356, 358, 360, 361, 362, 369, 371, 372, 373, 376, 377, 378, 379, 381, 384, 385, 386, 388, 390, 394, 398, 399, 401, 402, 403, 404, 406, 407, 408, 409, 410, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 451, 452, 453, 455, 456, 457, 458, 459, 460, 461, 462, 488, 494, 498, 500, 502, 513, 514, 515, 518, 519, 520, 524, 526, 529, 530, 533, 535, 538, 539, 540, 541, 542, 543, 545, 546, 547, 551, 554, 555, 557, 558, 559, 564, 568, 570], "averag": [2, 7, 10, 13, 319, 332, 335, 336, 337, 411, 413, 414, 502, 511, 512, 524, 541, 567], "precis": [2, 10, 11, 12, 13, 81, 133, 134, 136, 137, 138, 139, 143, 148, 163, 167, 208, 212, 224, 226, 302, 303, 304, 309, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 331, 334, 335, 336, 337, 339, 340, 341, 348, 349, 360, 368, 375, 388, 389, 390, 392, 401, 405, 419, 431, 440, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 466, 467, 468, 497, 498, 499, 502, 512, 518, 520, 521, 523, 524, 536, 539, 543, 545, 547, 548, 553, 554, 557, 563, 567], "onednn": [2, 13, 213, 542], "oneapi": [2, 473, 540], "mo": [2, 75, 78, 79, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 224, 525, 532], "convert_model": [2, 77, 78, 79, 80, 81, 82, 84, 85, 111, 112, 113, 114, 115, 116, 505, 508, 509, 511, 512, 513, 515, 526, 527, 528, 529, 530, 531, 532, 533, 536], "legaci": [2, 6, 13, 14, 15, 75, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 127, 132, 473, 500, 525, 532, 539, 541, 566], "mvn": [2, 8, 135, 185, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "varianc": [2, 13, 96, 320, 321, 327, 328, 329, 403, 404, 406, 408, 409, 524], "ncdhw": [2, 7, 8, 411, 412], "number": [2, 7, 9, 12, 50, 51, 52, 53, 55, 58, 59, 60, 65, 68, 69, 70, 74, 81, 103, 106, 109, 115, 118, 120, 121, 122, 123, 126, 127, 129, 130, 132, 212, 220, 222, 224, 226, 242, 244, 245, 252, 258, 259, 260, 309, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 347, 348, 349, 355, 369, 370, 373, 375, 377, 378, 380, 381, 383, 384, 387, 393, 394, 397, 398, 399, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 413, 414, 415, 416, 417, 420, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 465, 474, 482, 493, 499, 500, 509, 511, 512, 516, 519, 522, 523, 524, 529, 530, 533, 536, 537, 539, 540, 541, 542, 543, 545, 547, 548, 551, 553, 554, 555, 559, 562, 564, 565, 566, 570, 571], "imag": [2, 7, 9, 10, 12, 13, 75, 76, 82, 87, 89, 92, 94, 96, 97, 101, 105, 111, 113, 118, 122, 226, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 338, 344, 345, 346, 347, 348, 349, 350, 351, 375, 453, 471, 473, 476, 477, 478, 479, 482, 487, 490, 491, 496, 497, 498, 499, 501, 502, 504, 505, 506, 508, 510, 514, 519, 522, 524, 529, 535, 537, 539, 545, 549, 551, 555, 557, 558, 559, 561, 572], "depth": [2, 13, 75, 95, 313, 315, 316, 317, 374, 375, 396, 413, 414, 415, 416, 417, 437, 471, 477, 478, 479, 487, 496, 542, 543, 559], "height": [2, 83, 87, 89, 106, 127, 312, 313, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 344, 345, 346, 350, 351, 413, 414, 415, 416, 417, 454, 455, 456, 457, 458, 459, 508, 536, 557, 559, 560], "width": [2, 12, 83, 87, 89, 106, 127, 312, 313, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 344, 345, 346, 350, 351, 413, 414, 415, 416, 417, 454, 455, 456, 457, 458, 459, 466, 468, 508, 524, 536, 557, 559, 560], "nchw": [2, 77, 80, 82, 122, 344, 408, 410, 502, 508, 509, 559], "nhwc": [2, 7, 77, 80, 82, 111, 122, 346, 348, 351, 557], "nm": [2, 7, 320, 321, 322, 323, 326, 330, 331, 451, 452, 453, 455, 459], "non": [2, 3, 9, 13, 15, 106, 110, 118, 120, 122, 130, 208, 210, 245, 253, 262, 310, 314, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 330, 331, 335, 336, 337, 338, 339, 340, 341, 344, 347, 348, 349, 352, 353, 354, 356, 357, 358, 375, 377, 378, 380, 381, 383, 388, 389, 390, 392, 395, 398, 401, 410, 417, 418, 432, 437, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 465, 497, 502, 522, 524, 542, 543, 552, 558, 564, 570], "maximum": [2, 4, 7, 106, 109, 135, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 260, 320, 321, 322, 323, 326, 327, 328, 330, 331, 335, 336, 338, 340, 349, 355, 382, 388, 399, 420, 425, 430, 431, 432, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 468, 493, 502, 524, 525, 533, 534, 543, 550, 567], "suppress": [2, 320, 321, 322, 323, 326, 330, 331, 451, 452, 453, 454, 455, 456, 457, 458, 459], "nn": [2, 77, 80, 85, 96, 113, 114, 115, 440, 528, 529, 530, 532], "nst": 2, "style": [2, 13, 16, 266, 275, 283, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 363, 365, 366, 420, 536], "transfer": [2, 13, 355, 360, 473, 527, 536, 539, 542, 545], "od": 2, "o": [2, 13, 15, 98, 100, 103, 127, 290, 467, 473, 474, 477, 481, 483, 490, 493, 496, 499, 500, 502, 515, 516, 540, 542, 547, 551, 555, 565, 568], "oper": [2, 5, 6, 10, 13, 14, 74, 75, 77, 78, 80, 81, 82, 100, 103, 106, 109, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 127, 136, 137, 138, 139, 140, 141, 142, 143, 148, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 208, 209, 213, 216, 220, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 309, 311, 312, 313, 314, 317, 318, 319, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 338, 339, 340, 341, 342, 343, 344, 345, 348, 350, 352, 353, 354, 355, 357, 358, 360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 380, 381, 382, 383, 384, 385, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 434, 435, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 460, 461, 462, 463, 464, 465, 466, 467, 468, 470, 473, 477, 483, 490, 491, 496, 497, 498, 499, 500, 504, 514, 515, 519, 520, 523, 524, 526, 527, 528, 529, 530, 531, 535, 539, 541, 542, 543, 544, 545, 552, 553, 555, 556, 557, 559, 561, 563, 568, 569, 572], "system": [2, 6, 9, 13, 14, 75, 79, 83, 95, 98, 100, 127, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 486, 487, 488, 490, 491, 492, 495, 496, 499, 502, 504, 513, 514, 515, 516, 530, 539, 540, 542, 543, 545, 546, 547, 555, 556, 562, 564], "ovc": [2, 74, 78, 114, 505, 506, 508, 509, 511, 512, 526, 527, 528, 530, 531, 532, 533], "pci": 2, "peripher": 2, "interconnect": [2, 545], "prelu": [2, 7, 8, 135, 165, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 522], "parametr": [2, 216, 254, 408, 551], "rectifi": [2, 254, 260], "psroi": 2, "posit": [2, 83, 106, 132, 258, 287, 303, 313, 314, 317, 318, 319, 320, 321, 325, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342, 343, 354, 361, 362, 367, 373, 374, 379, 380, 381, 387, 390, 391, 392, 393, 395, 396, 398, 405, 406, 407, 408, 409, 410, 430, 433, 434, 435, 436, 437, 438, 439, 441, 454, 463, 497, 533], "sensit": [2, 13, 16, 127, 319, 332, 367, 502, 524, 536], "region": [2, 111, 220, 319, 332, 333, 335, 336, 337, 338, 394, 407, 413, 414, 415, 416, 417, 516], "Of": [2, 327, 328, 475], "interest": [2, 226, 319, 332, 335, 336, 337, 338, 504], "rcnn": [2, 106], "r": [2, 12, 81, 83, 106, 112, 119, 127, 208, 245, 256, 340, 341, 346, 349, 351, 361, 362, 373, 379, 388, 389, 390, 391, 392, 394, 401, 408, 409, 410, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 433, 434, 435, 436, 438, 439, 444, 445, 446, 447, 448, 449, 473, 474, 477, 478, 479, 490, 496, 502, 503, 504, 507, 548, 560], "base": [2, 3, 9, 11, 12, 13, 14, 82, 83, 93, 98, 104, 106, 114, 115, 118, 120, 121, 122, 123, 124, 127, 128, 129, 130, 131, 132, 133, 208, 210, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 245, 247, 248, 253, 254, 256, 260, 261, 262, 265, 268, 269, 270, 272, 273, 276, 284, 287, 289, 293, 295, 296, 297, 298, 308, 311, 314, 323, 326, 335, 336, 338, 340, 341, 344, 361, 362, 364, 367, 382, 383, 384, 397, 398, 402, 403, 404, 408, 411, 412, 415, 417, 418, 433, 435, 468, 470, 471, 476, 483, 490, 491, 496, 497, 502, 514, 515, 516, 518, 522, 523, 524, 525, 526, 529, 530, 536, 539, 542, 543, 547, 548, 550, 555, 556, 561, 569, 570, 572], "relu": [2, 7, 8, 77, 81, 113, 115, 120, 130, 132, 135, 166, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 245, 254, 433, 434, 435, 436, 438, 439, 522, 528, 530], "roi": [2, 83, 119, 319, 322, 323, 325, 326, 332, 335, 336, 337, 338, 450], "sdk": 2, "kit": [2, 75, 470, 477, 478, 479, 486, 487], "ssd": [2, 11, 12, 13, 75, 106, 129, 476, 477, 478, 479, 482, 490, 491, 501, 522, 535], "singl": [2, 9, 10, 12, 13, 81, 84, 100, 111, 118, 120, 122, 130, 133, 136, 148, 210, 212, 213, 216, 220, 221, 222, 226, 310, 319, 330, 331, 337, 340, 341, 346, 351, 361, 367, 368, 369, 373, 385, 390, 391, 398, 401, 402, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 435, 436, 438, 439, 461, 500, 502, 508, 509, 514, 516, 518, 527, 529, 533, 535, 536, 537, 538, 539, 541, 544, 546, 549, 552, 553, 556, 562, 563, 566, 567, 569, 570], "shot": [2, 13, 369], "multibox": 2, "detector": [2, 111], "sse": 2, "stream": [2, 6, 10, 13, 133, 213, 312, 473, 490, 496, 502, 505, 506, 508, 509, 510, 539, 541, 544, 546, 554, 556, 564, 566, 571], "simd": 2, "usb": 2, "univers": [2, 13, 552], "serial": [2, 80, 81, 85, 113, 115, 131, 133, 210, 502, 528, 530, 532, 533, 541, 543, 551, 555, 556, 558, 559, 566], "bu": 2, "vgg": 2, "geometri": 2, "voc": [2, 109, 111], "class": [2, 77, 80, 87, 89, 96, 101, 111, 114, 115, 118, 119, 120, 121, 122, 123, 124, 129, 132, 133, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 216, 220, 222, 223, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 320, 321, 322, 330, 331, 333, 340, 349, 430, 431, 432, 437, 451, 452, 453, 454, 455, 456, 457, 458, 459, 470, 498, 508, 522, 529, 530, 533, 542, 544, 548, 549, 550, 551, 552, 553, 557, 558, 559, 569, 571], "winapi": 2, "window": [2, 13, 15, 75, 95, 96, 98, 99, 100, 108, 123, 413, 414, 415, 416, 417, 474, 475, 477, 478, 481, 482, 483, 486, 487, 488, 492, 493, 496, 500, 504, 515, 540, 542, 544, 547, 549], "batch": [2, 6, 9, 13, 78, 81, 82, 84, 93, 95, 96, 98, 101, 102, 103, 106, 108, 109, 110, 111, 115, 130, 219, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 326, 330, 332, 335, 336, 337, 338, 339, 340, 345, 346, 347, 350, 351, 362, 367, 368, 369, 370, 375, 377, 378, 380, 381, 382, 386, 395, 403, 404, 406, 408, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 434, 436, 439, 440, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 464, 471, 479, 502, 504, 509, 510, 515, 529, 533, 535, 536, 537, 538, 544, 556, 558, 559, 566], "dure": [2, 15, 77, 79, 81, 83, 84, 95, 106, 117, 118, 120, 121, 122, 123, 124, 125, 127, 130, 131, 132, 134, 136, 137, 148, 167, 208, 211, 212, 213, 219, 221, 223, 225, 226, 315, 316, 355, 398, 415, 416, 417, 430, 431, 432, 451, 452, 453, 456, 457, 458, 461, 479, 492, 496, 498, 500, 501, 504, 519, 520, 522, 523, 524, 526, 527, 529, 530, 533, 535, 536, 537, 542, 543, 544, 545, 548, 559, 560, 570, 572], "one": [2, 6, 10, 13, 14, 16, 75, 76, 77, 78, 81, 82, 84, 89, 101, 105, 106, 108, 109, 118, 120, 121, 122, 123, 124, 125, 129, 130, 132, 135, 148, 167, 208, 209, 210, 212, 213, 219, 222, 224, 226, 242, 250, 251, 256, 265, 269, 286, 293, 309, 311, 313, 314, 316, 317, 318, 319, 326, 340, 344, 345, 346, 347, 348, 349, 350, 351, 353, 355, 358, 360, 362, 367, 368, 369, 371, 372, 373, 380, 388, 389, 390, 392, 398, 407, 408, 416, 417, 420, 434, 436, 437, 439, 440, 441, 453, 466, 467, 468, 474, 475, 477, 478, 490, 491, 496, 498, 499, 502, 504, 505, 506, 508, 509, 511, 512, 513, 524, 525, 526, 527, 529, 533, 535, 536, 538, 539, 542, 543, 544, 545, 550, 551, 552, 553, 555, 557, 558, 559, 560, 562, 564, 565, 566, 567, 569, 570, 571], "call": [2, 12, 96, 111, 114, 118, 119, 120, 122, 123, 124, 127, 130, 131, 132, 208, 209, 219, 220, 222, 225, 341, 343, 353, 355, 358, 470, 498, 500, 514, 516, 519, 520, 522, 524, 526, 529, 530, 535, 536, 537, 539, 540, 541, 542, 543, 544, 545, 546, 548, 549, 550, 553, 555, 560, 563, 567, 569, 570, 571, 572], "size": [2, 7, 9, 12, 13, 74, 77, 78, 81, 82, 101, 103, 106, 108, 109, 111, 115, 117, 122, 130, 209, 224, 242, 252, 258, 259, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 330, 331, 333, 335, 336, 337, 338, 340, 347, 348, 349, 354, 360, 361, 362, 367, 368, 369, 370, 371, 372, 373, 374, 375, 379, 387, 389, 392, 393, 394, 395, 396, 398, 407, 411, 412, 413, 414, 415, 416, 417, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 445, 446, 447, 448, 449, 456, 457, 458, 471, 493, 496, 497, 498, 499, 501, 502, 506, 508, 509, 510, 515, 517, 524, 527, 532, 535, 536, 537, 542, 543, 552, 553, 554, 556, 557, 558, 559, 563, 564, 568, 571], "properti": [2, 3, 13, 15, 16, 133, 137, 138, 139, 140, 141, 142, 212, 213, 217, 218, 224, 262, 368, 398, 469, 473, 498, 502, 515, 536, 539, 540, 541, 544, 545, 546, 549, 553, 556, 562, 565, 567, 568], "befor": [2, 9, 12, 74, 75, 78, 81, 82, 83, 85, 86, 95, 96, 98, 100, 103, 106, 111, 115, 118, 122, 126, 127, 130, 132, 135, 143, 148, 213, 220, 266, 275, 283, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 320, 321, 323, 326, 330, 331, 337, 343, 348, 349, 361, 362, 363, 365, 366, 368, 369, 401, 419, 420, 432, 433, 434, 435, 436, 438, 439, 470, 477, 478, 479, 481, 482, 492, 499, 500, 502, 504, 505, 506, 508, 509, 510, 511, 512, 514, 519, 520, 521, 522, 523, 524, 525, 530, 534, 536, 537, 539, 541, 542, 543, 544, 545, 546, 549, 551, 556, 557, 565, 569, 572], "layout": [2, 8, 16, 57, 58, 62, 78, 80, 85, 121, 122, 130, 219, 312, 313, 314, 315, 316, 317, 318, 326, 344, 346, 348, 351, 367, 370, 382, 406, 410, 451, 452, 453, 481, 501, 502, 508, 509, 535, 541, 558, 563, 571], "n": [2, 13, 77, 82, 83, 95, 117, 122, 127, 130, 220, 226, 308, 312, 313, 314, 317, 318, 320, 321, 323, 326, 332, 333, 334, 335, 336, 337, 338, 341, 344, 345, 346, 349, 350, 351, 360, 367, 368, 370, 371, 372, 373, 374, 377, 378, 392, 393, 394, 395, 396, 398, 400, 405, 406, 408, 411, 412, 413, 414, 415, 416, 417, 430, 431, 432, 437, 440, 446, 447, 448, 451, 463, 466, 475, 477, 496, 500, 502, 541, 543, 559, 571], "refer": [2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 15, 49, 73, 75, 78, 79, 80, 83, 84, 85, 87, 89, 90, 91, 92, 93, 94, 96, 98, 100, 101, 103, 106, 108, 111, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 126, 129, 130, 131, 132, 135, 208, 212, 213, 222, 224, 225, 226, 254, 255, 256, 257, 258, 259, 308, 314, 316, 319, 320, 321, 325, 331, 332, 333, 334, 335, 336, 337, 339, 367, 383, 384, 398, 401, 413, 414, 470, 471, 476, 477, 478, 479, 480, 481, 482, 487, 488, 490, 491, 495, 496, 498, 502, 504, 505, 506, 508, 509, 510, 511, 512, 514, 515, 519, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 539, 540, 541, 542, 543, 544, 546, 547, 548, 549, 550, 553, 555, 556, 558, 559, 560, 562, 567, 570, 572], "devic": [2, 5, 7, 9, 10, 12, 53, 74, 79, 90, 96, 127, 130, 131, 133, 135, 210, 212, 213, 215, 216, 217, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 368, 470, 473, 474, 475, 487, 492, 493, 494, 496, 498, 500, 501, 504, 509, 510, 511, 512, 514, 522, 524, 525, 526, 534, 536, 544, 549, 550, 554, 555, 556, 557, 560, 562, 563, 564, 568, 572], "affin": [2, 7, 13, 209, 213, 216, 419, 502, 542], "prefer": [2, 10, 129, 138, 220, 477, 479, 493, 496, 499, 513, 524, 539, 543, 551, 564, 566, 567], "run": [2, 4, 6, 9, 10, 12, 13, 75, 76, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 118, 122, 124, 129, 130, 133, 135, 143, 148, 210, 211, 212, 219, 220, 221, 222, 355, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 471, 472, 473, 476, 477, 478, 479, 480, 481, 482, 483, 486, 487, 488, 490, 491, 492, 493, 494, 495, 497, 498, 499, 501, 513, 514, 516, 518, 522, 524, 525, 526, 527, 528, 530, 531, 532, 533, 536, 537, 539, 540, 541, 542, 543, 544, 545, 546, 549, 552, 554, 555, 556, 562, 564, 567, 572], "etc": [2, 10, 80, 83, 85, 127, 208, 473, 476, 490, 494, 497, 499, 500, 501, 515, 517, 519, 522, 534, 539, 541, 545, 550, 555, 556, 557, 558, 564, 566, 572], "mechan": [2, 8, 13, 73, 78, 83, 118, 122, 124, 213, 220, 353, 358, 535, 539, 542, 544, 547, 550, 551, 553, 569], "custom": [2, 6, 7, 73, 81, 102, 105, 111, 112, 113, 116, 118, 119, 121, 122, 127, 129, 210, 213, 483, 493, 497, 498, 499, 500, 502, 514, 515, 523, 525, 531, 535, 536, 539, 542, 551, 563, 572], "layer": [2, 5, 7, 10, 13, 80, 81, 85, 87, 89, 96, 103, 105, 107, 108, 111, 118, 120, 121, 122, 123, 124, 135, 208, 216, 224, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 483, 496, 497, 518, 522, 523, 524, 532, 535, 536, 542, 545, 547, 564, 570], "capabl": [2, 15, 75, 77, 84, 85, 129, 131, 133, 213, 220, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 470, 471, 472, 494, 497, 501, 502, 514, 515, 516, 526, 529, 532, 533, 536, 538, 539, 542, 543, 547, 548, 556, 563, 564, 568, 571, 572], "extend": [2, 4, 12, 13, 73, 83, 118, 120, 121, 122, 123, 124, 131, 220, 226, 353, 358, 383, 384, 398, 399, 437, 468, 472, 481, 502, 544, 548], "so": [2, 10, 13, 75, 82, 83, 100, 103, 104, 106, 108, 109, 111, 112, 114, 117, 118, 119, 120, 121, 122, 123, 127, 130, 131, 132, 135, 208, 209, 213, 216, 220, 221, 222, 312, 313, 314, 315, 316, 317, 319, 335, 336, 338, 341, 345, 350, 360, 362, 367, 368, 371, 372, 373, 394, 412, 434, 435, 436, 460, 462, 481, 482, 483, 492, 498, 500, 502, 515, 518, 519, 520, 524, 530, 532, 533, 535, 536, 539, 541, 542, 543, 545, 546, 548, 551, 555, 556, 557, 564, 565, 567, 568, 569, 570, 571, 572], "thei": [2, 9, 10, 13, 14, 16, 74, 75, 83, 85, 93, 98, 101, 103, 106, 108, 111, 113, 118, 122, 127, 130, 132, 135, 167, 210, 211, 216, 220, 226, 314, 329, 355, 360, 371, 372, 383, 384, 398, 408, 437, 440, 470, 494, 498, 501, 502, 504, 515, 524, 525, 532, 536, 538, 543, 544, 546, 552, 556, 563, 567, 568, 570], "yet": [2, 10, 83, 129, 496, 525, 529, 539, 541, 543, 546, 550, 553, 561, 567, 572], "treat": [2, 81, 103, 340, 344, 347, 367, 398, 502, 542, 571], "synonym": 2, "avoid": [2, 3, 9, 10, 12, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 135, 220, 221, 368, 407, 408, 409, 410, 432, 487, 498, 516, 522, 526, 530, 532, 535, 539, 541, 544, 545, 549, 550, 551, 552, 566, 567, 569, 570, 571], "confus": [2, 568], "being": [2, 16, 216, 320, 321, 347, 348, 349, 371, 372, 397, 407, 502, 524, 539, 540, 541, 545, 546, 552, 555, 557, 562, 569], "push": 2, "out": [2, 10, 13, 75, 78, 86, 96, 98, 99, 103, 106, 108, 111, 118, 120, 122, 129, 130, 131, 132, 313, 315, 316, 320, 321, 330, 331, 344, 378, 379, 390, 394, 398, 411, 412, 451, 471, 476, 477, 478, 479, 480, 481, 482, 487, 488, 490, 491, 493, 498, 503, 508, 511, 512, 513, 516, 518, 519, 526, 527, 528, 529, 537, 539, 542, 543, 546, 557, 562, 563, 569, 571], "current": [2, 6, 13, 15, 74, 77, 87, 89, 95, 98, 103, 104, 109, 110, 111, 115, 120, 123, 131, 132, 135, 136, 148, 209, 212, 213, 220, 221, 343, 355, 368, 433, 435, 470, 474, 475, 477, 478, 498, 499, 502, 520, 521, 523, 524, 526, 529, 539, 541, 542, 543, 544, 547, 548, 549, 550, 555, 556, 557, 560, 565, 568, 569, 570, 572], "accept": [2, 77, 80, 81, 83, 113, 114, 130, 132, 212, 213, 225, 226, 314, 398, 461, 471, 505, 506, 508, 509, 510, 511, 512, 528, 533, 536, 539, 542, 544, 546, 548, 550, 557, 560, 567, 569], "import": [2, 6, 9, 13, 14, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 90, 92, 93, 94, 95, 96, 98, 99, 103, 105, 106, 108, 110, 112, 113, 114, 115, 118, 119, 120, 122, 123, 124, 126, 129, 133, 136, 148, 211, 212, 213, 218, 349, 355, 487, 492, 496, 498, 500, 505, 508, 509, 511, 512, 514, 516, 518, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 536, 539, 542, 546, 547, 555, 556, 558, 559, 562, 563, 564, 567, 568, 571, 572], "popular": [2, 13, 74, 220, 493, 498, 499, 500, 520, 525, 536, 553], "usabl": [2, 129, 132], "repres": [2, 3, 9, 13, 15, 77, 82, 83, 96, 97, 114, 115, 118, 120, 129, 133, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 217, 220, 224, 226, 244, 248, 252, 258, 259, 288, 295, 296, 297, 298, 337, 340, 344, 345, 346, 350, 351, 361, 362, 367, 368, 371, 372, 377, 378, 380, 381, 382, 385, 394, 398, 403, 404, 407, 432, 433, 434, 435, 436, 437, 438, 439, 446, 447, 448, 451, 452, 453, 454, 455, 459, 460, 462, 466, 467, 468, 521, 522, 524, 525, 526, 527, 529, 530, 535, 540, 541, 544, 548, 549, 551, 557, 560, 571], "certain": [2, 6, 13, 15, 83, 84, 100, 104, 113, 114, 136, 472, 518, 533, 538, 541, 545, 546, 547, 556, 559, 562, 566, 567], "basic": [2, 75, 115, 126, 129, 216, 220, 222, 313, 319, 394, 398, 476, 477, 478, 479, 482, 487, 490, 491, 513, 514, 519, 520, 521, 523, 530, 543, 569, 571], "default": [2, 4, 13, 77, 79, 80, 83, 85, 102, 103, 106, 111, 114, 118, 119, 120, 122, 123, 124, 127, 130, 131, 132, 148, 208, 211, 212, 220, 225, 242, 248, 252, 258, 259, 262, 266, 274, 275, 278, 280, 281, 282, 283, 285, 286, 291, 292, 295, 297, 298, 299, 300, 301, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 336, 337, 338, 339, 340, 341, 344, 347, 348, 349, 355, 360, 361, 362, 363, 365, 366, 368, 369, 371, 372, 374, 377, 378, 380, 381, 386, 388, 390, 393, 394, 396, 398, 401, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 440, 443, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 468, 475, 478, 480, 481, 498, 502, 504, 505, 506, 507, 508, 509, 511, 512, 513, 514, 522, 523, 524, 525, 526, 529, 530, 532, 536, 539, 541, 542, 543, 544, 545, 547, 549, 552, 553, 554, 556, 565, 567, 568, 569, 570, 572], "all": [2, 3, 7, 9, 10, 11, 12, 13, 14, 15, 74, 77, 79, 80, 81, 84, 85, 86, 88, 106, 111, 115, 118, 120, 122, 124, 129, 130, 131, 132, 135, 136, 148, 163, 208, 209, 210, 211, 212, 213, 216, 218, 220, 221, 222, 225, 227, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 325, 326, 327, 328, 330, 331, 337, 340, 343, 348, 349, 355, 358, 360, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 379, 380, 381, 382, 383, 384, 386, 387, 388, 389, 390, 391, 392, 394, 395, 398, 402, 408, 410, 416, 417, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 434, 436, 437, 439, 441, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 465, 468, 470, 471, 475, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 492, 497, 501, 504, 507, 514, 515, 516, 518, 522, 523, 524, 525, 526, 527, 529, 530, 532, 533, 535, 536, 538, 539, 540, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 553, 556, 557, 561, 562, 563, 564, 565, 566, 568, 569, 571, 572], "allow": [2, 3, 9, 10, 12, 13, 14, 77, 78, 83, 84, 97, 106, 115, 117, 128, 129, 131, 132, 133, 135, 148, 167, 209, 210, 212, 213, 215, 217, 218, 219, 220, 222, 242, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 314, 318, 340, 353, 354, 355, 356, 358, 360, 363, 365, 366, 368, 373, 376, 377, 378, 388, 394, 398, 401, 408, 409, 414, 416, 417, 420, 466, 467, 468, 471, 473, 493, 497, 498, 499, 502, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 530, 532, 533, 535, 536, 541, 542, 543, 544, 549, 550, 551, 552, 553, 555, 557, 559, 560, 564, 566, 567, 568, 571, 572], "file": [2, 9, 10, 13, 14, 74, 75, 79, 80, 85, 87, 89, 90, 91, 92, 93, 94, 95, 98, 101, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 124, 127, 131, 132, 211, 213, 220, 224, 225, 226, 354, 475, 476, 481, 484, 485, 489, 490, 491, 492, 496, 499, 500, 502, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 516, 518, 524, 525, 526, 529, 530, 531, 532, 533, 540, 541, 542, 543, 544, 545, 546, 549, 551, 558, 563, 572], "input": [2, 6, 7, 9, 10, 12, 13, 16, 52, 59, 65, 75, 77, 78, 80, 85, 87, 89, 90, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 123, 129, 130, 131, 133, 140, 142, 148, 167, 208, 209, 210, 212, 213, 219, 222, 223, 224, 225, 226, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 471, 498, 501, 503, 504, 505, 508, 509, 510, 511, 512, 517, 522, 523, 524, 525, 526, 527, 528, 530, 536, 537, 539, 541, 542, 543, 545, 546, 547, 551, 554, 556, 557, 558, 561, 562, 563, 564, 566, 567, 569, 570, 571], "output": [2, 6, 7, 9, 10, 13, 16, 52, 55, 59, 65, 77, 78, 82, 87, 89, 90, 91, 93, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 127, 129, 130, 131, 133, 135, 136, 140, 148, 163, 208, 209, 212, 219, 224, 225, 226, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 473, 477, 478, 479, 498, 502, 504, 518, 522, 526, 528, 530, 535, 538, 539, 541, 542, 543, 544, 545, 549, 551, 555, 556, 563, 564, 569, 570, 571], "execut": [2, 6, 9, 10, 13, 14, 15, 81, 100, 103, 104, 111, 115, 118, 121, 122, 125, 127, 129, 130, 133, 208, 209, 210, 211, 212, 213, 216, 219, 220, 221, 223, 225, 309, 340, 355, 360, 368, 470, 471, 482, 494, 496, 501, 502, 504, 506, 509, 513, 514, 516, 524, 536, 538, 539, 540, 541, 544, 547, 548, 549, 550, 553, 554, 555, 556, 557, 558, 560, 562, 563, 564, 567, 569, 572], "your": [2, 3, 4, 6, 9, 10, 13, 14, 15, 49, 73, 75, 76, 79, 81, 82, 83, 84, 85, 86, 87, 89, 95, 99, 103, 105, 111, 112, 114, 115, 118, 126, 127, 128, 129, 130, 131, 132, 216, 220, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 486, 487, 488, 490, 491, 492, 493, 494, 495, 496, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 518, 522, 524, 525, 526, 529, 530, 532, 534, 536, 538, 539, 540, 541, 543, 544, 550, 551, 552, 553, 554, 556, 559, 561, 562, 563, 564, 567, 568, 571], "tensor": [2, 7, 13, 16, 48, 55, 56, 61, 69, 77, 81, 90, 96, 97, 100, 103, 106, 108, 109, 113, 114, 118, 120, 122, 123, 124, 129, 132, 133, 136, 148, 163, 167, 171, 210, 217, 219, 224, 226, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 470, 497, 499, 500, 502, 510, 522, 528, 533, 535, 536, 537, 541, 542, 543, 545, 549, 551, 552, 555, 557, 559, 560, 563, 564, 568, 569, 570], "ov": [2, 11, 13, 14, 31, 49, 77, 78, 81, 82, 85, 112, 113, 114, 115, 116, 129, 130, 131, 132, 133, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 470, 500, 505, 506, 508, 509, 511, 512, 513, 515, 517, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 555, 556, 557, 558, 559, 560, 562, 563, 565, 566, 567, 568, 569, 570, 571], "consist": [2, 9, 13, 81, 109, 111, 115, 127, 129, 131, 133, 148, 211, 226, 313, 326, 328, 335, 336, 337, 338, 367, 369, 376, 377, 378, 379, 432, 499, 519, 520, 525, 526, 527, 530, 532, 557, 563, 571], "structur": [2, 13, 16, 81, 83, 106, 111, 113, 115, 117, 118, 120, 121, 122, 132, 133, 210, 212, 213, 222, 309, 355, 360, 499, 517, 527, 528, 529, 542, 544, 553, 555, 570], "bias": [2, 81, 83, 114, 130, 224, 361, 362, 433, 434, 435, 436, 438, 439], "compiledmodel": [2, 13, 53, 55, 85, 213, 513, 523, 525, 532, 535, 539, 541, 542, 543, 544, 545, 549, 550, 555, 566], "instanc": [2, 9, 12, 96, 106, 114, 115, 118, 120, 122, 123, 124, 127, 130, 133, 136, 148, 210, 212, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 320, 321, 379, 389, 408, 432, 496, 522, 524, 530, 538, 541, 543, 546, 548, 550, 551, 552, 555, 556, 567, 571], "sever": [2, 6, 10, 74, 81, 83, 99, 101, 103, 106, 108, 111, 115, 118, 120, 122, 123, 124, 127, 129, 133, 135, 167, 171, 210, 211, 212, 213, 217, 218, 219, 220, 226, 355, 360, 367, 392, 460, 462, 477, 478, 479, 496, 499, 502, 504, 518, 522, 523, 524, 530, 536, 537, 542, 543, 545, 550, 551, 559, 562, 563, 565, 566, 567, 568, 569, 570], "synchron": [2, 9, 12, 212, 216, 501, 505, 506, 508, 510, 511, 544, 549, 552, 555, 556, 564], "asynchron": [2, 133, 212, 213, 216, 219, 501, 502, 503, 509, 512, 539, 541, 543, 549, 553, 555, 556, 562, 564, 566, 567], "inferrequest": [2, 52, 212, 541, 543, 544, 549, 550, 552, 553, 555, 556, 569], "end": [2, 7, 10, 14, 101, 103, 111, 126, 127, 130, 132, 135, 210, 245, 254, 256, 260, 312, 313, 314, 315, 316, 317, 318, 320, 321, 333, 343, 346, 348, 349, 351, 355, 360, 370, 373, 375, 382, 383, 384, 394, 395, 397, 398, 402, 411, 412, 413, 414, 415, 416, 417, 437, 444, 446, 447, 448, 449, 460, 462, 496, 500, 502, 519, 522, 526, 536, 537, 553, 555, 562, 567], "here": [2, 6, 13, 15, 77, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 132, 148, 208, 222, 224, 226, 325, 336, 340, 348, 349, 369, 407, 454, 455, 459, 473, 475, 479, 483, 496, 502, 504, 514, 519, 520, 525, 526, 529, 530, 532, 538, 543, 545, 546, 552, 565, 569, 570, 571], "should": [2, 10, 13, 14, 15, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 132, 135, 148, 209, 212, 213, 216, 217, 218, 219, 220, 225, 226, 260, 275, 299, 300, 301, 305, 306, 307, 314, 315, 316, 322, 323, 324, 327, 328, 329, 333, 334, 340, 348, 349, 355, 371, 372, 373, 382, 384, 385, 416, 417, 418, 420, 434, 435, 436, 437, 439, 440, 446, 447, 448, 449, 451, 452, 453, 460, 461, 462, 465, 470, 474, 492, 494, 495, 496, 498, 500, 502, 506, 514, 515, 517, 518, 519, 520, 524, 529, 530, 532, 533, 536, 537, 541, 542, 544, 545, 546, 548, 553, 554, 555, 557, 560, 564, 566, 567, 569, 570, 571], "profilinginfo": 2, "profil": [2, 10, 133, 212, 219, 516, 540, 545], "per": [2, 9, 10, 13, 127, 136, 148, 163, 171, 208, 254, 314, 318, 319, 320, 321, 322, 325, 327, 328, 329, 340, 382, 399, 403, 404, 406, 409, 431, 451, 452, 453, 454, 455, 456, 457, 458, 459, 473, 524, 536, 542, 545, 548, 555, 564, 566, 567], "show": [2, 13, 75, 106, 109, 113, 118, 122, 127, 132, 209, 220, 222, 367, 380, 381, 390, 391, 415, 417, 418, 471, 494, 495, 496, 497, 498, 501, 502, 504, 507, 509, 514, 518, 519, 522, 523, 524, 532, 536, 539, 541], "sequenc": [2, 13, 78, 95, 100, 103, 115, 220, 221, 222, 274, 340, 341, 342, 343, 360, 361, 362, 367, 382, 386, 394, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 499, 500, 502, 536, 537, 539, 543, 545, 546, 557, 569, 570, 571, 572], "4d": [2, 83, 118, 254, 319, 320, 321, 324, 325, 330, 331, 332, 333, 334, 335, 336, 337, 338, 344, 348, 349, 362, 375, 393, 403, 404, 407, 411, 412, 413, 414, 415, 416, 417, 418, 434, 439, 444, 445, 446, 447, 448, 449], "5d": [2, 118, 348, 349, 367, 368, 370, 398, 411, 412, 413, 414, 415, 416, 417, 446, 447, 448], "memori": [2, 8, 13, 80, 84, 120, 127, 218, 225, 353, 358, 367, 435, 464, 470, 471, 473, 493, 496, 497, 498, 502, 513, 518, 524, 525, 526, 529, 532, 533, 534, 535, 536, 537, 541, 542, 545, 547, 549, 550, 554, 555, 556, 562, 563, 566, 567, 568, 569, 571], "typic": [2, 12, 14, 81, 130, 309, 355, 360, 497, 534, 538, 546, 549, 555, 556, 560, 562, 567, 570], "pixel": [2, 312, 313, 315, 316, 317, 327, 328, 329, 330, 331, 344, 345, 346, 347, 348, 349, 350, 351, 407, 413, 414, 415, 416, 417, 557], "horizont": [2, 106, 319], "direct": [2, 74, 115, 118, 122, 226, 274, 295, 297, 298, 299, 305, 307, 362, 363, 365, 366, 371, 372, 434, 436, 439, 454, 542, 556, 565, 567], "row": [2, 310, 319, 339, 368, 369, 437], "vertic": [2, 106, 226, 319, 454], "dimens": [2, 16, 63, 80, 82, 84, 87, 89, 93, 98, 106, 117, 118, 122, 130, 224, 226, 242, 252, 254, 258, 259, 274, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 326, 327, 328, 330, 339, 340, 345, 346, 347, 348, 349, 350, 351, 355, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 434, 436, 437, 439, 440, 441, 444, 445, 446, 447, 448, 449, 451, 452, 453, 460, 461, 462, 468, 502, 526, 533, 535, 541, 543, 551, 558, 559, 560, 561, 570], "plane": [2, 345, 346, 350, 351, 543, 544, 560], "overview": [2, 73, 74, 77, 82, 83, 208, 470, 471, 476, 477, 478, 479, 480, 481, 488, 490, 491, 504, 536, 542, 543, 547, 548, 557, 558], "ov_runtime_ug": 2, "layout_overview": 2, "md": [2, 13, 96, 111, 127, 420, 516], "element": [2, 3, 14, 16, 48, 58, 62, 68, 69, 101, 103, 118, 122, 123, 130, 131, 132, 135, 208, 218, 219, 224, 226, 242, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 331, 332, 335, 336, 337, 338, 339, 340, 341, 343, 344, 347, 348, 349, 354, 355, 356, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 398, 399, 400, 401, 402, 403, 404, 406, 408, 410, 412, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 439, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 466, 467, 468, 472, 508, 529, 533, 537, 542, 544, 551, 560, 569], "type": [2, 7, 10, 13, 14, 16, 48, 69, 76, 77, 78, 79, 80, 81, 85, 103, 106, 108, 109, 114, 118, 119, 120, 121, 122, 123, 124, 127, 130, 131, 132, 133, 135, 136, 148, 209, 212, 213, 216, 217, 218, 219, 221, 222, 224, 226, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 473, 492, 494, 496, 498, 500, 502, 505, 506, 508, 509, 510, 515, 522, 523, 524, 525, 526, 528, 538, 539, 540, 544, 546, 547, 548, 551, 554, 560, 561, 568, 569, 571], "For": [2, 6, 9, 10, 11, 12, 13, 14, 15, 49, 74, 77, 78, 79, 80, 81, 82, 84, 85, 87, 89, 95, 96, 98, 99, 100, 101, 103, 106, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 127, 128, 130, 132, 135, 136, 148, 208, 212, 213, 216, 222, 224, 225, 226, 227, 248, 249, 250, 251, 254, 255, 257, 260, 266, 271, 275, 277, 278, 280, 281, 282, 283, 285, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 310, 311, 312, 313, 315, 316, 317, 319, 325, 327, 328, 329, 330, 331, 337, 338, 340, 341, 342, 343, 347, 348, 349, 353, 355, 358, 363, 365, 366, 367, 369, 371, 372, 376, 377, 378, 379, 380, 382, 384, 386, 388, 389, 390, 392, 398, 399, 403, 404, 407, 408, 413, 414, 415, 416, 417, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 446, 447, 448, 449, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 463, 465, 466, 467, 470, 471, 473, 475, 476, 477, 478, 479, 480, 482, 486, 487, 488, 490, 491, 492, 495, 496, 498, 499, 500, 502, 504, 505, 506, 507, 508, 509, 514, 515, 516, 518, 519, 520, 522, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572], "f32": [2, 50, 72, 132, 148, 224, 226, 309, 334, 339, 340, 341, 343, 353, 354, 356, 358, 368, 375, 405, 466, 468, 502, 505, 506, 507, 508, 509, 510, 542, 543, 547, 568], "32": [2, 10, 13, 97, 119, 135, 224, 226, 295, 313, 324, 325, 329, 330, 340, 341, 367, 373, 375, 377, 378, 383, 384, 411, 412, 413, 414, 415, 416, 417, 466, 467, 468, 477, 498, 518, 524, 543], "bit": [2, 10, 12, 13, 15, 127, 135, 295, 296, 297, 298, 312, 340, 341, 398, 419, 466, 467, 468, 476, 477, 478, 479, 480, 490, 491, 492, 496, 497, 498, 499, 514, 517, 518, 519, 520, 521, 522, 523, 524, 547, 557, 560, 568], "f16": [2, 339, 341, 354, 356, 358, 468, 498, 502, 542, 543, 547, 568], "16": [2, 6, 15, 83, 94, 100, 110, 111, 119, 313, 325, 327, 328, 329, 330, 331, 333, 335, 336, 337, 340, 341, 346, 351, 360, 361, 362, 367, 371, 372, 373, 375, 377, 378, 380, 381, 411, 412, 415, 416, 417, 418, 433, 434, 435, 436, 438, 439, 446, 447, 448, 449, 502, 512, 516, 541, 567], "plugin": [2, 6, 7, 10, 15, 73, 79, 83, 103, 130, 134, 136, 167, 208, 209, 210, 212, 217, 218, 219, 220, 225, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 454, 455, 459, 478, 481, 502, 505, 506, 507, 508, 509, 510, 514, 515, 526, 534, 535, 536, 538, 541, 542, 543, 545, 546, 547, 548, 555, 569], "mode": [2, 6, 7, 12, 79, 83, 92, 102, 114, 132, 212, 213, 248, 274, 286, 312, 319, 332, 335, 336, 344, 347, 348, 349, 367, 371, 372, 374, 383, 384, 385, 396, 401, 460, 461, 462, 468, 501, 502, 504, 505, 508, 509, 510, 512, 516, 519, 520, 524, 526, 539, 541, 543, 544, 547, 548, 549, 552, 554, 555, 556, 562, 566, 572], "make": [2, 10, 13, 14, 73, 75, 81, 83, 95, 98, 103, 106, 111, 122, 127, 132, 213, 216, 220, 369, 461, 472, 473, 474, 479, 480, 482, 486, 488, 492, 496, 497, 499, 502, 504, 505, 506, 508, 509, 511, 514, 516, 522, 524, 526, 532, 541, 543, 545, 549, 550, 554, 556, 557, 567, 569, 570, 572], "avail": [2, 3, 6, 9, 10, 12, 13, 15, 76, 77, 78, 80, 91, 96, 98, 99, 100, 101, 103, 106, 109, 110, 111, 112, 118, 119, 120, 126, 127, 128, 129, 131, 132, 135, 213, 226, 254, 263, 264, 266, 267, 275, 278, 279, 280, 281, 282, 283, 285, 288, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 342, 355, 359, 360, 363, 365, 366, 367, 371, 372, 387, 395, 399, 420, 440, 446, 447, 448, 449, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 487, 488, 490, 491, 492, 494, 496, 498, 499, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 515, 518, 521, 522, 523, 525, 526, 529, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551, 553, 555, 558, 560, 561, 563, 565, 567, 568, 569, 571, 572], "earlier": [2, 82, 127, 504, 556], "version": [2, 6, 9, 10, 13, 14, 15, 74, 76, 77, 81, 85, 96, 99, 100, 101, 103, 106, 111, 115, 118, 122, 123, 124, 127, 130, 131, 211, 213, 224, 227, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 470, 473, 474, 475, 476, 477, 478, 479, 481, 482, 486, 492, 496, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 518, 526, 529, 530, 536, 539, 541, 547, 564, 571], "mai": [2, 3, 9, 10, 11, 12, 13, 14, 15, 16, 74, 75, 79, 81, 82, 84, 86, 96, 101, 106, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 123, 129, 130, 132, 213, 216, 222, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 247, 248, 254, 256, 314, 318, 325, 340, 341, 355, 368, 394, 402, 466, 467, 468, 469, 472, 474, 475, 476, 477, 478, 479, 480, 482, 487, 488, 490, 491, 492, 496, 497, 498, 499, 500, 501, 502, 504, 512, 514, 515, 516, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 560, 562, 564, 565, 567, 568, 569, 570], "still": [2, 10, 14, 74, 78, 83, 96, 100, 104, 109, 112, 113, 115, 116, 118, 129, 132, 135, 136, 210, 329, 461, 475, 476, 477, 478, 479, 480, 482, 487, 488, 490, 491, 499, 502, 504, 518, 524, 525, 527, 528, 530, 531, 536, 537, 541, 543, 544, 547, 553, 555, 568, 570], "some": [2, 7, 10, 13, 15, 16, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 129, 131, 132, 135, 163, 167, 208, 212, 213, 218, 222, 226, 355, 358, 360, 397, 398, 402, 437, 448, 449, 472, 473, 476, 477, 478, 479, 480, 482, 487, 488, 490, 491, 498, 499, 502, 504, 515, 516, 519, 520, 522, 523, 524, 525, 526, 528, 529, 532, 533, 535, 536, 537, 539, 541, 542, 543, 544, 545, 546, 551, 553, 556, 558, 559, 560, 562, 563, 565, 567, 568, 569, 570], "becaus": [2, 81, 96, 97, 98, 100, 103, 106, 108, 118, 121, 122, 127, 130, 210, 220, 222, 226, 315, 316, 319, 371, 372, 498, 506, 515, 521, 523, 524, 525, 526, 529, 533, 536, 543, 565, 568, 570], "now": [2, 13, 74, 75, 77, 81, 83, 100, 118, 122, 473, 475, 476, 477, 478, 479, 480, 482, 486, 487, 488, 490, 491, 492, 493, 498, 524, 525, 536, 547, 552, 557], "virtual": [2, 9, 100, 127, 492, 499, 500, 502, 539, 541, 546], "concept": [2, 13, 16, 106, 120, 216, 559], "store": [2, 10, 13, 16, 85, 90, 100, 104, 111, 113, 115, 123, 124, 135, 213, 220, 224, 225, 353, 358, 468, 470, 492, 496, 502, 515, 516, 524, 525, 528, 530, 542, 543, 547, 550, 551, 558, 563, 565, 567, 569], "vari": [3, 9, 10, 11, 12, 13, 14, 15, 115, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 514, 523, 530, 535], "configur": [3, 6, 9, 10, 11, 12, 13, 15, 16, 75, 90, 103, 106, 107, 111, 127, 129, 133, 135, 212, 213, 461, 476, 480, 481, 482, 487, 488, 490, 491, 497, 498, 501, 503, 504, 507, 511, 512, 514, 515, 518, 523, 526, 534, 538, 540, 543, 549, 554, 556, 557, 562, 563, 566, 567, 572], "factor": [3, 9, 12, 13, 15, 108, 111, 135, 245, 319, 330, 331, 332, 335, 336, 337, 375, 399, 403, 404, 419, 440, 451, 524, 557, 567], "www": [3, 9, 13, 15, 547], "com": [3, 7, 9, 13, 15, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 108, 109, 110, 111, 127, 473, 474, 476, 486, 490, 492, 496, 500, 529, 547], "performanceindex": [3, 9, 13, 15], "date": [3, 9, 13, 96, 133], "shown": [3, 10, 81, 130, 477, 478, 502, 504, 509, 515, 520, 524, 528, 532, 536, 541, 570], "reflect": [3, 9, 10, 86, 344, 383, 384], "publicli": [3, 9, 96, 98, 100, 110], "updat": [3, 9, 12, 13, 14, 15, 118, 119, 122, 124, 127, 136, 143, 167, 218, 326, 329, 341, 352, 353, 361, 362, 388, 389, 390, 391, 392, 452, 453, 473, 474, 476, 477, 478, 479, 482, 490, 491, 496, 497, 499, 516, 535, 536, 558, 571, 572], "see": [3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 74, 75, 77, 78, 79, 81, 82, 83, 85, 96, 105, 106, 112, 113, 114, 115, 117, 120, 126, 127, 130, 132, 135, 208, 209, 213, 216, 224, 225, 325, 345, 348, 349, 350, 454, 455, 459, 470, 471, 472, 473, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 492, 493, 496, 497, 498, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 517, 518, 519, 520, 522, 525, 526, 529, 532, 533, 534, 535, 536, 538, 539, 540, 542, 543, 546, 547, 549, 550, 551, 554, 555, 556, 557, 560, 566, 567, 569, 570, 571, 572], "backup": [3, 524, 529], "No": [3, 6, 9, 13, 15, 77, 130, 136, 142, 148, 209, 242, 263, 264, 267, 279, 288, 314, 340, 342, 355, 359, 360, 368, 387, 395, 398, 399, 416, 417, 446, 447, 448, 449, 494, 500, 502, 515, 517, 520, 539, 546, 571], "absolut": [3, 9, 11, 13, 15, 101, 263, 319, 332, 338, 421, 451, 452, 453, 502, 523], "cost": [3, 9, 10, 221, 367, 497, 502, 541], "technologi": [3, 9, 10, 13, 15, 212, 219, 476, 477, 479, 480, 481, 482, 487, 488, 490, 491], "requir": [3, 6, 9, 10, 12, 13, 14, 49, 73, 75, 80, 81, 82, 87, 89, 91, 95, 96, 100, 103, 106, 108, 111, 113, 114, 115, 117, 118, 122, 129, 131, 132, 136, 137, 138, 139, 140, 141, 142, 148, 163, 212, 213, 216, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 473, 474, 476, 477, 478, 480, 481, 482, 486, 487, 488, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 523, 524, 526, 528, 529, 530, 533, 534, 536, 537, 539, 541, 542, 543, 544, 546, 547, 550, 552, 553, 554, 555, 556, 557, 560, 562, 564, 565, 566, 567, 568, 569, 571], "servic": [3, 9, 13, 15, 127, 471, 495, 497], "activ": [3, 8, 9, 13, 15, 100, 122, 127, 132, 135, 148, 171, 208, 209, 213, 224, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 361, 362, 403, 404, 433, 434, 435, 436, 438, 439, 482, 492, 496, 497, 498, 499, 500, 502, 518, 519, 521, 522, 524, 526, 542, 545, 547, 555], "opencl": [3, 13, 15, 130, 213, 473, 482, 496, 515, 543, 544, 567], "appl": [3, 13, 15, 478, 480], "inc": [3, 13, 15, 109], "permiss": [3, 13, 15, 127, 483, 562], "khrono": [3, 13, 15], "corpor": [3, 13, 15, 496], "mark": [3, 10, 13, 82, 83, 84, 118, 122, 135, 148, 355, 375, 398, 468, 533], "subsidiari": 3, "name": [3, 10, 11, 13, 15, 16, 55, 77, 80, 81, 82, 84, 89, 91, 95, 97, 100, 104, 106, 108, 110, 111, 113, 114, 115, 117, 118, 119, 121, 123, 124, 127, 130, 135, 136, 137, 138, 139, 140, 141, 142, 148, 212, 213, 217, 218, 219, 224, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 473, 482, 490, 496, 498, 499, 500, 502, 504, 505, 506, 508, 509, 510, 515, 522, 526, 528, 530, 533, 535, 536, 538, 539, 540, 541, 545, 546, 548, 549, 550, 551, 556, 560, 569, 570], "brand": [3, 13, 15], "claim": [3, 13, 15], "equiti": 3, "around": [3, 73, 111, 120, 213, 314, 320, 321, 337, 541], "project": [3, 10, 74, 93, 100, 209, 475, 481, 486, 488, 496, 497, 500, 513, 514, 525], "creat": [3, 9, 14, 75, 77, 79, 81, 90, 92, 94, 95, 98, 99, 100, 104, 106, 108, 110, 111, 113, 114, 115, 118, 120, 122, 123, 124, 128, 131, 132, 133, 135, 136, 148, 212, 217, 218, 220, 221, 295, 296, 297, 298, 340, 368, 388, 389, 390, 391, 392, 398, 477, 478, 479, 481, 482, 483, 487, 490, 491, 496, 498, 499, 500, 502, 504, 505, 506, 508, 509, 510, 513, 514, 515, 522, 525, 526, 528, 530, 532, 536, 541, 542, 543, 544, 548, 551, 552, 553, 555, 556, 562, 563, 566, 567, 572], "commun": [3, 9, 12, 14, 127, 218, 479, 516, 541, 546, 556, 567], "onli": [3, 7, 9, 12, 13, 15, 75, 77, 78, 80, 81, 82, 85, 86, 87, 89, 95, 96, 100, 103, 104, 106, 112, 115, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 132, 135, 136, 137, 148, 167, 208, 211, 212, 213, 217, 218, 220, 221, 222, 224, 225, 226, 242, 275, 313, 314, 317, 318, 319, 320, 321, 322, 324, 330, 331, 332, 337, 339, 340, 346, 348, 349, 351, 353, 358, 360, 362, 367, 368, 369, 371, 372, 382, 383, 384, 385, 390, 394, 398, 405, 408, 416, 417, 434, 436, 439, 444, 448, 461, 468, 470, 475, 476, 477, 478, 479, 480, 481, 483, 486, 487, 488, 490, 491, 496, 498, 500, 501, 502, 505, 508, 509, 510, 511, 513, 515, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 532, 535, 536, 537, 538, 539, 541, 544, 546, 547, 548, 550, 551, 552, 553, 555, 556, 557, 560, 562, 564, 567, 568, 569, 570, 571], "offer": [3, 6, 10, 12, 13, 14, 16, 73, 74, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 497, 513, 517, 521, 524, 525, 538, 547, 553, 554, 555, 556, 562, 566, 569, 570], "built": [3, 13, 15, 83, 115, 118, 120, 121, 122, 216, 483, 502, 504, 510, 514, 515, 530, 557], "must": [3, 75, 78, 84, 106, 109, 111, 118, 122, 127, 130, 135, 171, 210, 213, 220, 225, 242, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 309, 311, 319, 320, 321, 324, 325, 332, 338, 343, 348, 355, 363, 365, 366, 367, 368, 370, 372, 374, 380, 381, 383, 384, 386, 387, 390, 391, 393, 395, 396, 397, 398, 400, 402, 403, 404, 419, 420, 431, 432, 446, 447, 448, 449, 452, 453, 454, 455, 456, 457, 458, 459, 466, 467, 473, 476, 477, 478, 479, 482, 483, 487, 492, 496, 497, 499, 502, 504, 515, 516, 526, 530, 539, 541, 542, 543, 553, 555, 557, 563, 567, 570, 571], "connect": [3, 9, 13, 14, 15, 83, 118, 119, 121, 122, 123, 124, 127, 130, 131, 132, 163, 208, 222, 224, 226, 315, 316, 355, 360, 401, 434, 436, 439, 513, 524, 545, 569, 570], "truth": 3, "mislead": 3, "modif": [3, 13, 15, 106, 118, 119, 121, 122, 123, 124, 316, 398, 433, 434, 526, 530, 551, 552, 553, 557, 559, 570, 571], "ani": [3, 4, 7, 9, 10, 12, 13, 15, 75, 95, 103, 112, 118, 127, 129, 130, 132, 135, 167, 213, 216, 220, 222, 226, 242, 244, 249, 250, 252, 255, 257, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 302, 303, 304, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 471, 476, 477, 478, 479, 480, 481, 482, 487, 488, 490, 491, 492, 495, 496, 499, 500, 501, 502, 505, 506, 508, 509, 510, 511, 512, 513, 515, 516, 521, 522, 525, 527, 529, 530, 534, 536, 539, 541, 542, 543, 544, 545, 546, 549, 550, 551, 553, 555, 556, 557, 559, 562, 565, 566, 568, 570, 571, 572], "separ": [3, 9, 10, 75, 78, 81, 82, 83, 85, 93, 109, 118, 122, 127, 128, 129, 131, 132, 135, 212, 216, 226, 315, 316, 346, 351, 361, 362, 367, 406, 433, 434, 476, 493, 502, 518, 522, 525, 527, 529, 533, 539, 545, 546, 550, 551, 556, 559, 560, 562, 566, 571], "": [3, 9, 14, 15, 81, 82, 84, 103, 106, 108, 118, 120, 122, 123, 127, 129, 132, 135, 148, 163, 211, 213, 216, 220, 222, 242, 309, 313, 319, 320, 321, 325, 327, 328, 329, 337, 343, 344, 348, 349, 355, 360, 369, 379, 380, 381, 384, 389, 392, 398, 399, 400, 401, 406, 407, 409, 432, 440, 452, 453, 454, 455, 459, 461, 468, 470, 471, 472, 481, 483, 493, 496, 498, 499, 502, 503, 509, 511, 512, 513, 516, 518, 523, 524, 529, 536, 538, 539, 541, 544, 546, 549, 550, 552, 553, 560, 562, 564, 568, 572], "alon": [3, 74, 519, 539], "commit": [3, 87, 89, 90, 92, 94, 96, 98, 99, 101, 103, 111], "respect": [3, 78, 83, 93, 109, 115, 118, 120, 122, 132, 211, 244, 256, 314, 322, 324, 327, 328, 329, 335, 336, 337, 341, 348, 349, 355, 377, 378, 383, 384, 403, 404, 406, 415, 416, 417, 418, 441, 446, 447, 448, 449, 467, 470, 504, 508, 524, 529, 533, 542, 543, 544, 551, 555, 556, 557, 567], "caus": [3, 13, 15, 113, 115, 118, 127, 466, 467, 468, 492, 498, 502, 519, 520, 536, 542, 543, 545, 564, 565], "advers": 3, "impact": [3, 9, 13, 14, 468, 513, 521, 523, 537, 539, 540, 554, 562, 565, 568], "intend": [3, 83, 102, 106, 117, 242, 526, 543, 557], "do": [3, 10, 11, 12, 75, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 132, 143, 148, 167, 212, 220, 222, 225, 226, 274, 312, 313, 314, 315, 316, 317, 318, 325, 333, 347, 348, 349, 355, 367, 368, 375, 385, 408, 409, 413, 414, 415, 430, 431, 446, 447, 448, 449, 451, 452, 453, 454, 455, 456, 457, 458, 459, 477, 479, 482, 492, 493, 496, 502, 504, 505, 506, 508, 509, 510, 515, 516, 519, 520, 522, 523, 524, 530, 532, 533, 535, 536, 539, 541, 542, 543, 544, 545, 546, 550, 551, 554, 555, 556, 557, 559, 560, 563, 567, 568, 570, 571], "facilit": [4, 13, 15, 129, 132, 499, 546], "debug": [4, 10, 81, 106, 122, 135, 224, 502, 504, 515, 516, 526, 539, 557, 559], "further": [4, 12, 13, 75, 81, 118, 126, 129, 337, 456, 457, 458, 471, 493, 497, 518, 519, 520, 525, 536, 539, 542, 544, 545, 555, 563, 567], "anonym": 4, "stop": [4, 103, 122, 127, 210, 213, 226, 340, 342, 343, 394, 398, 456, 457, 458, 523, 548, 558], "anytim": [4, 541], "opt_in_out": 4, "opt_out": 4, "doe": [4, 7, 10, 15, 77, 81, 82, 97, 103, 105, 106, 107, 108, 109, 117, 118, 120, 122, 123, 124, 127, 129, 131, 148, 163, 210, 216, 217, 218, 222, 224, 263, 264, 267, 279, 280, 288, 299, 300, 301, 305, 306, 307, 328, 330, 331, 337, 363, 365, 366, 367, 389, 391, 392, 398, 405, 406, 414, 416, 418, 432, 461, 468, 477, 478, 479, 480, 481, 482, 488, 490, 491, 492, 503, 511, 512, 513, 514, 517, 518, 519, 521, 524, 526, 530, 534, 536, 537, 539, 541, 542, 543, 545, 546, 553, 556, 557, 559, 563, 567, 568, 569, 570, 572], "websit": [4, 9, 12, 111, 127, 480, 492], "googl": [4, 98, 103, 115, 211, 216, 495, 504, 525, 530], "analyt": 4, "understand": [4, 106, 113, 115, 132, 134, 212, 218, 219, 222, 312, 367, 499, 500, 515, 548, 554, 559, 560], "opt_in": 4, "failur": [4, 13, 118], "error": [4, 13, 15, 75, 81, 106, 111, 113, 115, 118, 120, 122, 127, 132, 247, 248, 276, 352, 353, 357, 358, 368, 444, 479, 492, 502, 518, 519, 522, 523, 524, 540, 555, 563, 571], "download": [4, 9, 14, 15, 75, 87, 89, 95, 96, 97, 101, 106, 108, 111, 112, 126, 127, 135, 212, 219, 473, 474, 476, 478, 491, 492, 496, 500, 503, 505, 506, 508, 509, 511, 512, 525, 527, 547], "checker": [4, 13, 74, 75, 127], "quantiz": [4, 7, 10, 13, 75, 79, 125, 133, 134, 136, 138, 141, 142, 148, 163, 167, 213, 225, 419, 420, 497, 498, 513, 517, 524, 525, 526, 543, 547, 554, 568], "retent": 4, "retain": 4, "14": [4, 13, 106, 127, 243, 274, 333, 337, 342, 343, 367, 368, 375, 377, 378, 380, 381, 388, 390, 392, 413, 414, 416, 417, 418, 468, 479, 496, 504, 511, 512], "month": 4, "raw": [4, 98, 127, 496, 506, 571], "reach": [4, 83, 122, 125, 127, 493, 523, 529], "threshold": [4, 9, 260, 320, 321, 322, 323, 326, 451, 452, 453, 454, 455, 456, 457, 458, 459, 523, 542], "delet": [4, 81, 96, 98, 226, 322, 398, 452, 453, 454, 455, 459, 477, 478, 479, 526, 530, 570], "monthli": 4, "basi": 4, "list": [5, 6, 7, 8, 9, 12, 13, 15, 77, 78, 80, 81, 84, 85, 96, 98, 101, 106, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 123, 129, 132, 167, 213, 220, 224, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 314, 318, 319, 322, 325, 327, 328, 330, 331, 332, 333, 339, 340, 347, 348, 349, 354, 356, 358, 361, 362, 371, 372, 381, 398, 402, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 433, 434, 435, 436, 438, 439, 445, 446, 447, 448, 449, 452, 453, 454, 455, 459, 472, 473, 474, 476, 477, 478, 479, 480, 481, 482, 487, 488, 490, 491, 492, 496, 502, 508, 509, 515, 518, 522, 527, 528, 529, 530, 531, 532, 533, 538, 540, 542, 543, 545, 546, 548, 551, 559, 560, 569, 571], "select": [6, 7, 8, 9, 10, 12, 13, 14, 83, 127, 167, 208, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 340, 344, 348, 394, 398, 410, 416, 417, 440, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 468, 471, 473, 478, 479, 480, 488, 492, 496, 498, 499, 502, 504, 515, 524, 526, 538, 540, 542, 543, 545, 546, 548, 556, 557, 560, 562, 564, 567, 570, 572], "guid": [6, 9, 10, 12, 13, 14, 73, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 127, 128, 129, 132, 134, 135, 212, 213, 214, 216, 220, 225, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 483, 490, 491, 493, 495, 498, 500, 501, 503, 505, 506, 507, 508, 509, 510, 511, 512, 515, 518, 525, 526, 528, 529, 532, 533, 540, 543, 547, 551, 556, 559, 568, 570], "besid": [6, 502, 523, 541, 553, 571], "specif": [6, 7, 8, 10, 12, 13, 14, 15, 73, 74, 75, 76, 78, 82, 83, 86, 100, 106, 111, 112, 113, 114, 117, 118, 120, 123, 124, 126, 127, 129, 130, 132, 133, 134, 136, 210, 212, 213, 215, 216, 217, 219, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 278, 280, 281, 282, 285, 291, 320, 321, 355, 367, 390, 391, 398, 434, 436, 439, 476, 477, 479, 480, 481, 482, 487, 488, 490, 491, 492, 493, 494, 500, 501, 502, 504, 505, 506, 508, 509, 511, 512, 514, 515, 516, 518, 520, 522, 525, 526, 529, 534, 539, 541, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 556, 560, 563, 566, 572], "option": [6, 10, 13, 14, 52, 53, 55, 59, 65, 69, 75, 77, 78, 79, 80, 81, 82, 85, 96, 98, 102, 103, 106, 109, 111, 113, 115, 118, 122, 123, 124, 127, 129, 130, 131, 132, 135, 136, 143, 148, 211, 213, 224, 225, 262, 274, 309, 314, 316, 318, 319, 320, 321, 329, 331, 339, 348, 349, 355, 358, 369, 370, 371, 379, 383, 384, 394, 395, 398, 401, 419, 431, 432, 433, 435, 440, 444, 446, 447, 448, 449, 455, 456, 457, 458, 459, 463, 464, 465, 471, 475, 476, 477, 478, 479, 480, 481, 484, 485, 489, 492, 496, 497, 498, 500, 503, 509, 511, 512, 513, 515, 516, 517, 521, 522, 524, 525, 526, 528, 529, 530, 532, 536, 539, 540, 541, 542, 543, 544, 545, 546, 549, 551, 558, 562, 564, 565, 566, 568, 569, 570], "autom": [6, 74, 132, 497, 538, 570], "automat": [6, 13, 77, 81, 85, 118, 120, 122, 123, 130, 132, 211, 216, 220, 314, 318, 348, 398, 471, 477, 478, 493, 497, 498, 501, 502, 504, 513, 515, 524, 525, 526, 527, 530, 534, 538, 542, 546, 547, 548, 553, 556, 557, 561, 563, 566, 567, 568, 569, 570], "best": [6, 9, 15, 74, 103, 111, 136, 148, 430, 431, 470, 495, 497, 502, 519, 525, 532, 534, 538, 539, 541, 542, 546, 548, 554, 556, 564, 567, 568], "given": [6, 12, 74, 84, 88, 111, 115, 122, 126, 132, 222, 242, 245, 246, 247, 248, 252, 253, 254, 256, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 310, 314, 320, 321, 337, 339, 340, 341, 363, 364, 365, 366, 368, 370, 371, 372, 375, 382, 383, 384, 386, 390, 397, 398, 399, 401, 402, 403, 404, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 461, 466, 467, 468, 502, 504, 511, 512, 523, 529, 530, 539, 543, 544, 545, 548, 551, 552, 553, 558, 567, 569], "task": [6, 12, 98, 106, 111, 122, 126, 127, 133, 148, 210, 212, 213, 398, 494, 497, 498, 500, 501, 504, 505, 506, 508, 509, 510, 511, 512, 524, 539, 540, 543, 547, 560], "addit": [6, 10, 13, 15, 78, 80, 83, 85, 106, 111, 127, 129, 209, 213, 220, 221, 222, 226, 266, 314, 315, 316, 318, 320, 321, 348, 349, 361, 362, 367, 388, 402, 429, 434, 436, 439, 461, 467, 476, 480, 482, 488, 490, 491, 492, 497, 504, 513, 514, 515, 519, 520, 526, 534, 536, 544, 545, 552, 553, 560, 561, 562, 565, 566, 567, 569, 570], "same": [6, 9, 10, 11, 74, 77, 81, 82, 83, 84, 95, 103, 104, 111, 115, 118, 120, 121, 122, 123, 126, 127, 128, 130, 132, 135, 136, 138, 141, 148, 167, 209, 211, 216, 220, 222, 225, 226, 242, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 256, 258, 259, 260, 261, 262, 265, 268, 269, 270, 272, 273, 274, 276, 278, 279, 282, 284, 289, 290, 293, 294, 295, 296, 297, 298, 299, 302, 304, 308, 311, 312, 313, 314, 315, 316, 317, 318, 322, 323, 325, 326, 334, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 360, 363, 364, 365, 366, 367, 368, 369, 370, 372, 373, 379, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 397, 398, 401, 402, 403, 404, 405, 406, 407, 409, 410, 412, 415, 416, 417, 419, 420, 434, 436, 437, 439, 440, 441, 446, 447, 448, 449, 451, 452, 453, 460, 461, 462, 463, 464, 465, 466, 467, 468, 473, 479, 498, 500, 502, 516, 518, 519, 520, 523, 524, 525, 526, 527, 529, 530, 533, 536, 541, 542, 543, 544, 545, 546, 547, 548, 554, 556, 559, 560, 562, 565, 567, 569, 570, 571], "heterogen": [6, 126, 471, 538], "split": [6, 7, 8, 103, 105, 118, 120, 126, 128, 135, 181, 208, 216, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 315, 316, 317, 318, 319, 341, 374, 393, 402, 471, 545, 555, 556, 560], "among": [6, 16, 118, 122, 210, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 320, 321, 477, 478, 537], "doesn": [6, 96, 132, 135, 213, 218, 360, 371, 372, 444, 445, 526, 529, 541, 571], "t": [6, 7, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 83, 96, 124, 127, 132, 135, 213, 218, 220, 222, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 305, 306, 307, 308, 310, 311, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 330, 331, 332, 333, 335, 336, 337, 338, 342, 344, 345, 346, 347, 348, 349, 350, 351, 354, 356, 359, 360, 361, 362, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 387, 388, 389, 390, 391, 393, 394, 396, 397, 398, 399, 400, 401, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 414, 415, 416, 417, 421, 422, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 438, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 461, 462, 463, 464, 465, 466, 477, 479, 492, 496, 502, 518, 523, 526, 529, 541, 546, 549, 563, 568, 571], "multi": [6, 13, 83, 213, 295, 297, 298, 299, 305, 307, 363, 365, 366, 369, 452, 453, 471, 502, 514, 515, 538, 539, 547, 548, 550, 552, 556, 562], "consid": [6, 9, 10, 13, 77, 78, 81, 83, 85, 118, 120, 122, 123, 124, 132, 208, 209, 220, 320, 321, 322, 344, 360, 367, 401, 403, 404, 416, 417, 446, 447, 448, 449, 451, 452, 453, 454, 455, 456, 457, 458, 459, 492, 516, 518, 523, 524, 525, 526, 529, 533, 536, 537, 543, 545, 546, 550, 552, 554, 555, 557, 558, 562, 564, 567, 571], "advis": [6, 13, 523, 555], "improv": [6, 13, 15, 367, 471, 493, 498, 502, 515, 517, 518, 519, 521, 522, 523, 524, 532, 536, 539, 541, 542, 546, 547, 549, 550, 555, 556, 557, 559, 562, 564, 566, 567], "util": [6, 15, 75, 76, 77, 96, 103, 108, 122, 124, 125, 127, 137, 148, 211, 216, 471, 496, 501, 502, 513, 523, 538, 539, 541, 543, 544, 545, 546, 556, 557, 560, 564, 567], "ye": [6, 109, 127, 136, 137, 138, 139, 140, 141, 244, 245, 309, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 347, 348, 349, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 367, 373, 374, 375, 379, 383, 384, 385, 396, 397, 398, 403, 404, 405, 406, 407, 408, 409, 410, 413, 414, 415, 416, 417, 419, 420, 433, 434, 435, 436, 437, 438, 439, 440, 441, 460, 461, 462, 466, 500, 502], "partial": [6, 13, 83, 120, 122, 123, 333, 368, 440, 537, 542, 544, 547], "cach": [6, 13, 127, 212, 476, 493, 497, 498, 500, 502, 515, 516, 558, 562, 565, 572], "shape": [6, 7, 10, 13, 58, 60, 64, 69, 78, 80, 81, 82, 85, 93, 95, 98, 100, 101, 102, 103, 104, 108, 110, 111, 113, 115, 118, 120, 122, 123, 124, 129, 131, 167, 218, 219, 220, 222, 224, 226, 242, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 265, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 314, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 344, 347, 348, 349, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 436, 437, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 471, 499, 500, 502, 503, 505, 506, 508, 509, 510, 511, 525, 526, 528, 529, 530, 547, 554, 557, 558, 559, 560, 567, 569, 570, 571], "export": [6, 13, 48, 78, 82, 90, 92, 93, 94, 95, 96, 97, 98, 99, 108, 111, 112, 113, 126, 127, 128, 129, 133, 211, 213, 497, 498, 499, 502, 503, 516, 518, 527, 528, 532, 540, 542, 543, 547, 553, 563], "preprocess": [6, 9, 13, 48, 56, 77, 78, 83, 90, 96, 97, 100, 106, 212, 219, 226, 432, 502, 505, 506, 508, 509, 525, 529, 535, 544, 545, 549, 553, 559], "state": [6, 10, 13, 14, 100, 102, 104, 109, 118, 127, 210, 213, 219, 353, 361, 362, 433, 434, 435, 436, 438, 439, 474, 497, 499, 518, 539, 553], "infer_request": [6, 500, 550], "compiled_model": [6, 77, 85, 112, 499, 525, 529, 532, 539, 541, 543, 546, 556, 567], "80": [6, 111, 333, 341, 347, 348, 349, 375, 440, 502, 512, 524], "0": [6, 9, 10, 11, 13, 74, 76, 77, 80, 81, 82, 85, 87, 89, 90, 95, 96, 97, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 115, 117, 118, 119, 120, 122, 123, 127, 130, 132, 135, 163, 224, 226, 227, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 473, 474, 476, 477, 478, 479, 480, 481, 482, 490, 491, 493, 496, 498, 499, 500, 502, 504, 505, 506, 507, 508, 509, 510, 513, 514, 516, 519, 523, 524, 529, 530, 532, 536, 538, 539, 540, 541, 542, 543, 545, 546, 548, 553, 565, 571, 572], "100": [6, 77, 80, 83, 95, 106, 114, 115, 224, 226, 310, 322, 325, 332, 341, 344, 375, 380, 381, 382, 385, 386, 387, 388, 394, 406, 446, 447, 448, 449, 451, 452, 453, 454, 455, 458, 459, 473, 502, 529, 530, 541, 543, 557], "89": [6, 68, 83, 334, 375, 502, 524], "74": [6, 59, 375], "cpu_arm": 6, "84": [6, 11, 52, 323, 325, 326, 375], "dgpu": [6, 539, 541], "82": [6, 52, 333, 341, 375, 502, 524], "10": [6, 13, 15, 77, 87, 88, 96, 99, 104, 106, 109, 111, 118, 127, 224, 226, 243, 244, 260, 274, 290, 302, 303, 304, 308, 310, 311, 314, 322, 329, 333, 340, 341, 344, 355, 360, 367, 369, 370, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 394, 395, 397, 398, 401, 402, 403, 404, 407, 408, 409, 410, 413, 414, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 440, 453, 454, 455, 458, 459, 460, 461, 462, 478, 480, 482, 492, 496, 499, 500, 502, 504, 505, 506, 509, 510, 511, 512, 519, 524, 536, 543, 545], "26": [6, 11, 100, 103, 333, 334, 375, 377, 378, 388], "auto": [6, 12, 85, 112, 133, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 363, 365, 366, 420, 471, 502, 515, 532, 538, 541, 547, 548, 551, 553, 556, 562, 567], "40": [6, 11, 53, 54, 96, 109, 375, 377, 378, 383, 384, 388, 390, 490, 502], "97": [6, 11], "44": [6, 83, 329, 375], "58": [6, 53, 91, 96, 333, 375], "30": [6, 11, 13, 78, 81, 103, 109, 111, 115, 135, 329, 367, 375, 377, 378, 380, 381, 388, 390, 473, 511], "hetero": [6, 213, 216, 471, 502, 509, 514, 515, 538, 547, 548], "99": [6, 375, 502, 524], "23": [6, 53, 111, 297, 329, 333, 341, 342, 343, 375, 377, 378, 380, 381, 390, 512], "percentag": [6, 500], "2023": [6, 13, 15, 74, 77, 78, 85, 115, 227, 475, 490, 500, 525], "3": [6, 10, 11, 13, 15, 74, 77, 80, 81, 82, 83, 84, 87, 89, 92, 93, 94, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 110, 111, 113, 114, 115, 117, 118, 120, 122, 123, 130, 167, 224, 226, 227, 242, 243, 247, 248, 249, 250, 251, 252, 253, 256, 265, 268, 270, 274, 286, 290, 295, 296, 297, 298, 302, 304, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 330, 331, 332, 333, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 475, 476, 477, 478, 479, 480, 482, 490, 491, 492, 496, 502, 504, 505, 506, 508, 509, 510, 511, 513, 516, 524, 525, 528, 529, 530, 532, 533, 536, 539, 540, 545, 548, 557, 558, 559, 560, 571, 572], "08": [6, 11, 333, 502, 512], "jan": 6, "2024": [6, 9, 74, 227, 476, 477, 478, 479, 481, 482, 490, 491, 542], "similar": [6, 10, 80, 99, 111, 118, 122, 127, 132, 308, 315, 316, 345, 350, 355, 360, 367, 372, 383, 384, 394, 431, 440, 446, 447, 448, 449, 473, 492, 502, 519, 523, 536, 539, 544, 560], "ones": [6, 7, 10, 84, 118, 213, 225, 242, 339, 349, 355, 372, 463, 464, 465, 497, 502, 536, 543], "access": [6, 9, 13, 15, 75, 83, 118, 122, 131, 132, 215, 218, 220, 222, 473, 496, 502, 504, 524, 551, 553, 555, 564, 569, 572], "devcloud": [6, 9, 12, 74, 471], "edg": [6, 9, 12, 13, 74, 81, 105, 118, 120, 122, 224, 226, 308, 309, 355, 360, 383, 384, 394, 454, 470, 493, 516], "remot": [6, 9, 12, 13, 133, 210, 213, 496, 513, 543, 555], "latest": [6, 9, 10, 13, 15, 75, 127, 129, 132, 213, 220, 470, 471, 473, 474, 476, 482, 490, 491, 492, 493, 496, 500, 518, 547], "distribut": [6, 9, 12, 13, 14, 15, 73, 74, 75, 127, 129, 210, 213, 247, 248, 314, 340, 341, 470, 471, 473, 475, 479, 480, 481, 482, 488, 490, 491, 493, 500, 504, 518, 542, 543, 547, 564], "regist": [6, 122, 127, 131, 132, 220, 221, 520, 542], "up": [6, 10, 13, 73, 83, 84, 91, 96, 106, 122, 126, 130, 133, 135, 148, 208, 209, 212, 290, 294, 342, 343, 348, 349, 367, 398, 430, 432, 471, 473, 474, 477, 478, 482, 492, 493, 496, 499, 502, 504, 518, 524, 526, 533, 539, 540, 541, 542, 546, 549, 552, 553, 555, 563, 568, 572], "relev": [6, 9, 12, 79, 83, 113, 115, 227, 371, 372, 526, 529, 547, 555], "topic": [6, 83, 85, 213, 227, 492, 496, 532, 554, 558, 567], "step": [6, 9, 76, 79, 81, 82, 83, 87, 89, 90, 91, 95, 96, 98, 99, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 118, 122, 126, 128, 129, 131, 132, 167, 212, 213, 217, 219, 222, 278, 280, 281, 282, 285, 291, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 331, 342, 343, 360, 367, 368, 369, 370, 382, 394, 398, 419, 430, 431, 432, 433, 435, 452, 453, 454, 455, 456, 457, 458, 459, 471, 473, 482, 492, 496, 498, 499, 500, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519, 520, 522, 523, 524, 525, 526, 529, 532, 536, 539, 540, 542, 544, 545, 547, 552, 555, 556, 559, 560, 563, 567, 569, 571, 572], "With": [6, 84, 85, 103, 104, 117, 220, 226, 440, 444, 476, 490, 491, 500, 515, 524, 532, 536, 538, 539, 540, 541, 543, 559, 560, 563, 569], "releas": [6, 9, 10, 12, 15, 75, 77, 85, 100, 106, 115, 127, 209, 211, 226, 227, 477, 478, 479, 481, 496, 500, 504, 515, 516, 518, 542, 551, 552, 565], "gna": [6, 13, 15], "discontinu": [6, 14, 83, 85], "keep": [6, 10, 13, 83, 85, 100, 104, 117, 118, 121, 212, 220, 320, 321, 441, 451, 452, 453, 455, 456, 457, 458, 459, 470, 476, 515, 516, 519, 523, 525, 539, 541, 546, 549, 550, 555, 556, 557, 564, 566, 567, 568], "revert": [6, 13, 82, 260, 385, 523], "lt": [6, 7, 13, 14, 15, 85, 473, 475, 496, 514], "cancel": [6, 543, 550], "stick": 6, "2": [6, 7, 9, 10, 11, 12, 13, 15, 74, 76, 77, 78, 80, 81, 84, 87, 89, 93, 94, 95, 96, 99, 100, 103, 105, 106, 108, 109, 111, 112, 113, 117, 118, 119, 120, 122, 123, 130, 163, 167, 209, 224, 227, 242, 243, 247, 248, 249, 254, 256, 262, 266, 274, 275, 276, 278, 280, 281, 282, 283, 285, 286, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 355, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 473, 481, 492, 496, 497, 498, 502, 509, 510, 512, 513, 514, 517, 521, 522, 524, 525, 529, 532, 533, 537, 539, 540, 541, 542, 543, 545, 560, 567, 568, 572], "power": [6, 8, 9, 10, 13, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 407, 472, 498, 502, 539, 541, 543, 545, 546, 547, 553], "movidiu": [6, 13, 15], "myriad": 6, "x": [6, 9, 75, 77, 81, 83, 88, 93, 96, 101, 106, 111, 113, 115, 118, 120, 122, 127, 130, 132, 208, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 260, 261, 262, 276, 278, 282, 294, 312, 313, 314, 315, 316, 317, 318, 319, 322, 324, 325, 330, 331, 335, 336, 338, 340, 341, 348, 349, 361, 362, 368, 369, 370, 374, 375, 390, 393, 395, 396, 403, 404, 405, 406, 410, 413, 414, 415, 416, 417, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 433, 434, 435, 436, 438, 439, 446, 447, 448, 449, 450, 451, 454, 479, 492, 496, 517, 521, 522, 528, 529, 530, 543], "hddl": [6, 545], "2022": [6, 74, 75, 83, 106, 224, 227, 475, 479, 490, 502, 536], "limit": [7, 8, 13, 14, 15, 81, 83, 84, 100, 104, 122, 127, 220, 420, 495, 502, 515, 516, 517, 533, 539, 549, 556, 562, 571], "aten": [7, 132, 440], "__and__": 7, "__derive_index": 7, "__getitem__": 7, "__not__": 7, "__or__": 7, "__range_length": 7, "__xor__": 7, "_convolut": 7, "_convolution_mod": 7, "_native_multi_head_attent": 7, "_pack_padded_sequ": 7, "_pad_packed_sequ": 7, "_set_item": 7, "_shape_as_tensor": 7, "_unique2": 7, "_upsample_bicubic2d_aa": 7, "_upsample_bilinear2d_aa": 7, "_weight_norm": 7, "ab": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 349, 367, 406], "abs_": [7, 349], "aco": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "acos_": 7, "acosh": [7, 8, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "acosh_": 7, "adaptive_avg_pool1d": 7, "adaptive_avg_pool2d": 7, "adaptive_avg_pool3d": 7, "adaptive_max_pool1d": 7, "adaptive_max_pool2d": 7, "adaptive_max_pool3d": 7, "add": [7, 8, 10, 83, 96, 99, 103, 106, 111, 118, 120, 122, 125, 126, 128, 129, 131, 132, 135, 167, 208, 210, 211, 216, 220, 222, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 309, 312, 313, 314, 315, 316, 317, 318, 324, 325, 347, 348, 349, 383, 384, 409, 410, 413, 414, 415, 416, 417, 419, 445, 452, 453, 454, 455, 456, 457, 458, 459, 469, 473, 476, 477, 478, 479, 480, 481, 483, 496, 498, 500, 515, 516, 518, 519, 520, 539, 541, 551, 558, 572], "add_": 7, "addcmul": 7, "addmm": 7, "alia": [7, 122, 539, 543, 546], "alias_copi": 7, "amax": 7, "amin": 7, "append": [7, 83, 111, 340, 499], "pattern": [7, 102, 135, 216, 220, 221, 398, 514, 522], "arang": [7, 343, 500], "argmax": [7, 8, 529], "argmin": 7, "argsort": 7, "as_strid": 7, "as_tensor": 7, "asin": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "asin_": 7, "asinh": [7, 8, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "asinh_": 7, "atan": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "atan_": 7, "atanh": [7, 8, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "atanh_": 7, "avg_pool1d": 7, "avg_pool2d": 7, "avg_pool3d": 7, "baddbmm": 7, "batch_norm": 7, "bitwise_and": 7, "bitwise_not": 7, "bitwise_or": 7, "bitwise_xor": 7, "bmm": 7, "bool": [7, 80, 83, 103, 131, 302, 303, 304, 337, 340, 355, 368, 440, 468, 502, 565], "broadcast_tensor": 7, "broadcast_to": 7, "bucket": [7, 109, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "cat": [7, 96, 506, 529], "cdist": 7, "ceil": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 325, 335, 336, 337, 343, 348, 349, 413, 414, 415, 416, 417, 418], "ceil_": 7, "celu": 7, "celu_": 7, "channel_shuffl": 7, "chunk": [7, 397, 402, 537], "clamp": [7, 8, 135, 164, 209, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 394, 398], "clamp_": 7, "clamp_max": 7, "clamp_min": 7, "clip": [7, 11, 244, 320, 321, 322, 323, 326, 327, 328, 329, 330, 331, 346, 351, 361, 362, 420, 433, 434, 435, 436, 438, 439], "clip_": 7, "clone": [7, 13, 91, 95, 96, 98, 99, 103, 108, 109, 110, 111, 496, 500], "complex": [7, 13, 14, 80, 81, 106, 112, 113, 115, 116, 132, 226, 367, 380, 381, 446, 447, 449, 497, 519, 524, 541, 542, 561], "concat": [7, 8, 13, 77, 96, 122, 135, 176, 208, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 360], "contigu": [7, 394], "conv1d": 7, "conv2d": [7, 10, 81, 122, 135, 522], "conv3d": 7, "conv_transpose1d": 7, "conv_transpose2d": 7, "conv_transpose3d": 7, "copi": [7, 95, 96, 103, 111, 123, 127, 131, 132, 213, 220, 274, 332, 349, 360, 368, 383, 384, 388, 389, 390, 391, 392, 399, 441, 496, 515, 527, 541, 543, 544, 545, 546, 552, 553, 555, 560, 564, 569, 571], "copy_": 7, "co": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 435, 436], "cos_": 7, "cosh": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "cosh_": 7, "cross": [7, 109, 313, 367, 451, 452, 453, 521, 542], "cumsum": [7, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "dequant": [7, 143, 163, 167, 208, 517, 524], "detach": 7, "dim": [7, 81, 83, 122, 130, 224, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468], "div": [7, 8], "div_": 7, "dot": [7, 83, 220, 313, 367, 370, 392, 395, 440, 446, 447, 448, 449, 497, 545], "dropout": [7, 110], "dropout_": 7, "einsum": [7, 229, 230, 231, 232, 233, 239, 240, 241, 243], "elu_": 7, "embed": [7, 10, 13, 78, 103, 104, 105, 108, 109, 369, 376, 440, 463, 464, 465, 497, 505, 506, 508, 509, 524, 526, 538, 559], "embedding_bag": 7, "empti": [7, 127, 148, 167, 308, 309, 330, 331, 339, 352, 353, 354, 356, 357, 358, 367, 385, 400, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 441, 442, 443, 451, 452, 453, 454, 455, 459, 463, 465, 470, 502, 529, 539, 551, 571], "empty_lik": 7, "eq": 7, "erf": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 247, 248], "erf_": 7, "erfc": 7, "erfc_": 7, "exp": [7, 8, 96, 132, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 252, 322, 432, 446, 447, 448, 449, 451, 455, 459], "exp_": 7, "expand": 7, "expand_a": 7, "expm1": 7, "expm1_": 7, "ey": [7, 229, 230, 231, 232, 233, 241, 243], "fake_quantize_per_channel_affin": 7, "fake_quantize_per_tensor_affin": 7, "feature_dropout": 7, "fft_irfftn": 7, "fft_rfftn": 7, "fill": [7, 8, 103, 117, 127, 311, 312, 322, 323, 324, 330, 331, 339, 378, 382, 383, 384, 399, 430, 431, 437, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 463, 465, 502, 537, 544, 560], "fill_": 7, "fill_diagonal_": 7, "flatten": [7, 8, 118, 324, 333, 393, 401, 412, 416, 417, 451, 452, 453, 529, 572], "flip": [7, 327, 328, 368], "floor": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 275, 278, 325, 341, 348, 349, 413, 414, 415, 416, 417, 418], "floor_": 7, "floor_divid": 7, "floor_divide_": 7, "floordiv": [7, 13], "fmod": 7, "frobenius_norm": 7, "full": [7, 8, 13, 76, 78, 81, 83, 85, 95, 106, 118, 119, 120, 125, 167, 209, 224, 312, 360, 394, 398, 446, 447, 448, 449, 472, 476, 477, 478, 479, 480, 481, 482, 487, 488, 490, 491, 497, 502, 519, 524, 539, 540, 541, 542, 544, 548, 560, 564], "full_lik": 7, "gather": [7, 8, 10, 13, 118, 135, 178, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 344, 379, 380, 381, 396, 440, 464, 541, 553, 564], "gcd": 7, "ge": 7, "gelu": [7, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 522], "glu": 7, "grid_sampl": 7, "group_norm": 7, "gru": [7, 361, 362, 433, 434, 569, 570], "gt": [7, 432], "hardsigmoid": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "hardsigmoid_": 7, "hardswish": 7, "hardswish_": 7, "hardtanh": [7, 132], "hardtanh_": 7, "im2col": 7, "index": [7, 13, 14, 16, 81, 96, 98, 101, 103, 115, 120, 130, 132, 148, 242, 274, 308, 330, 333, 339, 340, 349, 360, 368, 371, 372, 376, 377, 378, 379, 380, 381, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 398, 400, 401, 416, 417, 430, 431, 432, 441, 444, 460, 461, 462, 463, 464, 465, 500, 529, 530, 535, 549, 550, 551, 559, 560, 570], "index_add": 7, "index_add_": 7, "index_copy_": 7, "index_put_": 7, "index_select": 7, "instance_norm": 7, "int": [7, 13, 80, 103, 106, 122, 130, 252, 258, 259, 290, 309, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 347, 348, 349, 354, 355, 356, 358, 360, 361, 362, 373, 374, 375, 379, 380, 381, 386, 393, 396, 397, 398, 406, 407, 408, 413, 414, 415, 416, 417, 420, 433, 434, 435, 436, 437, 438, 439, 450, 451, 452, 453, 460, 461, 462, 466, 467, 516, 535, 571], "intimplicit": 7, "invers": [7, 233, 264, 265, 267, 268, 269, 270], "is_grad_en": 7, "is_nonzero": 7, "item": [7, 81, 95, 122, 130, 402, 499, 500, 529, 560], "layer_norm": 7, "le": [7, 256], "leaky_relu": 7, "leaky_relu_": 7, "len": [7, 95, 122, 333, 348, 349, 374, 376, 377, 378, 383, 384, 388, 390, 398, 407, 446, 447, 448, 449], "lift": 7, "lift_fresh": 7, "lift_fresh_copi": 7, "linalg_cross": 7, "linalg_inv": 7, "linalg_matrix_norm": 7, "linalg_norm": 7, "linalg_vector_norm": 7, "linspac": 7, "log": [7, 8, 115, 122, 127, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 252, 260, 326, 340, 432, 505, 508, 509, 510, 541, 542, 547], "log10": 7, "log10_": 7, "log1p": 7, "log1p_": 7, "log2": [7, 325, 543], "log2_": 7, "log_": 7, "log_sigmoid": 7, "log_softmax": 7, "logical_and": 7, "logical_not": 7, "logical_or": 7, "logical_xor": 7, "lstm": [7, 104, 435, 436, 569, 570], "masked_fil": 7, "masked_fill_": 7, "masked_scatt": 7, "masked_scatter_": 7, "matmul": [7, 117, 135, 167, 175, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 440, 498], "max": [7, 8, 9, 15, 106, 244, 249, 250, 251, 254, 255, 256, 270, 280, 326, 328, 329, 335, 336, 338, 341, 343, 349, 384, 388, 390, 407, 410, 412, 415, 416, 417, 420, 425, 451, 460, 461, 462, 466, 468, 473, 502, 511, 512, 539, 541, 543], "max_pool1d": 7, "max_pool1d_with_indic": 7, "max_pool2d": 7, "max_pool2d_with_indic": 7, "max_pool3d": 7, "max_pool3d_with_indic": 7, "meshgrid": 7, "min": [7, 8, 106, 244, 249, 250, 251, 254, 256, 270, 281, 322, 327, 328, 329, 341, 349, 377, 378, 380, 381, 382, 388, 390, 407, 420, 427, 451, 454, 455, 456, 457, 458, 459, 460, 461, 462, 502, 511, 512], "minimum": [7, 15, 106, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 323, 326, 327, 328, 330, 331, 388, 420, 427, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 468, 502, 533, 537, 552, 555, 567], "mish": [7, 122, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "mish_": 7, "mm": 7, "movedim": 7, "mul": [7, 8, 122, 208], "mul_": 7, "multinomi": [7, 232, 233, 243], "multipli": [7, 108, 132, 135, 168, 171, 220, 222, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 319, 335, 336, 337, 361, 362, 368, 369, 407, 451, 463, 464, 465, 524, 568], "multiply_": 7, "mv": [7, 477, 478, 490], "narrow": [7, 519], "ne": 7, "neg": [7, 8, 83, 220, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 252, 254, 259, 262, 274, 287, 290, 303, 314, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 335, 336, 337, 338, 339, 340, 342, 343, 347, 348, 349, 354, 355, 356, 360, 373, 375, 376, 377, 378, 379, 383, 387, 388, 389, 390, 392, 394, 395, 397, 398, 402, 408, 409, 416, 417, 432, 434, 436, 437, 439, 444, 445, 446, 447, 448, 449, 450, 460, 461, 462, 466, 467], "new_empti": 7, "new_ful": 7, "new_on": 7, "new_zero": 7, "nonzero": [7, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "nonzero_numpi": 7, "norm": [7, 8, 405, 421, 422, 524], "normal_": 7, "numel": 7, "numpy_t": 7, "one_hot": 7, "ones_lik": 7, "outer": [7, 355, 367], "pad": [7, 8, 13, 81, 103, 106, 123, 130, 179, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 312, 313, 314, 315, 316, 317, 318, 344, 347, 349, 375, 395, 398, 399, 407, 413, 414, 415, 416, 417, 418, 446, 447, 448, 449, 536, 555, 561], "pairwise_dist": 7, "permut": [7, 8, 118, 122, 370, 374, 393, 396, 400], "pixel_shuffl": 7, "pixel_unshuffl": 7, "pow": [7, 8], "pow_": 7, "prod": [7, 8, 349, 388, 390, 428, 447, 448], "quantize_per_channel": 7, "quantize_per_tensor": 7, "rand": [7, 113, 525, 528, 529], "rand_lik": 7, "randint": 7, "randn": [7, 94, 95, 114, 529], "randn_lik": 7, "reciproc": [7, 8], "reciprocal_": 7, "reflection_pad2d": 7, "relu6": [7, 8], "relu6_": 7, "relu_": 7, "remaind": 7, "repeat": [7, 83, 127, 340, 367, 368, 399, 430, 431, 432, 440, 451, 465, 532], "repeat_interleav": 7, "reshap": [7, 8, 13, 75, 77, 81, 84, 95, 100, 104, 106, 111, 118, 135, 196, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 323, 326, 349, 360, 369, 370, 374, 393, 395, 396, 471, 476, 477, 478, 479, 482, 490, 491, 501, 503, 525, 533, 536, 537, 541, 542, 543, 553, 567, 570], "reshape_a": 7, "resolve_conj": 7, "resolve_neg": 7, "rnn_relu": 7, "rnn_tanh": 7, "roll": [7, 229, 230, 231, 232, 233, 239, 240, 241, 243], "round": [7, 106, 208, 209, 229, 230, 231, 232, 233, 237, 238, 239, 240, 241, 243, 290, 294, 341, 343, 348, 349, 368, 388, 413, 414, 415, 416, 417, 418, 420, 466, 467], "rsqrt": 7, "rsub": 7, "scalarimplicit": 7, "scaled_dot_product_attent": [7, 440], "scatter": [7, 388, 389, 392, 541], "scatter_": 7, "scatter_add": 7, "scatter_add_": 7, "scatter_reduc": 7, "scatter_reduce_": 7, "selu": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "selu_": 7, "sigmoid": [7, 8, 77, 113, 115, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 249, 250, 262, 361, 362, 433, 434, 435, 436, 438, 439, 528, 530], "sigmoid_": 7, "sign": [7, 8, 11, 13, 117, 135, 148, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 270, 278, 282, 284, 341, 368, 419, 466, 467, 468, 473, 539], "silu": 7, "silu_": 7, "sin": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "sin_": 7, "sinh": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "sinh_": 7, "slice": [7, 8, 229, 230, 231, 232, 233, 240, 241, 243, 347, 348, 349, 355, 360, 376, 377, 378, 380, 381, 386, 390, 391, 398, 401, 407, 408, 409, 446, 447, 448, 449, 460, 461, 462], "softmax": [7, 8, 96, 123, 135, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 252, 333, 432, 440, 529, 545], "softplu": [7, 8, 122, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243, 253], "sort": [7, 118, 222, 308, 320, 321, 323, 326, 330, 331, 340, 367, 371, 372, 401, 408, 409, 432, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 502], "split_with_s": 7, "sqrt": [7, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 247, 248, 325, 403, 404, 405, 406, 408, 409, 410, 440], "squar": [7, 106, 120, 290, 291, 319, 327, 328, 344, 368, 405, 410, 422, 559], "squeez": [7, 8, 13, 77, 122, 135, 198, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 369, 529], "stack": [7, 15, 375, 519, 540], "std": [7, 16, 96, 210, 219, 220, 270, 470, 516, 544, 548, 550, 551, 569, 571], "std_mean": 7, "sub": [7, 8, 78, 82, 106, 118, 122, 216, 220, 222, 225, 319, 355, 390, 542, 543, 544, 562, 572], "sub_": 7, "sum": [7, 8, 10, 226, 274, 340, 341, 361, 362, 367, 373, 387, 388, 390, 398, 402, 405, 407, 408, 409, 410, 421, 422, 429, 432, 433, 434, 435, 436, 438, 439, 446, 447, 448, 449, 453, 463, 464, 465, 546, 555, 566], "swapax": 7, "t_": 7, "take_along_dim": 7, "tan": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "tan_": 7, "tanh": [7, 8, 98, 122, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 247, 248, 253, 361, 362, 433, 434, 435, 436, 438, 439], "tanh_": 7, "tensor_split": 7, "tile": [7, 8, 122, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 543, 562], "topk": [7, 8, 118, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 450], "transpos": [7, 118, 135, 183, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 314, 323, 326, 367, 368, 369, 370, 374, 393, 395, 396, 438, 440, 564], "tril": 7, "tril_": 7, "triu": [7, 440], "triu_": 7, "type_a": 7, "unbind": 7, "unflatten": 7, "unfold": 7, "unsqueez": [7, 8, 96, 122, 135, 199, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 369, 529], "unsqueeze_": 7, "upsample_bicubic2d": 7, "upsample_bilinear2d": 7, "upsample_linear1d": 7, "upsample_nearest1d": 7, "upsample_nearest2d": 7, "upsample_nearest3d": 7, "upsample_trilinear3d": 7, "var": [7, 127, 403, 404, 482, 540], "var_mean": 7, "view": [7, 10, 81, 118, 471, 473, 493, 513, 539, 545, 552, 571], "view_a": 7, "where": [7, 9, 12, 14, 75, 77, 78, 81, 90, 93, 95, 97, 100, 101, 104, 105, 106, 107, 111, 114, 115, 117, 118, 120, 122, 123, 127, 130, 132, 167, 208, 213, 220, 222, 223, 226, 242, 245, 247, 248, 249, 250, 251, 252, 254, 256, 258, 259, 260, 262, 290, 295, 296, 297, 298, 311, 312, 314, 315, 316, 319, 321, 325, 340, 341, 342, 347, 348, 349, 354, 360, 367, 368, 370, 373, 374, 375, 376, 377, 378, 379, 380, 381, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 400, 401, 402, 403, 404, 406, 408, 409, 410, 416, 417, 419, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 437, 441, 444, 445, 446, 447, 448, 449, 455, 456, 457, 458, 459, 466, 467, 468, 479, 493, 496, 499, 500, 502, 504, 516, 518, 524, 526, 527, 529, 530, 532, 535, 539, 540, 541, 542, 543, 545, 552, 553, 558, 559, 560, 568, 570], "zero_": 7, "zero": [7, 13, 92, 100, 117, 130, 208, 209, 245, 275, 278, 282, 286, 287, 309, 310, 314, 316, 318, 320, 321, 323, 324, 339, 340, 341, 343, 344, 349, 354, 358, 368, 375, 377, 378, 383, 384, 395, 398, 401, 403, 404, 406, 407, 408, 409, 410, 413, 414, 430, 440, 441, 446, 447, 448, 449, 463, 465, 473, 496, 499, 518, 519, 524, 542, 551, 552, 555, 570], "zeros_lik": 7, "prim": 7, "constant": [7, 13, 78, 81, 83, 100, 103, 106, 117, 118, 122, 124, 130, 131, 132, 135, 167, 171, 222, 224, 225, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 349, 355, 357, 383, 384, 401, 403, 404, 440, 444, 445, 530, 543, 545, 570], "dictconstruct": 7, "getattr": 7, "If": [7, 10, 14, 74, 75, 78, 79, 81, 82, 83, 84, 85, 90, 91, 93, 95, 96, 99, 101, 103, 105, 106, 111, 115, 118, 120, 122, 123, 126, 127, 128, 129, 131, 132, 135, 139, 148, 167, 210, 213, 217, 218, 220, 222, 225, 226, 229, 230, 231, 232, 233, 240, 241, 242, 243, 254, 274, 286, 290, 295, 296, 297, 298, 308, 314, 316, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 333, 335, 336, 337, 338, 339, 340, 341, 343, 348, 353, 355, 357, 358, 360, 361, 362, 367, 368, 369, 371, 372, 374, 377, 378, 384, 385, 387, 388, 389, 390, 391, 392, 394, 396, 398, 399, 401, 408, 409, 410, 415, 416, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 436, 439, 440, 441, 444, 446, 447, 448, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 460, 462, 463, 464, 465, 468, 472, 473, 474, 475, 477, 478, 479, 480, 484, 485, 487, 488, 489, 492, 495, 496, 498, 499, 500, 502, 504, 505, 506, 508, 509, 515, 516, 518, 522, 523, 524, 525, 526, 529, 530, 533, 534, 535, 536, 537, 539, 540, 541, 542, 543, 544, 545, 548, 551, 559, 560, 562, 563, 564, 565, 567, 568, 570, 571, 572], "is_cuda": 7, "listconstruct": 7, "listunpack": 7, "loop": [7, 10, 122, 229, 230, 231, 232, 233, 237, 238, 239, 240, 241, 243, 340, 360, 497, 499, 502, 537, 538, 543, 544, 564, 569], "numtotensor": 7, "pythonop": 7, "requires_grad": 7, "tupleconstruct": 7, "tupleindex": 7, "tupleunpack": 7, "add_relu": 7, "conv2d_relu": 7, "torchvis": [7, 77, 80, 85, 114, 525, 529, 532], "deform_conv2d": 7, "roi_align": 7, "standard": [7, 16, 112, 113, 115, 116, 118, 119, 129, 131, 216, 368, 371, 372, 398, 466, 482, 505, 506, 508, 509, 510, 526, 527, 528, 530, 531, 534, 542, 557, 560, 571], "And": [7, 8, 132, 221, 222, 226, 326, 385, 488, 568], "averagepool": 7, "batchnorm": [7, 8, 81], "bitshift": 7, "cast": [7, 13, 217, 218, 341, 343], "castlik": 7, "constantofshap": 7, "conv": 7, "convinteg": 7, "convtranspos": 7, "constantfil": 7, "depthtospac": [7, 8, 135, 177, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "dequantizelinear": 7, "equal": [7, 8, 78, 82, 100, 106, 109, 111, 115, 117, 118, 119, 120, 121, 122, 123, 132, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 254, 258, 259, 266, 274, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 300, 301, 303, 306, 308, 309, 312, 313, 315, 316, 317, 319, 320, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 333, 335, 336, 337, 338, 339, 340, 341, 342, 343, 345, 346, 350, 351, 356, 362, 363, 365, 366, 367, 368, 369, 370, 372, 375, 376, 377, 378, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 397, 398, 399, 402, 403, 404, 407, 408, 413, 414, 415, 416, 417, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 437, 441, 442, 443, 444, 446, 447, 448, 450, 452, 453, 454, 455, 459, 461, 526, 543, 567, 571], "eyelik": 7, "gatherel": [7, 229, 230, 231, 232, 233, 238, 239, 240, 241, 243], "gathernd": [7, 100, 229, 230, 231, 232, 233, 240, 241, 243, 344], "gemm": [7, 8], "globalaveragepool": 7, "globallppool": 7, "globalmaxpool": 7, "greater": [7, 8, 132, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 254, 274, 309, 320, 321, 337, 348, 349, 370, 379, 380, 381, 383, 384, 386, 388, 393, 394, 398, 403, 404, 420, 432, 437, 452, 453, 454, 455, 456, 457, 458, 459, 468, 541, 542], "hardmax": 7, "ident": [7, 10, 13, 77, 81, 83, 110, 129, 130, 132, 309, 339, 368, 377, 378, 421, 422, 423, 424, 425, 426, 427, 428, 429, 483, 536], "imagescal": 7, "instancenorm": 7, "leakyrelu": 7, "less": [7, 8, 10, 103, 132, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 322, 323, 324, 326, 330, 331, 333, 340, 348, 349, 377, 378, 381, 388, 389, 398, 399, 431, 450, 456, 457, 458, 468, 497, 523, 524, 526, 532, 541, 551, 552, 564, 567, 568], "logsoftmax": [7, 8, 229, 230, 231, 232, 233, 237, 238, 239, 240, 241, 243], "lpnormal": 7, "matmulinteg": 7, "maxpool": [7, 135, 188, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 418], "meanvariancenorm": 7, "mod": [7, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 278, 341], "nonmaxsuppress": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 543, 544], "Not": [7, 8, 14, 77, 109, 148, 226, 441, 536, 543, 561, 563, 565], "Or": [7, 132, 548, 560], "onehot": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "qlinearconv": 7, "qlinearmatmul": 7, "quantizelinear": 7, "randomnorm": 7, "randomnormallik": 7, "randomuniform": [7, 229, 230, 231, 232, 233, 240, 241, 243], "randomuniformlik": 7, "reducelogsum": [7, 8], "reducelogsumexp": [7, 8], "reducel1": [7, 8, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "reducel2": [7, 8, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "reducemax": [7, 8, 135, 191, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 252], "reducemean": [7, 8, 135, 192, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 408, 409], "reducemin": [7, 8, 135, 193, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "reduceprod": [7, 8, 118, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "reducesum": [7, 8, 135, 194, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 252, 464], "reducesumsquar": [7, 8], "resiz": [7, 67, 97, 101, 108, 117, 336, 348, 349, 441, 501, 502, 535, 557, 558, 559, 561], "reversesequ": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "rnn": [7, 8, 100, 355, 362, 434, 436, 438, 439, 569, 570], "roialign": [7, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243, 325], "scatterel": 7, "scatternd": 7, "shrink": [7, 398], "softsign": [7, 8, 229, 230, 231, 232, 233, 241, 243], "spacetodepth": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "thresholdedrelu": [7, 132], "xor": [7, 226, 298, 341, 366, 390], "deprec": [7, 14, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 220, 475, 525, 542], "crop": [7, 8, 370, 384, 550, 560], "upsampl": [7, 8], "org": [7, 14, 75, 95, 104, 108, 127, 406, 473, 477, 478, 479, 491, 492, 496, 500, 514, 529], "openvinotoolkit": [7, 13, 14, 127, 477, 478, 479, 496, 500], "deformableconv2d": 7, "detectionoutput": [7, 8, 83, 87, 89, 106, 107, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 543, 544], "experimentaldetectrondetectionoutput": [7, 243], "experimentaldetectrongenerateproposalssingleimag": [7, 243], "experimentaldetectrongroupnorm": 7, "experimentaldetectronpriorgridgener": [7, 243], "experimentaldetectronroifeatureextractor": [7, 243], "experimentaldetectrontopkroi": [7, 243], "fakequant": [7, 8, 10, 136, 138, 141, 148, 163, 167, 189, 209, 225, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "groupnorm": [7, 231, 232, 233, 243], "priorbox": [7, 8, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "priorboxclust": [7, 8, 106, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "swish": [7, 118, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243, 251], "microsoft": [7, 13, 15, 479, 496, 499, 504, 516, 544], "attent": [7, 13, 94, 361, 362, 440, 497, 499, 553, 571], "biasgelu": 7, "embedlayernorm": 7, "skiplayernorm": 7, "v": [7, 127, 345, 346, 351, 475, 477, 541, 554, 555], "1": [7, 9, 10, 11, 12, 15, 71, 74, 77, 78, 80, 81, 82, 84, 87, 89, 90, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 120, 122, 123, 129, 130, 132, 163, 167, 208, 213, 224, 226, 227, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 473, 481, 482, 486, 496, 498, 502, 505, 506, 507, 508, 509, 510, 513, 515, 524, 525, 528, 529, 532, 533, 536, 537, 538, 539, 540, 541, 542, 543, 545, 547, 548, 551, 556, 557, 558, 559, 560, 564, 570, 572], "arg_max": 7, "int32": [7, 83, 110, 274, 308, 310, 322, 339, 341, 355, 379, 387, 390, 391, 401, 408, 409, 411, 412, 414, 416, 417, 431, 432, 437, 443, 446, 447, 448, 449, 451, 452, 453, 455, 457, 458, 461, 462, 463, 464, 465, 466, 467, 500], "data_typ": [7, 123, 124, 224], "adaptive_pool2d": 7, "data_layout": 7, "assign": [7, 100, 104, 127, 132, 135, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243, 340, 357, 358, 509, 529, 539, 541, 546, 559, 569, 570], "assign_valu": 7, "bicubic_interp": 7, "bilinear_interp": 7, "ncw": 7, "nwc": 7, "ndhwc": 7, "box_cod": 7, "conditional_block": 7, "conv2d_transpos": 7, "deformable_conv": 7, "depthwise_conv2d": 7, "depthwise_conv2d_transpos": 7, "elementwise_add": 7, "elementwise_div": 7, "elementwise_floordiv": 7, "elementwise_max": 7, "elementwise_min": 7, "elementwise_mod": 7, "elementwise_mul": 7, "elementwise_pow": 7, "elementwise_sub": 7, "fill_any_lik": 7, "fill_const": 7, "fill_constant_batch_size_lik": 7, "flatten_contiguous_rang": 7, "gather_nd": 7, "generate_propos": 7, "greater_equ": 7, "greater_than": 7, "hard_sigmoid": 7, "hard_swish": 7, "less_than": 7, "linear_interp": 7, "lookup_t": 7, "matrix_nm": 7, "box": [7, 13, 78, 86, 87, 89, 96, 98, 106, 118, 120, 129, 130, 131, 132, 319, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 451, 452, 453, 454, 455, 456, 457, 458, 459, 496, 498, 508, 526, 539, 550, 569], "static": [7, 8, 16, 84, 113, 123, 130, 211, 218, 341, 360, 481, 488, 502, 511, 514, 515, 516, 526, 528, 533, 535, 536, 542, 543, 544, 547, 548, 551], "e": [7, 12, 13, 14, 15, 84, 100, 118, 122, 126, 127, 132, 208, 209, 213, 216, 245, 246, 252, 253, 256, 257, 258, 259, 260, 262, 276, 294, 315, 316, 325, 340, 343, 348, 349, 380, 398, 399, 403, 404, 420, 440, 463, 465, 467, 470, 477, 490, 497, 499, 522, 524, 529, 536, 539, 540, 541, 542, 543, 544, 546, 553, 554, 555, 557, 560, 562, 566, 568], "g": [7, 12, 13, 14, 76, 83, 95, 118, 126, 127, 132, 208, 209, 213, 216, 315, 316, 325, 343, 346, 348, 349, 351, 361, 362, 399, 406, 420, 432, 433, 435, 448, 463, 465, 467, 497, 499, 502, 516, 522, 536, 539, 540, 541, 542, 543, 546, 553, 554, 555, 557, 560, 562, 566, 568], "num_box": [7, 332, 451, 452, 453, 454, 455, 456, 457, 458, 459], "nms_top_k": [7, 451, 452, 453], "num_classes_output": 7, "keep_top_k": [7, 320, 321, 451, 452, 453], "max_pool2d_with_index": 7, "multiclass_nm": 7, "nearest_interp": 7, "not_equ": 7, "p_norm": 7, "pad3d": 7, "circular": 7, "pool2d": 7, "prior_box": 7, "reduce_max": 7, "reduce_mean": 7, "reduce_min": 7, "reduce_prod": 7, "reduce_sum": 7, "revers": [7, 77, 101, 106, 111, 235, 236, 237, 243, 274, 345, 350, 360, 362, 370, 376, 377, 378, 382, 386, 388, 390, 394, 398, 419, 434, 436, 439, 502, 505, 506, 508, 509, 560], "simplernn": 7, "scale": [7, 13, 77, 78, 94, 96, 106, 111, 119, 126, 208, 245, 256, 319, 330, 331, 332, 335, 336, 337, 348, 349, 403, 404, 406, 407, 419, 440, 493, 497, 502, 537, 555, 557, 558, 559], "select_input": 7, "strided_slic": 7, "sync_batch_norm": 7, "top_k": [7, 96, 320, 321, 460, 461, 462], "trilinear_interp": 7, "where_index": 7, "while": [7, 9, 10, 13, 15, 76, 81, 103, 106, 111, 113, 118, 119, 120, 127, 132, 208, 212, 226, 355, 369, 371, 372, 431, 468, 470, 471, 473, 492, 496, 497, 502, 512, 513, 514, 518, 522, 524, 525, 528, 529, 539, 541, 543, 545, 546, 548, 549, 550, 552, 553, 555, 556, 562, 566, 567, 569, 570, 571], "yolo_box": 7, "addv2": 7, "addn": 7, "assert": [7, 103, 349], "need": [7, 9, 14, 15, 74, 75, 77, 80, 81, 82, 85, 86, 90, 91, 95, 99, 100, 103, 106, 107, 110, 111, 113, 114, 118, 122, 127, 128, 129, 130, 131, 132, 134, 210, 212, 213, 214, 216, 219, 220, 222, 223, 348, 367, 372, 406, 407, 472, 476, 477, 478, 479, 480, 481, 482, 483, 487, 488, 490, 491, 492, 494, 497, 498, 499, 502, 504, 505, 506, 508, 509, 510, 511, 512, 514, 515, 516, 518, 519, 520, 521, 522, 524, 527, 529, 530, 532, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551, 553, 554, 555, 556, 557, 560, 562, 563, 565, 566, 567, 569, 572], "assignsub": 7, "avgpool": [7, 122, 135, 137, 148, 187, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 418], "avgpoolv2": 7, "foldabl": 7, "kernel_s": 7, "stride": [7, 81, 123, 218, 224, 312, 313, 314, 315, 316, 317, 318, 324, 334, 360, 375, 398, 413, 414, 415, 416, 417, 418], "avgpool3d": 7, "batchmatmul": 7, "batchmatmulv2": 7, "batchtospacend": 7, "biasadd": [7, 105], "blocklstm": [7, 100, 570], "broadcastto": 7, "clipbyvalu": 7, "concatv2": 7, "const": [7, 8, 49, 103, 117, 118, 120, 122, 124, 130, 212, 213, 224, 226, 341, 360, 470, 516, 569, 570], "conv2dbackpropinput": 7, "conv3dbackpropinputv2": 7, "cropandres": 7, "bilinear": [7, 316, 319, 332, 335, 336, 337, 338, 344], "ctcgreedydecod": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 431], "decod": [7, 10, 12, 83, 93, 96, 97, 103, 330, 331, 333, 382, 430, 431, 432, 498, 500, 544, 555, 571, 572], "indic": [7, 9, 11, 87, 89, 103, 109, 124, 127, 308, 310, 314, 318, 319, 320, 321, 322, 326, 332, 335, 336, 337, 338, 340, 347, 348, 349, 371, 372, 376, 377, 378, 379, 380, 381, 382, 383, 385, 387, 388, 389, 390, 391, 392, 394, 398, 401, 407, 408, 409, 410, 412, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 437, 440, 444, 445, 446, 447, 448, 449, 451, 452, 453, 460, 461, 462, 463, 464, 465, 479, 524, 539, 543, 551], "dens": [7, 98], "ctcloss": [7, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "depthwiseconv2dn": 7, "equat": [7, 260, 367, 368, 379], "label": [7, 14, 95, 111, 126, 320, 321, 367, 430, 431, 432, 471, 496, 504, 506, 509, 510, 522, 539, 541, 545, 546], "within": [7, 9, 12, 14, 82, 88, 127, 216, 226, 244, 316, 329, 340, 379, 386, 388, 389, 390, 391, 392, 395, 397, 415, 416, 417, 418, 454, 468, 493, 496, 499, 501, 517, 522, 523, 525, 529, 543, 544, 551, 553, 555, 564, 571], "subscript": [7, 367], "emptytensorlist": 7, "when": [7, 9, 10, 12, 13, 14, 15, 74, 77, 79, 80, 81, 83, 84, 85, 101, 103, 106, 111, 113, 115, 118, 120, 122, 123, 127, 129, 130, 132, 212, 216, 220, 221, 222, 225, 226, 242, 245, 260, 312, 313, 314, 315, 316, 317, 318, 320, 321, 332, 333, 335, 336, 340, 348, 349, 360, 371, 372, 380, 381, 390, 392, 398, 401, 408, 409, 410, 413, 414, 415, 416, 417, 433, 437, 439, 448, 449, 451, 452, 453, 455, 459, 461, 466, 468, 472, 473, 477, 478, 479, 482, 496, 498, 502, 504, 505, 506, 508, 509, 511, 512, 515, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 532, 533, 535, 536, 538, 539, 540, 541, 542, 543, 544, 546, 547, 550, 551, 552, 553, 555, 556, 557, 558, 560, 562, 564, 566, 567, 569, 571, 572], "part": [7, 9, 10, 13, 15, 73, 78, 82, 84, 85, 97, 102, 103, 109, 111, 118, 120, 129, 131, 135, 136, 208, 209, 220, 224, 226, 310, 315, 316, 348, 349, 355, 360, 402, 438, 448, 499, 513, 518, 526, 542, 543, 545, 552, 555, 557, 566, 571, 572], "graph": [7, 9, 10, 13, 76, 78, 80, 81, 82, 85, 96, 98, 99, 102, 103, 104, 105, 106, 108, 110, 115, 118, 119, 121, 123, 124, 131, 132, 133, 212, 216, 219, 220, 222, 224, 225, 226, 355, 502, 519, 520, 522, 526, 529, 530, 532, 541, 543, 544, 545, 547, 551, 557, 558, 560, 570, 572], "special": [7, 82, 96, 103, 106, 115, 118, 124, 208, 209, 220, 222, 226, 312, 331, 355, 360, 441, 468, 517, 521, 522, 530, 535, 537, 542, 545, 551, 553, 567, 568, 569], "form": [7, 10, 83, 100, 115, 130, 209, 225, 226, 367, 368, 380, 381, 398, 406, 419, 437, 446, 447, 448, 449, 497, 513, 514, 529, 530, 541, 543, 569, 571], "enter": [7, 13, 473, 496, 539], "fuse": [7, 10, 13, 81, 118, 122, 135, 167, 208, 213, 220, 222, 360, 497, 498, 543], "tensoriter": [7, 8, 122, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 355, 544, 569], "exit": [7, 81, 98, 103, 118, 122, 129, 502, 509, 541, 564], "expanddim": 7, "experimentalsparseweightedsum": 7, "extractimagepatch": [7, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "euclideannorm": 7, "fakequantwithminmaxvar": 7, "fakequantwithminmaxvarsperchannel": 7, "fft": 7, "fft2d": 7, "fft3d": 7, "fifoqueuev2": 7, "floormod": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "fusedbatchnorm": [7, 10, 135], "fusedbatchnormv2": 7, "fusedbatchnormv3": 7, "gathertre": [7, 8, 103, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "gatherv2": 7, "greaterequ": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "identityn": 7, "ifft": 7, "ifft2d": 7, "ifft3d": 7, "iteratorgetnext": [7, 98, 103, 109], "lessequ": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "logicaland": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 295], "logicalor": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 297], "logicalnot": [7, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 296, 440], "lookuptableinsertv2": 7, "loopcond": 7, "maxpoolv2": 7, "maxpool3d": 7, "merg": [7, 83, 126, 430, 431, 432], "mirrorpad": 7, "nextiter": 7, "nonmaxsuppressionv2": 7, "nonmaxsuppressionv3": 7, "nonmaxsuppressionv4": 7, "nonmaxsuppressionv5": 7, "notequ": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "noop": 7, "pack": [7, 13, 122, 527, 542, 553], "padv2": 7, "placehold": [7, 81, 98, 100, 102, 104, 110, 115, 129, 132, 530], "placeholderwithdefault": 7, "queuedequeu": 7, "queuedequeueuptov2": 7, "queuedequeuev2": 7, "randomuniformint": 7, "rank": [7, 114, 118, 242, 254, 259, 266, 274, 275, 283, 288, 292, 310, 312, 313, 314, 315, 316, 317, 318, 333, 348, 349, 367, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 384, 385, 386, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 405, 408, 409, 410, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 437, 441, 442, 443, 444, 445, 446, 447, 448, 449, 461, 462, 468, 498, 542, 543, 551], "realdiv": 7, "resizebilinear": 7, "resizenearestneighbor": 7, "resourcegath": [7, 105], "reversev2": 7, "selectv2": 7, "spacetobatchnd": 7, "sparsefillemptyrow": 7, "sparsereshap": 7, "sparsesegmentsum": 7, "sparsesegmentmean": 7, "sparsetodens": 7, "splitv": 7, "squareddiffer": [7, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "axi": [7, 81, 118, 122, 123, 132, 242, 252, 258, 259, 274, 312, 313, 314, 315, 316, 317, 318, 333, 336, 348, 349, 355, 360, 369, 370, 371, 372, 373, 376, 377, 378, 379, 383, 384, 385, 387, 388, 389, 392, 393, 394, 395, 397, 398, 399, 401, 402, 403, 404, 410, 413, 414, 415, 416, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 434, 436, 437, 439, 440, 446, 447, 448, 449, 451, 460, 461, 462, 464], "specifi": [7, 10, 15, 75, 77, 78, 80, 81, 85, 86, 87, 89, 91, 95, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 118, 122, 123, 124, 130, 131, 132, 148, 213, 220, 222, 224, 226, 248, 266, 274, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 303, 305, 306, 307, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 338, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 398, 399, 400, 401, 402, 406, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 466, 488, 492, 498, 502, 504, 505, 506, 508, 509, 510, 511, 512, 515, 518, 522, 524, 525, 526, 528, 529, 530, 532, 533, 535, 536, 537, 539, 540, 541, 542, 543, 545, 546, 548, 550, 552, 553, 556, 557, 559, 560, 562, 563, 565, 567, 568, 570, 571], "statelesswhil": 7, "stopgradi": 7, "stridedslic": [7, 8, 135, 182, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "begin": [7, 13, 100, 127, 132, 221, 224, 245, 254, 256, 260, 312, 313, 314, 315, 316, 317, 318, 333, 346, 347, 348, 349, 351, 354, 360, 370, 375, 383, 384, 395, 398, 411, 412, 413, 414, 415, 416, 417, 448, 471, 494, 519, 520, 539, 542], "swish_f32": 7, "switch": [7, 102, 109, 111, 114, 127, 477, 478, 493, 498, 504, 525, 529, 542, 562, 565], "control": [7, 9, 10, 13, 85, 132, 303, 340, 344, 388, 401, 441, 460, 461, 462, 468, 474, 495, 498, 516, 519, 520, 521, 522, 524, 526, 532, 539, 542, 544, 552, 553, 555, 556, 569, 572], "flow": [7, 82, 84, 111, 132, 224, 226, 360, 521, 523, 539, 541, 552, 553, 555, 556, 560, 563, 566, 572], "propag": [7, 117, 118, 123, 135, 148, 167, 171, 208, 220, 535, 536, 543], "tensorarraygatherv3": [7, 97], "tensorarrayreadv3": 7, "tensorarrayscatterv3": 7, "tensorarraysizev3": 7, "tensorarrayv3": 7, "tensorarraywritev3": 7, "tensorlistpushback": 7, "topkv2": [7, 132], "unpack": [7, 13, 14, 100, 108, 225, 542], "variabl": [7, 13, 83, 95, 96, 98, 99, 100, 103, 104, 108, 109, 110, 113, 115, 118, 120, 122, 127, 219, 220, 352, 353, 357, 358, 386, 477, 478, 479, 482, 492, 502, 504, 516, 528, 530, 540, 545, 548, 549, 551, 554, 569, 572], "variablev2": [7, 13], "zeroslik": 7, "add_n": 7, "arg_min": 7, "average_pool_2d": 7, "batch_matmul": 7, "batch_to_space_nd": 7, "broadcast_arg": 7, "complex_ab": 7, "rfft2d": 7, "concaten": [7, 118, 130, 148, 163, 317, 318, 326, 355, 360, 362, 367, 373, 431, 433, 434, 435, 436, 439, 560, 570], "conv_2d": 7, "depth_to_spac": 7, "depthwise_conv_2d": 7, "expand_dim": 7, "floor_div": 7, "floor_mod": 7, "fully_connect": 7, "l2_normal": 7, "less_equ": 7, "logist": [7, 8], "matrix_diag": 7, "max_pool_2d": 7, "mirror_pad": 7, "reduce_al": 7, "reduce_ani": 7, "resize_bilinear": 7, "resize_nearest_neighbor": 7, "reverse_v2": 7, "scatter_nd": 7, "segment_sum": [7, 465], "select_v2": 7, "space_to_batch_nd": 7, "space_to_depth": 7, "split_v": 7, "squared_differ": 7, "topk_v2": 7, "transpose_conv": 7, "uniqu": [7, 83, 104, 118, 122, 123, 135, 220, 229, 230, 231, 232, 233, 243, 308, 340, 349, 368, 394, 398, 408, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 466, 469, 539, 542, 548, 553, 565], "tensorflow2": [7, 75, 115, 492, 530, 570], "activityregular": 7, "additiveattent": 7, "alphadropout": 7, "averagepooling1d": 7, "averagepooling2d": 7, "averagepooling3d": 7, "bidirect": [7, 98, 110, 362, 372, 434, 436, 439], "conv1dtranspos": 7, "dilat": [7, 8, 81, 224, 312, 313, 314, 315, 316, 317, 318, 375, 416, 417, 418], "conv2dtranspos": 7, "conv3dtranspos": 7, "cropping1d": 7, "cropping2d": 7, "cropping3d": 7, "densefeatur": 7, "categor": [7, 109], "featur": [7, 9, 13, 14, 15, 16, 83, 85, 95, 106, 109, 111, 114, 117, 127, 129, 130, 134, 148, 208, 216, 220, 224, 312, 313, 315, 316, 317, 320, 321, 324, 325, 326, 331, 332, 335, 336, 337, 338, 355, 374, 375, 413, 414, 415, 416, 417, 475, 488, 492, 494, 495, 497, 498, 499, 502, 507, 508, 524, 529, 533, 534, 536, 538, 539, 552, 553, 554, 561, 562, 563, 565, 570, 572], "depthwiseconv2d": 7, "grucel": [7, 8, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243, 361, 434], "gaussiandropout": 7, "gaussiannois": 7, "globalaveragepooling1d": 7, "globalaveragepooling2d": 7, "globalaveragepooling3d": 7, "globalmaxpool1d": 7, "globalmaxpool2d": 7, "globalmaxpool3d": 7, "lstmcell": [7, 8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 360, 436], "lambda": [7, 96, 123, 222, 256, 390], "layernorm": 7, "locallyconnected1d": 7, "locallyconnected2d": 7, "maxpool1d": 7, "maxpool2d": 7, "cell": [7, 100, 104, 320, 321, 324, 361, 362, 433, 434, 435, 436, 438, 439, 569, 570], "repeatvector": 7, "separableconv1d": 7, "separableconv2d": 7, "simplernncel": 7, "spatialdropout1d": 7, "spatialdropout2d": 7, "spatialdropout3d": 7, "stackedrnncel": 7, "subtract": [7, 82, 83, 108, 135, 167, 170, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 291, 340, 398, 408, 409, 419, 502, 557, 559, 560], "timedistribut": 7, "upsampling1d": 7, "upsampling2d": [7, 13], "upsampling3d": 7, "zeropadding1d": 7, "zeropadding2d": 7, "zeropadding3d": 7, "present": [8, 9, 11, 12, 80, 81, 82, 83, 84, 90, 91, 109, 127, 135, 225, 321, 360, 369, 388, 398, 416, 417, 432, 470, 483, 515, 529, 533, 535, 539, 546, 550, 551, 552, 560], "tabl": [8, 10, 11, 12, 108, 109, 130, 135, 227, 463, 464, 465, 496, 497, 514, 515, 524, 536, 539, 542], "most": [8, 10, 13, 14, 16, 74, 77, 79, 83, 100, 106, 113, 115, 117, 118, 122, 130, 135, 136, 213, 220, 226, 262, 367, 368, 369, 390, 391, 431, 434, 436, 439, 451, 452, 453, 474, 497, 499, 500, 504, 513, 514, 520, 521, 523, 524, 525, 526, 529, 534, 537, 539, 540, 541, 542, 544, 548, 551, 555, 556, 558, 565, 566, 567, 568, 569, 570], "recent": [8, 13, 14, 74, 474], "implement": [8, 9, 10, 13, 76, 81, 82, 95, 96, 99, 101, 103, 106, 111, 118, 119, 120, 122, 123, 124, 127, 129, 131, 132, 133, 135, 148, 167, 208, 210, 212, 213, 216, 217, 219, 220, 226, 341, 367, 368, 388, 431, 432, 434, 436, 439, 440, 452, 453, 461, 470, 471, 483, 497, 502, 517, 518, 522, 524, 525, 526, 529, 534, 541, 542, 543, 544, 549, 554, 555, 556, 557, 560, 561, 567, 570, 571], "conform": [8, 127, 216], "report": [8, 9, 14, 83, 96, 135, 222, 502, 507, 511, 512, 523, 526, 536, 541, 543, 565], "leaki": [8, 130], "binaryconvolut": [8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "broadcast": [8, 127, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 254, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 363, 365, 366, 367, 369, 419, 420, 440], "3d": [8, 13, 130, 313, 314, 317, 318, 320, 321, 323, 348, 349, 362, 367, 368, 379, 388, 389, 394, 398, 411, 412, 413, 414, 415, 416, 417, 418, 434, 436, 439, 446, 447, 448, 449, 547], "ordinari": [8, 83, 506], "deconvolut": 8, "deformableconvolut": [8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "eltwis": [8, 10, 135, 208], "logicalxor": [8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 298], "squareddiff": 8, "fullyconnect": [8, 83, 226, 369, 542], "inner": [8, 316, 367, 368], "grn": [8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "interp": 8, "rnncell": [8, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243, 439], "lstmsequenc": [8, 228, 229, 230, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 243], "grusequ": [8, 229, 230, 231, 232, 233, 237, 238, 239, 240, 241, 243, 362], "rnnsequenc": [8, 229, 230, 231, 232, 233, 237, 238, 239, 240, 241, 243, 438], "pool": [8, 106, 117, 123, 226, 319, 332, 335, 336, 337, 338, 411, 412, 413, 414, 415, 416, 417, 463, 464, 465, 553, 567], "avg": [8, 335, 336], "powerfil": 8, "propos": [8, 83, 106, 119, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 253, 320, 321, 323, 326, 543], "psroipool": [8, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "reduceand": 8, "reduceor": 8, "regionyolo": [8, 111, 122, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "reorgyolo": [8, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "resampl": 8, "roipool": [8, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "scaleshift": [8, 83, 208], "scatterupd": [8, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "shufflechannel": [8, 180, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "simplernm": 8, "spatialtransform": 8, "unpool": 8, "paramet": [8, 9, 10, 13, 52, 53, 55, 57, 58, 59, 62, 64, 65, 66, 67, 69, 75, 79, 80, 82, 86, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 117, 118, 120, 122, 123, 124, 127, 130, 131, 132, 148, 208, 209, 213, 216, 220, 222, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 254, 262, 309, 325, 326, 348, 349, 355, 360, 398, 403, 404, 419, 440, 451, 452, 453, 455, 459, 471, 492, 498, 502, 505, 506, 507, 508, 509, 510, 519, 520, 523, 525, 527, 530, 532, 533, 539, 541, 542, 543, 544, 545, 550, 551, 554, 555, 556, 566, 567, 569, 570, 571], "public": [9, 12, 74, 76, 88, 99, 101, 102, 103, 105, 107, 111, 112, 116, 117, 126, 135, 212, 213, 216, 217, 510, 525, 527, 531, 539], "help": [9, 10, 13, 75, 76, 77, 78, 83, 84, 103, 104, 113, 115, 117, 118, 120, 131, 209, 221, 222, 432, 494, 498, 502, 509, 515, 516, 518, 519, 524, 526, 533, 543, 547, 551, 553, 559, 562, 564, 567, 569], "decid": [9, 129, 212, 355, 477, 478, 479, 502, 513, 515, 516, 545, 569], "plan": [9, 74, 106, 129, 535, 554], "workload": [9, 12, 479, 538, 542, 546, 564], "have": [9, 10, 13, 14, 16, 74, 75, 76, 77, 81, 82, 85, 95, 96, 99, 100, 103, 104, 106, 111, 112, 115, 116, 117, 118, 119, 120, 122, 127, 128, 129, 130, 132, 135, 148, 163, 167, 208, 209, 210, 212, 213, 218, 220, 221, 222, 224, 225, 226, 242, 309, 320, 321, 325, 338, 340, 341, 343, 344, 346, 351, 355, 360, 367, 369, 372, 379, 382, 389, 391, 392, 398, 402, 403, 404, 407, 430, 431, 432, 437, 440, 444, 445, 446, 447, 448, 454, 461, 468, 470, 471, 477, 478, 479, 480, 482, 484, 485, 486, 488, 489, 492, 495, 496, 498, 500, 502, 503, 504, 511, 512, 515, 518, 519, 522, 525, 526, 527, 529, 530, 531, 532, 533, 536, 537, 539, 541, 542, 543, 544, 545, 548, 549, 551, 553, 555, 557, 558, 560, 561, 567, 568, 570, 571], "alreadi": [9, 76, 95, 122, 129, 131, 133, 357, 474, 477, 478, 479, 496, 498, 502, 504, 518, 522, 523, 524, 525, 536, 545, 550, 552, 555, 557, 565, 567], "click": [9, 105, 127, 227, 473, 479, 495, 496, 540], "button": [9, 495, 540], "below": [9, 10, 11, 12, 75, 77, 78, 83, 85, 87, 89, 95, 100, 106, 108, 109, 110, 111, 113, 115, 117, 118, 119, 120, 122, 123, 127, 129, 130, 131, 132, 134, 135, 148, 208, 209, 210, 211, 213, 214, 218, 219, 220, 222, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 322, 325, 355, 360, 367, 388, 389, 393, 408, 440, 451, 452, 453, 454, 455, 456, 457, 458, 459, 471, 473, 477, 478, 479, 481, 482, 487, 491, 496, 497, 498, 499, 502, 504, 509, 514, 515, 517, 518, 519, 520, 522, 523, 524, 526, 528, 529, 530, 532, 534, 535, 536, 539, 541, 542, 543, 544, 545, 547, 548, 550, 555, 556, 557, 558, 559, 560, 567, 570, 571, 572], "chosen": [9, 12, 83, 111, 114, 225, 260, 340, 361, 362, 416, 417, 434, 435, 436, 439, 468, 504, 537, 572], "ovm": [9, 14, 127], "pleas": [9, 11, 15, 77, 103, 113, 126, 131, 132, 135, 208, 222, 316, 325, 398, 401, 418, 502, 505, 506, 508, 509, 510, 516, 526, 549, 552], "visit": [9, 75, 122, 131, 471, 476, 477, 478, 479, 482, 487, 490, 491, 518], "tab": [9, 473, 479, 540], "throughput": [9, 10, 12, 471, 498, 501, 509, 511, 515, 521, 541, 542, 543, 544, 546, 547, 548, 554, 555, 562], "measur": [9, 10, 11, 12, 211, 219, 220, 293, 469, 502, 505, 506, 508, 509, 510, 524, 547, 556, 567], "latenc": [9, 10, 12, 13, 85, 471, 493, 498, 511, 512, 518, 524, 525, 527, 528, 530, 531, 532, 534, 541, 542, 543, 547, 554, 555, 564, 565, 566, 567, 572], "frame": [9, 11, 12, 96, 502, 549, 550, 555, 572], "second": [9, 75, 77, 82, 100, 117, 118, 122, 123, 124, 129, 132, 135, 148, 208, 213, 222, 242, 254, 262, 274, 278, 280, 281, 282, 285, 291, 308, 311, 320, 321, 322, 324, 330, 331, 342, 343, 345, 346, 350, 351, 367, 369, 371, 372, 376, 377, 378, 380, 381, 385, 389, 391, 392, 398, 403, 404, 407, 411, 412, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 441, 444, 445, 446, 447, 448, 449, 453, 463, 465, 468, 502, 511, 512, 519, 524, 529, 536, 541, 550, 559], "trade": [9, 517, 519, 524, 566], "off": [9, 78, 84, 96, 97, 100, 103, 104, 109, 111, 117, 211, 515, 516, 517, 519, 524, 542, 566], "between": [9, 11, 75, 77, 81, 83, 102, 103, 106, 108, 120, 122, 123, 127, 130, 132, 148, 209, 212, 213, 224, 225, 226, 260, 312, 313, 315, 316, 317, 327, 328, 329, 334, 340, 341, 353, 358, 360, 361, 362, 375, 388, 390, 394, 406, 431, 454, 466, 467, 471, 492, 497, 502, 515, 524, 527, 529, 533, 534, 539, 542, 546, 564, 565, 566, 568, 569, 571], "price": 9, "meet": [9, 73, 127, 135, 461, 492, 567], "valu": [9, 10, 11, 13, 75, 80, 94, 95, 96, 100, 102, 103, 104, 106, 109, 111, 114, 117, 118, 119, 120, 122, 123, 124, 130, 132, 135, 136, 137, 138, 139, 140, 141, 142, 148, 171, 208, 209, 211, 212, 213, 216, 222, 223, 224, 242, 244, 245, 248, 252, 254, 258, 259, 260, 262, 263, 266, 274, 275, 278, 280, 281, 282, 283, 285, 286, 288, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 479, 498, 500, 501, 502, 507, 508, 509, 518, 519, 522, 523, 524, 526, 529, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 548, 551, 553, 555, 556, 557, 558, 560, 564, 566, 568, 569, 570, 571], "what": [9, 73, 109, 113, 115, 132, 208, 481, 494, 512, 514, 515, 519, 539, 540, 543, 546, 550, 559, 569], "critic": [9, 13, 496, 541, 542], "dollar": 9, "kpi": [9, 12], "calcul": [9, 11, 13, 106, 118, 122, 123, 131, 171, 208, 242, 248, 249, 250, 251, 252, 255, 257, 258, 259, 260, 271, 274, 275, 277, 294, 312, 313, 314, 315, 316, 317, 318, 319, 322, 324, 327, 328, 329, 330, 331, 335, 336, 337, 338, 341, 343, 344, 348, 349, 355, 360, 375, 380, 381, 387, 388, 403, 404, 406, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 441, 446, 447, 448, 449, 451, 452, 453, 454, 456, 457, 458, 502, 517, 521, 523, 524, 536, 542, 556, 567, 570], "engin": [9, 100, 122, 213, 483, 554], "socket": [9, 13, 127, 502, 542, 556, 562], "2x": [9, 294, 526], "found": [9, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 132, 254, 256, 312, 313, 314, 315, 316, 317, 353, 358, 414, 416, 418, 432, 474, 483, 492, 508, 527, 539, 543, 546, 548, 565, 567, 571], "pdf": [9, 471], "consider": [9, 10, 15, 242, 330, 331, 456, 457, 458, 530], "center": [9, 13, 15, 313, 322, 327, 328, 329, 330, 331, 337, 344, 375, 407, 454, 455, 456, 457, 458, 459, 497], "watt": 9, "excel": 9, "tdp": 9, "dissip": 9, "millisecond": [9, 502, 550], "each": [9, 10, 12, 14, 81, 82, 100, 104, 108, 109, 115, 118, 120, 122, 124, 125, 127, 129, 130, 132, 135, 208, 216, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 249, 250, 251, 255, 257, 271, 277, 286, 294, 295, 296, 297, 298, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 326, 327, 328, 329, 330, 331, 333, 335, 336, 337, 338, 340, 341, 344, 345, 346, 347, 350, 351, 353, 355, 358, 360, 362, 367, 368, 369, 370, 371, 372, 375, 379, 382, 383, 384, 385, 386, 387, 388, 389, 392, 394, 395, 398, 399, 401, 402, 403, 404, 406, 407, 408, 410, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 434, 436, 439, 440, 444, 448, 449, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 479, 496, 499, 500, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512, 515, 516, 522, 524, 525, 529, 530, 532, 534, 536, 539, 540, 541, 542, 543, 544, 545, 548, 550, 551, 553, 555, 556, 557, 559, 560, 562, 564, 565, 566, 567, 569, 570, 571], "postprocess": [9, 13, 96, 212, 219, 545, 557, 558], "complet": [9, 13, 14, 15, 83, 95, 108, 111, 115, 127, 129, 132, 133, 210, 213, 222, 226, 227, 314, 382, 488, 502, 504, 509, 534, 543, 544, 546, 549, 550, 551, 555, 566, 569], "next": [9, 12, 13, 14, 83, 88, 118, 129, 131, 132, 135, 136, 148, 208, 212, 213, 216, 217, 218, 219, 226, 314, 340, 352, 353, 355, 360, 367, 416, 417, 446, 447, 448, 449, 456, 457, 458, 496, 504, 519, 520, 523, 536, 539, 542, 546, 555, 567, 569], "start": [9, 10, 13, 76, 78, 106, 109, 118, 120, 126, 128, 130, 209, 220, 226, 242, 312, 313, 315, 316, 325, 333, 340, 342, 343, 355, 360, 368, 370, 377, 378, 380, 381, 387, 392, 394, 395, 398, 401, 411, 412, 413, 414, 415, 416, 417, 418, 430, 463, 473, 476, 477, 478, 479, 482, 483, 490, 491, 493, 494, 495, 496, 497, 498, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 539, 540, 543, 550, 555, 556, 562, 567, 569], "metric": [9, 11, 13, 16, 496, 501, 502, 507, 517, 521, 541, 543, 547, 556, 568], "scenario": [9, 12, 76, 83, 216, 469, 497, 499, 511, 516, 526, 535, 536, 541, 542, 543, 544, 550, 555, 556, 562, 566, 567, 569], "act": [9, 127, 502, 546, 567], "upon": [9, 10, 13, 550, 553, 555, 562], "soon": 9, "possibl": [9, 10, 13, 75, 77, 81, 106, 114, 115, 122, 127, 129, 132, 135, 312, 313, 315, 316, 317, 375, 413, 414, 415, 416, 417, 419, 432, 451, 452, 453, 454, 455, 459, 468, 470, 492, 502, 518, 525, 526, 530, 537, 541, 542, 543, 544, 549, 550, 553, 554, 555, 556, 557, 558, 562, 564, 566, 567, 568, 569, 570, 572], "would": [9, 10, 135, 310, 398, 468, 498, 536, 538, 541, 548, 551, 567, 569], "medic": [9, 12, 13, 539], "personnel": 9, "analysi": [9, 12, 13, 15, 502, 516, 539, 540], "ultra": [9, 12, 13, 15, 472, 539, 547], "sound": [9, 12], "scan": [9, 13, 355, 539], "robot": [9, 12, 539], "obstacl": [9, 12, 539], "autonom": [9, 12, 502, 539], "vehicl": [9, 12, 13, 539], "affect": [9, 111, 117, 118, 135, 222, 226, 328, 333, 340, 341, 369, 394, 461, 468, 477, 478, 479, 502, 516, 526, 537, 541, 548, 552, 553, 556, 568], "we": [9, 13, 15, 77, 126, 132, 208, 209, 213, 216, 220, 222, 341, 375, 448, 518, 519, 520, 542, 568], "natur": [9, 106, 252, 279, 497, 536, 543, 565, 566], "token": [9, 103, 110, 382, 497, 498, 503, 524, 525, 537, 569, 571], "length": [9, 78, 93, 95, 100, 103, 110, 115, 127, 333, 362, 367, 380, 381, 382, 385, 386, 397, 398, 402, 407, 430, 431, 432, 434, 436, 439, 440, 536, 537, 569, 571], "faq": [9, 81, 83, 118, 495, 496, 518], "genai": [9, 13, 498, 499, 500, 524, 571], "displai": [9, 83, 113, 115, 148, 471, 473, 544, 557], "1024": [9, 93, 95, 106, 360, 369, 446, 447, 448, 449], "128": [9, 12, 58, 90, 98, 135, 245, 247, 248, 254, 262, 303, 313, 346, 351, 361, 362, 377, 378, 403, 404, 430, 431, 432, 433, 434, 435, 436, 438, 439, 498, 502, 524, 539], "beam": [9, 13, 103, 382, 497, 499, 500], "text": [9, 13, 76, 83, 88, 98, 100, 106, 115, 121, 122, 226, 245, 254, 260, 448, 497, 498, 524, 525, 549, 566, 569, 571, 572], "iter": [9, 10, 81, 103, 118, 122, 355, 360, 398, 499, 511, 512, 516, 522, 536, 553, 569, 570], "20": [9, 13, 15, 83, 95, 111, 122, 127, 254, 260, 314, 318, 333, 341, 342, 343, 375, 376, 377, 378, 380, 381, 388, 389, 390, 392, 394, 405, 430, 431, 432, 473, 476, 477, 480, 486, 490, 496, 502, 514], "hxw": 9, "256": [9, 81, 105, 106, 135, 244, 246, 249, 250, 251, 252, 253, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 324, 325, 334, 335, 336, 337, 354, 360, 363, 364, 365, 366, 380, 381, 388, 389, 390, 391, 392, 420, 466, 467, 468, 502], "english": [9, 11, 100, 103, 504], "methodologi": [9, 10, 11, 12], "xlsx": 9, "setup": [9, 95, 474, 498, 502, 524, 538, 539, 545, 566], "instal": [9, 10, 13, 14, 15, 49, 74, 80, 85, 87, 89, 93, 95, 97, 100, 111, 115, 118, 213, 220, 472, 473, 474, 493, 494, 495, 498, 499, 501, 502, 503, 504, 514, 515, 516, 522, 524, 526, 530, 540, 545, 547, 549, 572], "spent": [9, 10, 540, 542], "actual": [9, 10, 11, 83, 109, 110, 118, 130, 213, 219, 227, 420, 469, 521, 526, 535, 536, 541, 543, 545, 546, 548, 556, 557, 562, 564, 565, 567], "exclud": [9, 13, 83, 123, 413, 414, 516, 522], "pre": [9, 10, 12, 13, 14, 75, 76, 78, 81, 87, 89, 91, 94, 95, 96, 100, 102, 103, 105, 106, 108, 111, 112, 113, 115, 116, 124, 130, 216, 225, 315, 316, 325, 470, 476, 477, 478, 479, 480, 483, 488, 490, 491, 497, 499, 500, 501, 505, 506, 508, 509, 511, 512, 513, 514, 524, 526, 535, 536, 544, 547, 550, 551, 554, 556, 558, 559, 566, 571], "expos": [9, 541, 547, 566, 569], "over": [9, 12, 76, 98, 103, 118, 122, 127, 131, 226, 244, 312, 313, 315, 316, 317, 319, 325, 330, 331, 332, 335, 336, 337, 338, 355, 360, 376, 377, 378, 398, 403, 404, 407, 410, 411, 412, 413, 414, 415, 416, 417, 452, 453, 454, 455, 456, 457, 458, 459, 508, 522, 524, 526, 529, 536, 537, 538, 541, 543, 546, 549, 553, 562, 564, 567, 569], "grpc": 9, "http": [9, 13, 14, 15, 77, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 104, 108, 109, 110, 111, 115, 127, 406, 473, 476, 477, 478, 479, 486, 490, 491, 492, 496, 500, 514, 525, 529, 530, 547], "rest": [9, 10, 13, 81, 89, 119, 122, 209, 322, 324, 360, 398, 450, 524, 567], "Its": [9, 242, 320, 321, 534, 545], "client": [9, 13, 127, 516, 562], "two": [9, 11, 13, 14, 75, 80, 81, 82, 83, 84, 100, 102, 103, 104, 106, 109, 111, 115, 118, 119, 120, 122, 126, 127, 129, 130, 131, 132, 135, 148, 167, 208, 209, 210, 212, 213, 218, 220, 221, 222, 224, 225, 226, 242, 248, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 309, 312, 313, 314, 315, 316, 317, 318, 319, 327, 328, 329, 330, 331, 332, 341, 346, 351, 355, 360, 363, 365, 366, 367, 368, 369, 372, 375, 390, 391, 406, 408, 431, 434, 437, 440, 441, 453, 454, 460, 462, 463, 466, 467, 497, 498, 500, 516, 519, 521, 522, 523, 524, 525, 529, 530, 537, 538, 539, 542, 543, 544, 545, 547, 548, 550, 551, 553, 554, 555, 556, 558, 565, 566, 567, 569, 571, 572], "ethernet": [9, 127], "bandwidth": [9, 546, 554, 556, 566, 568], "depend": [9, 12, 13, 14, 15, 75, 78, 83, 106, 111, 113, 115, 118, 120, 122, 127, 129, 132, 135, 167, 209, 210, 212, 213, 216, 217, 218, 219, 221, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 260, 309, 310, 311, 320, 321, 325, 327, 328, 329, 340, 341, 348, 355, 361, 362, 369, 371, 383, 384, 401, 402, 407, 410, 420, 431, 434, 435, 436, 439, 468, 469, 472, 473, 477, 481, 487, 488, 493, 496, 497, 498, 499, 500, 502, 513, 514, 515, 516, 522, 524, 525, 526, 528, 529, 530, 532, 533, 534, 535, 536, 539, 541, 543, 544, 552, 562, 564, 566, 567, 568, 569, 571], "under": [9, 10, 76, 81, 84, 100, 110, 111, 114, 127, 132, 222, 477, 483, 516, 525, 534, 538, 540, 545, 547, 548, 571, 572], "investig": 9, "bottleneck": [9, 543], "intens": [9, 498, 524, 552, 553, 567], "dedic": [9, 13, 14, 83, 106, 118, 120, 122, 123, 124, 130, 133, 209, 226, 420, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 504, 505, 506, 508, 509, 510, 514, 525, 526, 538, 543, 544, 545, 549, 555, 556, 567, 569, 570, 571], "four": [9, 80, 83, 105, 115, 118, 122, 135, 225, 320, 321, 330, 331, 341, 391, 420, 530], "launch": [9, 74, 78, 82, 84, 115, 127, 533], "docker": [9, 127, 473, 484, 489, 492, 496, 504, 514], "listen": 9, "answer": [9, 12, 13, 529], "correspond": [9, 77, 81, 82, 83, 103, 106, 109, 111, 118, 119, 120, 122, 123, 124, 127, 132, 135, 216, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 245, 249, 250, 251, 254, 255, 256, 257, 262, 271, 277, 294, 295, 297, 298, 302, 304, 309, 311, 319, 325, 330, 331, 340, 355, 357, 358, 360, 367, 368, 369, 370, 372, 378, 380, 381, 384, 385, 387, 388, 389, 390, 391, 392, 394, 395, 398, 403, 404, 408, 410, 413, 415, 416, 417, 419, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 437, 441, 452, 453, 454, 455, 459, 461, 466, 467, 498, 500, 506, 515, 519, 520, 541, 542, 548, 551, 569, 572], "locat": [9, 14, 83, 106, 111, 122, 127, 220, 315, 316, 320, 321, 322, 344, 388, 389, 390, 392, 401, 437, 441, 461, 496, 502, 515, 526, 527, 530, 550, 562], "mount": 9, "port": [9, 13, 77, 103, 105, 118, 119, 121, 122, 123, 124, 127, 130, 135, 136, 140, 142, 148, 163, 224, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 492, 497, 502, 535, 549, 550, 551], "physic": [9, 127, 133, 515, 542], "machin": [9, 13, 75, 103, 118, 213, 220, 476, 477, 478, 479, 482, 486, 487, 490, 491, 496, 514, 515, 540, 549], "python3": [9, 14, 75, 83, 91, 95, 96, 98, 100, 108, 111, 127, 476, 477, 478, 481, 487, 496, 500, 504, 516, 522], "parallel": [9, 133, 210, 212, 341, 368, 471, 481, 502, 504, 541, 542, 543, 546, 548, 550, 552, 553, 554, 555, 556, 562, 564, 566, 567], "wait": [9, 210, 213, 219, 500, 509, 544, 549, 550, 552, 553, 555, 556, 562], "send": [9, 127, 545, 567], "new": [9, 12, 14, 54, 64, 66, 69, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 131, 132, 133, 135, 163, 213, 216, 218, 220, 223, 226, 242, 371, 372, 374, 383, 384, 396, 398, 399, 430, 431, 437, 441, 475, 477, 478, 479, 487, 490, 491, 493, 498, 499, 500, 502, 525, 529, 532, 535, 536, 543, 544, 548, 550, 551, 553, 558, 560, 562, 569, 570, 571], "verif": [9, 504], "balanc": [9, 524, 539, 541, 542, 546, 564, 565, 566, 568], "haproxi": 9, "count": [9, 77, 101, 117, 252, 259, 274, 355, 360, 373, 379, 394, 399, 408, 409, 416, 417, 437, 441, 444, 460, 461, 462, 502, 511, 512, 553, 570], "forward": [9, 77, 95, 96, 208, 362, 368, 434, 436, 439, 514, 529, 572], "estim": [9, 13, 75, 76, 432, 471, 477, 478, 479, 487, 501, 502, 503, 511, 512, 522, 524, 547], "share": [9, 16, 83, 104, 111, 118, 127, 129, 131, 132, 211, 212, 213, 216, 226, 320, 321, 408, 453, 473, 476, 481, 490, 491, 498, 502, 524, 526, 530, 546, 550, 551, 565, 566, 567, 571], "prometheu": 9, "reason": [9, 13, 75, 83, 106, 111, 118, 121, 122, 130, 132, 136, 148, 208, 213, 502, 519, 526, 530, 536, 537, 543, 546, 555, 556, 568], "site": [9, 504, 572], "simul": [9, 355, 518, 542], "life": [9, 106, 571], "whole": [9, 11, 12, 77, 81, 82, 209, 216, 222, 226, 313, 315, 316, 326, 330, 331, 401, 468, 526, 530, 536, 542, 569], "final": [9, 10, 14, 81, 108, 118, 135, 148, 328, 360, 367, 369, 430, 432, 446, 447, 448, 449, 493, 499, 510, 513, 514, 515, 516, 517, 525, 541, 548, 557, 562, 564], "yourself": [9, 83, 90, 92, 94, 106, 107, 132, 546], "particular": [9, 83, 86, 106, 118, 122, 123, 124, 132, 133, 208, 209, 213, 216, 218, 220, 222, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 330, 331, 355, 394, 403, 404, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 475, 494, 516, 524, 526, 534, 537, 539, 541, 542, 546, 548, 555, 556, 557, 559, 563, 564, 566, 567], "evalu": [9, 10, 81, 96, 108, 114, 118, 128, 130, 219, 524, 529, 539, 541, 542, 546, 556, 572], "account": [9, 133, 334, 368, 446, 447, 449, 496, 522, 545, 556], "disclaim": 9, "april": 9, "17": [9, 96, 99, 103, 329, 342, 343, 375, 377, 378, 380, 381, 390, 415, 416, 417, 418, 524, 540], "march": [9, 13, 96], "15": [9, 13, 15, 99, 106, 122, 274, 330, 331, 341, 367, 375, 376, 377, 378, 380, 381, 383, 384, 388, 390, 391, 392, 413, 414, 417, 418, 502, 511, 524], "benefit": [9, 12, 13, 15, 85, 120, 224, 498, 499, 516, 524, 536, 542, 543, 546, 552, 569, 570], "oem": [9, 13, 15], "disclosur": 9, "degre": 9, "f": [9, 10, 11, 77, 95, 96, 127, 130, 361, 362, 433, 435, 438, 448, 499, 500, 529], "q": [9, 10, 11, 208, 390, 391, 446, 447, 448, 449, 517], "explain": [10, 86, 97, 99, 101, 103, 105, 107, 111, 118, 122, 127, 132, 368, 476, 490, 491, 494, 536, 564, 566, 567], "benchmark_app": [10, 12, 103, 129, 132, 135, 501, 502, 505, 506, 508, 509, 510, 512, 516, 539, 546], "through": [10, 12, 13, 15, 73, 75, 76, 81, 85, 109, 126, 127, 135, 167, 171, 208, 222, 326, 355, 360, 375, 385, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 439, 471, 474, 497, 498, 499, 502, 513, 518, 523, 529, 535, 536, 547, 571, 572], "intern": [10, 13, 15, 81, 83, 118, 120, 121, 122, 123, 133, 213, 219, 220, 309, 340, 403, 404, 497, 529, 536, 537, 542, 543, 544, 545, 546, 547, 555, 556, 562, 566, 567, 569], "counter": [10, 133, 135, 213, 341, 502, 542, 551], "itt": [10, 211, 212, 219, 516, 540], "vtune": [10, 540], "insight": 10, "experi": [10, 13, 74, 83, 471, 494, 497, 500, 537, 543, 552, 553, 564, 565, 567], "code": [10, 13, 14, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 129, 130, 131, 132, 133, 211, 213, 219, 220, 223, 320, 321, 333, 355, 430, 431, 440, 470, 476, 477, 478, 479, 486, 487, 490, 491, 493, 496, 497, 498, 499, 500, 503, 504, 510, 511, 512, 515, 517, 518, 520, 521, 522, 523, 524, 525, 528, 529, 530, 532, 535, 536, 538, 541, 542, 543, 544, 546, 549, 550, 551, 552, 553, 555, 556, 557, 560, 563, 568, 569, 571, 572], "sampl": [10, 13, 14, 75, 88, 101, 108, 111, 119, 120, 126, 127, 129, 130, 148, 315, 316, 319, 325, 337, 340, 344, 375, 408, 413, 414, 470, 472, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 494, 497, 499, 500, 502, 522, 524, 535, 536, 538, 541, 542, 543, 548, 549, 550, 555, 556, 571], "sure": [10, 14, 75, 81, 83, 103, 106, 111, 122, 127, 220, 472, 473, 474, 479, 480, 482, 486, 488, 492, 496, 502, 504, 505, 506, 508, 509, 514, 515, 516, 524, 541, 543, 545, 549, 556, 567], "packag": [10, 13, 14, 15, 31, 48, 49, 74, 83, 85, 95, 100, 125, 473, 474, 475, 477, 478, 479, 480, 484, 485, 486, 488, 489, 492, 493, 496, 501, 503, 514, 515, 518, 522, 526, 562, 572], "want": [10, 14, 75, 81, 83, 85, 98, 99, 106, 118, 132, 220, 222, 472, 475, 476, 477, 478, 479, 484, 485, 488, 489, 492, 496, 498, 504, 516, 522, 535, 540, 544, 545, 550, 554, 568], "reliabl": [10, 120, 551], "prepar": [10, 13, 73, 74, 78, 80, 81, 106, 118, 122, 126, 128, 135, 143, 210, 225, 471, 476, 480, 481, 488, 490, 491, 499, 502, 505, 508, 509, 513, 527, 528, 529, 530, 531, 532, 533, 534, 535, 541, 556, 558, 563], "lot": [10, 81, 118, 221, 519, 564, 568], "m": [10, 75, 103, 127, 130, 135, 220, 222, 320, 321, 341, 377, 378, 392, 398, 403, 404, 477, 478, 479, 481, 487, 492, 496, 499, 500, 501, 502, 503, 504, 509, 511, 512, 516, 522, 539, 541, 542, 546, 547, 556], "d": [10, 11, 103, 122, 127, 130, 132, 135, 252, 258, 259, 308, 367, 375, 383, 384, 388, 392, 395, 397, 402, 403, 404, 407, 411, 412, 413, 414, 415, 416, 417, 418, 446, 447, 448, 449, 452, 453, 454, 455, 459, 468, 473, 476, 479, 490, 501, 502, 504, 509, 516, 525, 529, 539, 540, 541, 545, 546, 556, 559], "equival": [10, 80, 81, 118, 132, 245, 295, 296, 297, 298, 318, 367, 370, 374, 375, 382, 390, 393, 395, 396, 398, 461, 464, 536], "app": [10, 103, 478, 480, 492, 493, 496, 502, 513, 514, 515, 541, 544, 549, 555], "realli": [10, 221, 454, 455, 459, 515, 555, 567], "low": [10, 12, 13, 31, 118, 129, 133, 134, 136, 143, 148, 163, 167, 208, 212, 419, 451, 471, 472, 498, 499, 502, 524, 539, 542, 543, 545, 546, 547, 553, 554, 562, 566, 572], "level": [10, 13, 31, 74, 100, 104, 118, 120, 122, 127, 129, 138, 208, 220, 226, 325, 382, 420, 471, 473, 496, 497, 499, 502, 516, 535, 538, 540, 542, 543, 546, 547, 554, 555, 562, 566, 567, 568, 572], "recommend": [10, 12, 13, 14, 15, 75, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 132, 213, 222, 224, 252, 367, 432, 473, 474, 476, 477, 478, 479, 492, 496, 497, 498, 499, 500, 502, 504, 513, 514, 515, 516, 517, 519, 520, 522, 523, 524, 525, 527, 528, 529, 530, 531, 533, 536, 541, 542, 546, 547, 554, 555, 556, 562, 565, 567, 569, 571], "alwai": [10, 120, 122, 130, 132, 224, 309, 319, 337, 355, 362, 367, 369, 393, 401, 461, 466, 467, 515, 526, 529, 535, 536, 538, 539, 542, 543, 546, 552, 554, 557, 563, 564, 567], "hint": [10, 13, 107, 213, 219, 471, 515, 526, 541, 543, 546, 547, 548, 554, 562, 564, 566, 567, 568], "first": [10, 13, 14, 75, 77, 81, 82, 83, 85, 89, 90, 91, 92, 94, 100, 101, 103, 104, 106, 111, 113, 118, 122, 123, 127, 129, 130, 131, 132, 148, 208, 213, 216, 220, 221, 222, 226, 242, 274, 278, 280, 281, 282, 285, 291, 308, 311, 313, 320, 321, 322, 327, 328, 329, 330, 331, 340, 342, 343, 344, 345, 346, 350, 351, 355, 358, 360, 367, 369, 371, 372, 376, 377, 378, 380, 381, 382, 385, 386, 387, 388, 389, 391, 392, 398, 400, 401, 406, 411, 412, 416, 417, 431, 437, 441, 444, 445, 453, 461, 464, 477, 478, 479, 493, 496, 499, 500, 502, 504, 509, 517, 519, 524, 525, 526, 527, 528, 529, 530, 531, 532, 534, 536, 539, 540, 541, 542, 544, 546, 547, 550, 555, 559, 562, 563, 565, 567, 569, 572], "priorit": [10, 14, 471, 502, 524, 539, 546, 554], "tput": [10, 502, 515, 541, 556], "proper": [10, 118, 122, 474, 482, 492, 514, 529, 536, 543, 561], "track": [10, 14, 212, 226, 541, 565], "occur": [10, 13, 81, 83, 135, 398, 406, 432, 496, 502, 537, 547, 553], "outsid": [10, 122, 127, 316, 344, 409, 420, 468, 499, 525, 552, 556, 571], "bake": 10, "accordingli": [10, 208, 320, 321, 388, 390, 519, 538, 541, 562, 567], "try": [10, 75, 79, 81, 86, 122, 129, 471, 476, 477, 478, 479, 480, 482, 487, 488, 490, 491, 492, 493, 503, 511, 512, 522, 523, 524, 539, 543, 545, 556, 565, 568], "credibl": 10, "conclus": [10, 132], "reproduc": [10, 107, 500, 529], "As": [10, 12, 81, 85, 96, 109, 118, 127, 130, 132, 135, 148, 163, 213, 226, 278, 280, 281, 282, 285, 291, 337, 341, 368, 398, 502, 504, 508, 515, 529, 536, 537, 541, 542, 543, 546, 555, 556, 560, 561, 562, 563, 564, 566, 567, 570, 571], "done": [10, 103, 118, 132, 135, 210, 213, 216, 343, 348, 349, 355, 408, 431, 498, 504, 506, 509, 516, 519, 520, 525, 529, 536, 540, 543, 546, 555, 560, 568], "invoc": [10, 341], "routin": [10, 131], "sinc": [10, 14, 74, 83, 103, 109, 115, 117, 208, 213, 340, 367, 368, 403, 404, 468, 519, 520, 521, 523, 524, 529, 542, 543, 544, 551, 553], "almost": [10, 516, 521, 541, 562], "significantli": [10, 13, 117, 226, 367, 493, 499, 516, 518, 523, 537, 541, 542, 556, 562, 563, 565], "slower": [10, 524, 539, 546], "than": [10, 13, 79, 81, 82, 103, 111, 116, 126, 127, 132, 135, 167, 213, 220, 242, 244, 260, 309, 320, 321, 322, 323, 324, 325, 326, 330, 331, 337, 339, 343, 344, 346, 348, 349, 351, 354, 368, 369, 370, 377, 378, 379, 380, 381, 383, 384, 387, 394, 398, 399, 403, 404, 420, 432, 441, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 464, 468, 473, 477, 478, 497, 498, 516, 518, 523, 524, 531, 532, 535, 536, 539, 541, 542, 543, 545, 555, 557, 562, 564, 565, 567, 569], "subsequ": [10, 85, 112, 113, 114, 115, 116, 242, 340, 355, 367, 532, 542, 547, 552], "aggreg": 10, "warm": [10, 541], "too": [10, 81, 106, 129, 130, 222, 516, 518, 535, 541, 569], "much": [10, 130, 135, 220, 464, 468, 471, 502, 521, 532, 539, 541, 542, 544, 546, 556, 564], "geomean": 10, "Be": [10, 87, 89, 222, 537, 556, 557, 567], "awar": [10, 13, 87, 89, 131, 208, 466, 467, 471, 517, 518, 524, 537, 542, 556, 557, 567], "throttl": [10, 502, 539, 546], "odditi": 10, "exist": [10, 13, 81, 103, 106, 120, 122, 123, 127, 130, 131, 132, 135, 136, 216, 225, 226, 355, 368, 388, 389, 390, 392, 432, 477, 478, 479, 499, 514, 515, 525, 529, 536, 541, 542, 543, 544, 566, 571], "fix": [10, 13, 14, 83, 100, 108, 224, 226, 335, 336, 337, 338, 341, 441, 473, 524, 529, 543, 545, 558], "frequenc": 10, "howev": [10, 78, 83, 84, 85, 105, 106, 115, 118, 120, 122, 123, 130, 208, 226, 368, 390, 398, 464, 468, 496, 497, 498, 502, 515, 519, 520, 524, 526, 532, 533, 536, 537, 541, 543, 548, 551, 555, 556, 557, 560, 562, 569, 570, 572], "condit": [10, 83, 117, 118, 132, 308, 309, 310, 311, 349, 355, 483, 502, 538], "compar": [10, 12, 77, 83, 106, 126, 226, 242, 479, 497, 518, 519, 524, 529, 542, 543, 553, 555, 556, 560, 564, 567, 568], "nativ": [10, 13, 74, 80, 132, 470, 473, 493, 494, 497, 498, 513, 536, 537, 542, 551, 553, 569, 572], "anoth": [10, 75, 84, 99, 111, 120, 122, 124, 127, 135, 167, 213, 218, 220, 222, 226, 254, 256, 341, 371, 372, 453, 466, 467, 493, 498, 527, 533, 535, 537, 541, 545, 553, 560, 562, 565, 568], "wrap": [10, 133, 212, 213, 218, 519, 520, 544, 559, 572], "exact": [10, 108, 208, 260, 398, 502, 525, 536, 568], "watch": 10, "random": [10, 340, 341, 502, 525, 529], "popul": [10, 339, 383, 384, 385, 430, 437, 460, 461, 462, 541, 555, 556, 562, 571], "situat": [10, 81, 120, 122, 524], "side": [10, 367, 369, 407, 544, 567], "leverag": [10, 516, 536, 541, 543, 554, 562, 567, 571, 572], "demand": [10, 226, 564, 565], "fp16": [10, 13, 78, 83, 135, 225, 260, 343, 390, 419, 468, 497, 502, 507, 513, 523, 526, 532, 539, 542, 543, 546, 547], "breakdown": 10, "pc": [10, 127, 502, 545], "resnet": [10, 11, 12, 135, 216], "50": [10, 11, 12, 103, 104, 109, 110, 127, 135, 216, 244, 308, 315, 316, 323, 325, 326, 329, 340, 341, 347, 371, 372, 373, 375, 388, 390, 498, 502, 508, 519, 532, 543, 557], "mind": [10, 83, 476, 525, 541, 550, 555, 556, 557, 564, 566, 567], "realtim": [10, 135, 539, 542, 545], "wall": 10, "clock": 10, "layernam": [10, 135], "execstatu": [10, 135], "layertyp": [10, 135, 542, 545], "exectyp": [10, 135, 542, 545], "cputim": [10, 135, 542], "resnet_model": [10, 135], "batch_normalization_15": [10, 135], "jit_avx512_1x1_i8": [10, 135], "377": [10, 135], "conv2d_16": [10, 135], "fq_input_0": [10, 135], "not_run": [10, 135, 545], "undef": [10, 135], "batch_normalization_16": [10, 135], "jit_avx512_i8": [10, 135], "499": [10, 135], "conv2d_17": [10, 135], "batch_normalization_17": [10, 135], "399": [10, 135], "add_4": [10, 135], "add_5": [10, 135], "fq_input_1": [10, 135], "column": [10, 109, 135, 339, 368, 369, 451], "standalon": [10, 135], "primit": [10, 83, 135, 367, 497, 542, 543, 544, 547, 568], "suffix": [10, 135, 226, 515, 548, 570], "could": [10, 83, 87, 89, 106, 108, 111, 118, 120, 122, 130, 225, 327, 328, 329, 441, 444, 445, 453, 468, 524, 533, 535, 539, 552], "i8": [10, 50, 72, 135, 148, 339, 354, 356, 358, 468, 502, 542, 543], "had": [10, 122, 127, 135], "8": [10, 11, 13, 15, 75, 83, 96, 100, 103, 111, 117, 119, 127, 135, 242, 243, 259, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 309, 311, 314, 316, 318, 319, 321, 325, 326, 328, 331, 340, 341, 342, 343, 345, 346, 350, 351, 354, 360, 361, 362, 363, 365, 366, 367, 370, 373, 375, 377, 378, 379, 380, 381, 383, 384, 386, 387, 390, 391, 392, 394, 398, 410, 411, 412, 415, 417, 418, 419, 430, 431, 432, 436, 451, 452, 454, 455, 459, 463, 464, 465, 468, 473, 476, 477, 478, 479, 480, 481, 490, 491, 492, 496, 497, 498, 502, 507, 509, 510, 511, 512, 514, 516, 517, 518, 521, 522, 523, 524, 529, 536, 537, 541, 556, 557, 559, 560, 567, 568, 571], "were": [10, 12, 15, 81, 90, 95, 101, 106, 108, 118, 122, 135, 163, 221, 223, 412, 419, 468, 502, 509, 519, 520, 523, 541, 542, 545, 546], "fp32": [10, 12, 81, 83, 127, 135, 224, 225, 226, 260, 302, 303, 304, 309, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 331, 335, 336, 337, 340, 341, 348, 349, 360, 368, 388, 389, 390, 392, 401, 419, 440, 450, 451, 452, 453, 454, 455, 459, 468, 507, 510, 523, 524, 539, 543, 545, 546, 548, 557], "int8": [10, 12, 13, 79, 83, 135, 148, 208, 209, 420, 497, 498, 507, 520, 523, 524, 526, 539, 542, 547, 564, 568], "describ": [10, 13, 15, 16, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 132, 135, 209, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 309, 319, 320, 321, 332, 335, 336, 337, 338, 339, 341, 347, 349, 355, 360, 367, 371, 372, 381, 393, 401, 402, 403, 404, 406, 411, 412, 433, 434, 435, 438, 440, 441, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 473, 475, 479, 492, 499, 504, 513, 520, 523, 525, 526, 529, 535, 536, 539, 542, 544, 545, 557, 563, 566, 567, 571], "seen": [10, 542], "statist": [10, 502, 541], "exec_graph_path": [10, 502], "netron": 10, "viewabl": 10, "especi": [10, 388, 502, 524, 525, 532, 541, 542, 552, 564], "note": [10, 11, 14, 77, 86, 106, 118, 120, 127, 132, 135, 212, 213, 244, 254, 260, 312, 313, 314, 315, 316, 317, 318, 325, 328, 348, 349, 355, 368, 370, 375, 382, 388, 397, 398, 413, 414, 415, 416, 417, 418, 419, 430, 432, 449, 473, 476, 477, 478, 479, 480, 481, 482, 486, 487, 488, 490, 491, 492, 500, 502, 514, 519, 520, 534, 538, 539, 541, 546, 562, 563, 565, 569, 571], "driver": [10, 15, 96, 213, 472, 473, 474, 475, 482, 492, 496, 502, 543, 546, 547], "queue": [10, 543, 553, 566, 567], "produc": [10, 13, 81, 83, 93, 97, 101, 106, 114, 118, 120, 122, 123, 129, 132, 220, 226, 250, 251, 330, 331, 335, 336, 337, 338, 341, 344, 354, 355, 370, 385, 387, 390, 391, 397, 401, 402, 437, 442, 443, 454, 455, 459, 516, 526, 529, 544, 569, 571], "nearli": [10, 539], "quit": [10, 209], "lastli": [10, 367], "carefulli": [10, 106, 541, 565], "isol": [10, 81, 127], "individu": [10, 132, 401, 460, 461, 462, 536, 541, 543, 564, 566, 567], "heavili": [10, 541, 543], "instrument": [10, 212, 219], "trace": [10, 114, 212, 219, 367, 524, 526, 529, 572], "therefor": [10, 12, 14, 81, 83, 95, 104, 114, 122, 127, 132, 213, 309, 340, 355, 451, 452, 453, 519, 535, 536, 537, 542, 543, 544, 551, 555, 556, 557, 558], "timelin": [10, 14], "origin": [11, 16, 77, 78, 79, 81, 82, 83, 84, 97, 100, 101, 102, 104, 106, 110, 111, 115, 117, 118, 122, 124, 129, 132, 135, 148, 163, 167, 208, 209, 213, 220, 223, 224, 226, 319, 320, 321, 336, 340, 341, 348, 349, 368, 393, 395, 398, 419, 432, 435, 437, 461, 498, 499, 500, 502, 510, 517, 518, 519, 520, 523, 526, 527, 529, 530, 533, 551, 553, 558, 560, 568, 570], "three": [11, 14, 78, 81, 83, 85, 108, 109, 111, 115, 118, 120, 121, 122, 127, 130, 132, 135, 213, 220, 313, 314, 317, 318, 319, 322, 330, 331, 346, 367, 368, 435, 436, 453, 500, 517, 525, 530, 536, 547, 569, 570, 571], "architectur": [11, 12, 13, 108, 127, 133, 481, 482, 486, 487, 488, 497, 504, 515, 534, 542, 543, 547, 554, 566], "i9": 11, "9000k": 11, "avx2": [11, 13, 542], "b": [11, 81, 83, 93, 95, 96, 102, 103, 108, 115, 130, 132, 171, 213, 220, 242, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 312, 313, 340, 341, 346, 351, 361, 362, 363, 365, 366, 367, 368, 369, 377, 378, 380, 381, 403, 404, 407, 431, 432, 433, 434, 435, 436, 438, 439, 448, 449, 452, 453, 454, 455, 459, 467, 481, 488, 502, 529, 541, 560, 571], "6338": 11, "vnni": [11, 12], "amx": [11, 13, 542, 568], "bert": [11, 12, 13, 78, 114, 115, 501, 522, 525, 536, 537], "sst": 11, "2_bert_cased_pad": 11, "spearman": 11, "cosin": [11, 264, 265, 272, 273], "93": [11, 68, 298, 375], "68": [11, 59, 83, 96, 329, 375, 390], "76": [11, 375, 388], "72": [11, 59, 375, 390], "uncas": [11, 12, 98, 525], "word": [11, 12, 88, 103, 148, 220, 398, 524, 551, 559], "mask": [11, 12, 106, 111, 112, 115, 127, 209, 302, 304, 311, 316, 333, 385, 398, 430, 431, 440, 499, 537], "squad": [11, 12], "0001": [11, 12, 407], "squad_v1_1_bert_msl384_mql64_ds128_lowercas": 11, "f1": 11, "19": [11, 96, 99, 100, 111, 329, 333, 375, 377, 378, 380, 381, 502], "03": [11, 340, 490], "11": [11, 13, 15, 72, 75, 83, 90, 92, 96, 99, 103, 106, 127, 243, 260, 308, 311, 333, 341, 342, 343, 348, 360, 367, 375, 377, 378, 380, 381, 383, 384, 387, 388, 390, 391, 392, 394, 417, 418, 461, 476, 477, 478, 479, 480, 490, 491, 492, 496, 502, 511, 524, 529, 547, 556, 572], "efficientdet": [11, 12, 106, 115], "d0": [11, 12], "coco2017_detection_91cl": 11, "coco_precis": 11, "64": [11, 13, 15, 77, 81, 93, 94, 127, 224, 312, 313, 315, 316, 325, 334, 340, 367, 375, 377, 378, 381, 419, 420, 476, 477, 478, 479, 480, 490, 491, 492, 496, 498, 502, 510, 514, 524, 547], "62": [11, 83, 111, 333, 375, 502], "63": [11, 83, 313, 319, 333, 375], "mask_rcnn_resnet50_atrous_coco": [11, 12], "coco2017_detection_91cl_bkgr": 11, "coco_orig_precis": 11, "04": [11, 15, 127, 407, 473, 474, 475, 476, 477, 480, 496, 502, 514, 547], "02": [11, 496, 512], "mobilenet": [11, 12, 13, 78, 84, 508, 522, 533, 536], "v2": [11, 12, 13, 106, 115, 316, 333, 498, 522, 524, 530, 536], "imagenet2012": 11, "top1": 11, "95": [11, 69, 375], "09": [11, 104, 502, 511, 540], "12": [11, 15, 91, 95, 96, 98, 104, 106, 110, 127, 243, 274, 317, 323, 326, 360, 367, 375, 376, 377, 378, 380, 381, 383, 384, 387, 388, 390, 391, 393, 394, 397, 399, 402, 406, 407, 408, 409, 410, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 460, 462, 473, 496, 502, 524, 541], "13": [11, 15, 96, 103, 106, 110, 111, 243, 295, 296, 297, 298, 329, 333, 334, 340, 375, 377, 378, 380, 381, 388, 390, 392, 417, 418, 419, 440, 454, 476, 477, 478, 480, 490, 491, 511, 512, 524], "resnet34": [11, 12], "1200": [11, 12], "coco2017_detection_80cl_bkgr": 11, "01": [11, 127, 523, 524], "v1": [11, 12, 13, 77, 80, 81, 85, 98, 105, 110, 115, 499, 504, 505, 509, 511, 512, 530, 532, 545], "coco": [11, 12, 111], "29": [11, 53, 96, 103, 340, 375, 377, 378, 490, 496, 502, 511, 524], "31": [11, 375, 377, 378], "unet": [11, 12, 78, 82], "camvid": [11, 12], "camvid_12cl": 11, "mean_iou": 11, "6": [11, 15, 81, 83, 95, 103, 106, 111, 126, 167, 242, 243, 250, 251, 260, 266, 274, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 309, 311, 317, 318, 322, 323, 324, 325, 326, 330, 332, 333, 335, 336, 337, 338, 340, 353, 358, 360, 361, 362, 363, 365, 366, 367, 370, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 387, 388, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 402, 407, 408, 409, 410, 415, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 434, 435, 436, 439, 440, 450, 451, 452, 453, 454, 455, 459, 460, 462, 463, 464, 465, 473, 474, 490, 496, 502, 509, 510, 524, 540, 545, 547], "28": [11, 91, 96, 331, 374, 375, 376, 377, 378, 388, 396, 496, 510, 512, 524], "41": [11, 54, 333, 375, 502, 524], "46": [11, 99, 327, 328, 375, 502], "yolo_v3_tini": [11, 111], "coco2017_detection_80cl": 11, "43": [11, 15, 375, 473], "87": [11, 375], "yolo_v8n": 11, "chatglm2": [11, 12], "6b": [11, 12, 13], "lambada": [11, 524], "openai": [11, 13, 524], "ppl": 11, "75": [11, 348, 349, 375, 407], "llama": [11, 12, 497, 498, 499, 500, 524], "7b": [11, 12, 13, 498, 499, 524, 532], "chat": [11, 12, 13, 498, 499, 524], "wiki": 11, "stackexch": 11, "crawl": 11, "38": [11, 53, 96, 319, 327, 328, 332, 333, 340, 375, 377, 378, 502, 512, 542], "27": [11, 96, 333, 375, 377, 378, 502, 524], "stabl": [11, 12, 13, 252, 360, 461, 497, 498, 499, 529, 565], "diffus": [11, 12, 13, 497, 498, 499], "liaon": 11, "5b": 11, "mistral": [11, 12, 13], "proprietari": [11, 85, 224, 547], "49": [11, 15, 308, 375, 512], "falcon": [11, 12, 13], "instruct": [11, 12, 13, 75, 83, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 100, 103, 104, 105, 106, 110, 111, 112, 113, 114, 115, 119, 130, 135, 167, 472, 473, 475, 476, 477, 478, 479, 480, 482, 488, 490, 491, 494, 496, 498, 500, 502, 504, 505, 506, 507, 508, 509, 510, 511, 512, 515, 518, 524, 527, 528, 530, 535, 540, 542, 547, 572], "bai": 11, "ze": 11, "65": [11, 52, 83, 109, 341, 375, 512], "gpt4all": 11, "25": [11, 109, 293, 316, 324, 325, 327, 328, 360, 375, 377, 378, 380, 381, 390, 391, 502, 512, 524], "gpteacher": 11, "5": [11, 13, 15, 77, 80, 81, 95, 96, 108, 111, 115, 118, 119, 132, 167, 242, 243, 247, 250, 252, 266, 274, 275, 278, 280, 281, 282, 283, 285, 286, 291, 292, 293, 295, 297, 298, 299, 300, 301, 305, 306, 307, 308, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 348, 349, 355, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 374, 375, 377, 378, 379, 380, 381, 383, 384, 387, 388, 390, 391, 392, 393, 394, 395, 396, 398, 399, 401, 402, 403, 404, 406, 407, 413, 414, 415, 417, 418, 419, 420, 432, 433, 434, 435, 436, 438, 439, 440, 441, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 463, 464, 465, 476, 477, 480, 486, 496, 502, 509, 510, 524, 525, 530, 537, 540, 545, 557, 563], "refinedweb": 11, "00": [11, 96, 127, 474, 511], "06": [11, 13, 403, 404, 502], "05": [11, 463, 464, 465, 502], "18": [11, 15, 109, 127, 367, 375, 377, 378, 380, 381, 384, 417, 418, 476, 477, 480, 496, 514, 541], "22": [11, 13, 15, 77, 96, 298, 355, 375, 377, 378, 380, 381, 473, 474, 475, 476, 477, 480, 490, 496, 502, 511, 514, 547], "4": [11, 13, 15, 80, 83, 94, 95, 96, 98, 99, 103, 106, 108, 109, 111, 118, 120, 122, 130, 167, 224, 227, 242, 243, 251, 253, 260, 262, 274, 286, 290, 302, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 333, 335, 336, 337, 339, 340, 341, 343, 344, 348, 349, 355, 360, 361, 362, 367, 368, 370, 371, 372, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 463, 464, 465, 466, 477, 496, 497, 498, 502, 509, 510, 511, 524, 530, 532, 537, 539, 540, 541, 542, 545, 547, 556, 559, 564, 567], "except": [11, 13, 106, 108, 120, 121, 122, 130, 135, 213, 220, 242, 347, 348, 349, 355, 368, 373, 379, 388, 389, 390, 392, 397, 401, 402, 432, 468, 501, 502, 516, 530, 533, 540, 542, 543, 551, 570], "perplex": [11, 524], "minu": [11, 539], "deviat": [11, 13, 15, 498, 512, 560], "often": [12, 401, 469, 529, 537, 541, 561, 568, 569], "publish": [12, 13, 14, 15, 473, 483], "everi": [12, 14, 75, 83, 103, 111, 122, 130, 220, 222, 337, 340, 368, 373, 394, 398, 400, 416, 417, 444, 477, 478, 487, 498, 500, 502, 516, 533, 536, 537, 546, 553, 555, 556, 558, 562, 563, 564, 566, 567], "major": [12, 74, 163, 226, 310, 481, 482, 486, 487, 488, 524, 540, 549, 566], "minor": [12, 79, 474], "repositori": [12, 13, 14, 74, 81, 90, 91, 94, 95, 96, 97, 98, 99, 101, 103, 105, 106, 108, 109, 110, 111, 112, 115, 127, 132, 135, 216, 473, 474, 475, 477, 478, 479, 483, 495, 496, 498, 500, 504, 505, 506, 508, 509, 510, 511, 512, 518, 524, 525, 527, 530, 572], "zoo": [12, 13, 74, 75, 101, 127, 130, 135, 471, 476, 480, 488, 490, 491, 504, 505, 506, 508, 509, 511, 512, 549], "Will": 12, "ad": [12, 13, 14, 83, 96, 103, 112, 113, 115, 116, 118, 120, 122, 127, 129, 130, 135, 148, 167, 216, 221, 222, 223, 226, 312, 313, 314, 315, 316, 317, 318, 319, 367, 369, 375, 383, 384, 387, 388, 398, 403, 404, 405, 406, 407, 408, 409, 413, 414, 415, 416, 417, 456, 457, 458, 479, 492, 496, 509, 518, 519, 525, 535, 541, 544, 558, 560, 572], "adopt": [12, 108, 516, 521, 543], "divers": [12, 497], "period": [12, 14, 519], "my": 12, "own": [12, 13, 73, 75, 83, 109, 111, 115, 126, 129, 132, 215, 216, 217, 218, 224, 453, 471, 475, 476, 477, 478, 479, 482, 486, 487, 490, 491, 497, 504, 515, 519, 520, 522, 525, 530, 532, 542, 543, 552, 567, 569], "thudm": 12, "32k": 12, "hugginfac": 12, "causal": [12, 440], "2048": [12, 100], "meta": [12, 85, 98, 101, 105, 109, 111, 115, 498, 502, 524, 529, 530, 532], "regress": 12, "4096": [12, 360], "latent": [12, 499], "77": [12, 375], "question": [12, 13, 118, 492, 529], "384": [12, 327, 328, 361, 362, 398, 433, 434, 502, 540, 543], "512x512": 12, "atrou": [12, 375], "800x1365": 12, "224x224": [12, 557], "50_v1_ilsvrc": 12, "2012": 12, "300x300": [12, 506], "1200x1200": 12, "u": [12, 13, 15, 127, 220, 345, 346, 351, 367, 368, 486, 500, 542, 547], "net": [12, 81, 92, 94, 95, 96, 103, 224, 226], "semant": [12, 13, 117, 118, 120, 122, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 355, 369, 377, 378], "368x480": 12, "yolo": [12, 13, 82, 113, 122, 333, 511, 512], "v3": [12, 13, 82, 111, 113, 333, 511, 512], "tini": [12, 82, 111], "416x416": 12, "yolov8n": 12, "yolov8nano": 12, "608x608": 12, "purchas": 12, "partner": [12, 471], "vendor": [12, 125, 496], "manufactur": [12, 516], "catalog": [12, 93, 483], "guidelin": 12, "join": [12, 83, 98, 102, 103, 123], "why": [12, 81, 83, 100, 108, 224, 529, 534], "beyond": [12, 13, 387, 502, 538], "processor": [12, 13, 15, 127, 471, 476, 477, 479, 480, 481, 482, 487, 488, 490, 491, 497, 502, 504, 538, 542, 543, 572], "reduc": [12, 13, 74, 117, 209, 367, 388, 394, 403, 404, 418, 425, 427, 471, 493, 496, 497, 498, 502, 516, 517, 518, 519, 521, 523, 524, 526, 539, 541, 542, 543, 547, 552, 561, 563, 567, 568, 569, 572], "faster": [12, 106, 112, 119, 220, 333, 497, 498, 518, 520, 524, 525, 526, 534, 542], "regardless": [12, 82, 118, 127, 369, 430, 431, 502, 515, 543], "intrins": 12, "comparison": [12, 122, 226, 299, 300, 301, 302, 303, 304, 305, 306, 307, 475, 537], "i7": [12, 539, 548], "8700t": 12, "512": [12, 360, 435, 436, 446, 447, 448, 449, 536, 542], "xeon": [12, 13, 15, 127, 542], "5218t": 12, "8270": 12, "search": [12, 13, 81, 103, 122, 340, 382, 401, 473, 476, 492, 499, 500, 518, 524], "hw": [12, 127, 208, 502, 542, 547], "chang": [12, 14, 15, 74, 77, 80, 83, 84, 85, 87, 89, 95, 96, 106, 107, 109, 111, 117, 120, 121, 122, 127, 135, 148, 163, 220, 223, 226, 337, 349, 398, 419, 441, 446, 447, 448, 449, 466, 467, 477, 478, 496, 498, 500, 517, 524, 529, 533, 536, 539, 541, 542, 544, 546, 548, 549, 551, 565, 568, 569, 570], "order": [12, 16, 81, 82, 83, 84, 101, 106, 108, 111, 118, 119, 122, 129, 130, 132, 136, 148, 167, 209, 220, 221, 222, 242, 310, 323, 326, 328, 340, 347, 348, 349, 360, 361, 362, 367, 387, 388, 389, 390, 392, 400, 401, 408, 409, 432, 433, 434, 435, 436, 441, 446, 447, 448, 449, 450, 451, 452, 453, 460, 461, 462, 468, 492, 495, 502, 505, 506, 508, 509, 529, 533, 535, 539, 542, 543, 546, 547, 548, 549, 550, 555, 556, 557, 558, 564, 566, 567], "approach": [12, 13, 16, 78, 118, 122, 123, 129, 136, 148, 167, 171, 220, 222, 497, 513, 514, 517, 524, 525, 535, 536, 537, 543, 549, 551, 552, 554, 555, 560, 564, 566, 567, 570], "oppos": 12, "review": [12, 118, 122, 129, 132, 220, 525], "entir": [12, 14, 130, 132, 223, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 536, 537, 538, 571], "seismic": 12, "oil": 12, "ga": 12, "polici": [13, 127, 539, 545], "gen": [13, 15, 127], "coverag": [13, 521, 542], "mixtral": 13, "urlnet": 13, "chatglm3": 13, "qwen": [13, 498], "speed": [13, 75, 83, 148, 497, 502, 518, 521, 524, 536, 537, 542, 556, 563, 572], "llm": [13, 497, 498, 499, 500, 524, 569, 570], "readi": [13, 83, 84, 127, 210, 212, 473, 476, 477, 478, 479, 482, 486, 487, 490, 491, 493, 502, 522, 524, 525, 535, 539], "superior": [13, 493], "v9": 13, "v8": 13, "orient": [13, 502, 504, 511, 534, 541, 546, 554, 555, 562, 567], "bound": [13, 130, 244, 308, 320, 321, 322, 323, 326, 327, 328, 329, 330, 331, 341, 344, 361, 362, 379, 388, 389, 390, 391, 392, 398, 400, 416, 417, 434, 435, 436, 439, 451, 454, 455, 459, 502, 508, 541, 542, 550, 567], "oob": 13, "mobileclip": 13, "rmbg": 13, "background": [13, 75, 320, 321, 322, 330, 331, 451, 452, 453, 477, 478, 479, 487], "magika": 13, "triposr": 13, "animateanyon": 13, "llava": 13, "rag": [13, 500], "langchain": 13, "broader": 13, "techniqu": [13, 75, 408, 497, 518, 523, 524, 555], "1st": [13, 15, 109, 332, 353, 355, 358, 369, 371, 372, 376, 385, 398, 399, 419, 420, 434, 436, 439, 460, 462], "4th": [13, 15, 83, 109, 542], "5th": [13, 15, 109], "matrix": [13, 78, 312, 313, 315, 316, 317, 339, 361, 362, 367, 368, 369, 398, 433, 434, 435, 436, 438, 439, 451, 533, 542, 568], "int4": [13, 208, 497, 498, 524], "arc": [13, 15, 473, 497], "signific": [13, 14, 79, 213, 468, 521, 524, 542, 543, 552, 562, 565], "reduct": [13, 94, 367, 388, 390, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 497, 517, 520, 521, 524, 543], "smaller": [13, 118, 242, 244, 325, 339, 369, 387, 497, 523, 524, 525, 537, 541, 564, 568], "portabl": [13, 471, 502, 538, 556, 566, 567, 568], "cloud": [13, 74, 101, 127, 493, 497, 502], "preview": [13, 14, 74, 541, 543], "pypi": [13, 14, 75, 125, 475, 484, 485, 489, 492, 502, 514], "javascript": [13, 49, 486], "easili": [13, 76, 81, 108, 120, 135, 368, 471, 477, 478, 483, 493, 502, 527, 529, 539, 553, 561], "npm": [13, 49, 475, 484, 485, 489], "seamless": [13, 500, 553], "unicod": [13, 501, 571], "path": [13, 73, 77, 85, 91, 95, 96, 97, 98, 99, 103, 105, 106, 110, 111, 112, 113, 115, 116, 117, 118, 122, 127, 129, 130, 430, 431, 432, 477, 478, 479, 480, 481, 492, 496, 497, 499, 500, 501, 502, 504, 505, 506, 509, 516, 517, 522, 526, 527, 528, 530, 531, 541, 556, 563], "after": [13, 14, 81, 82, 95, 97, 98, 99, 100, 103, 104, 106, 107, 109, 110, 117, 118, 120, 122, 127, 129, 130, 135, 148, 163, 209, 212, 213, 216, 219, 220, 222, 226, 242, 260, 266, 275, 280, 283, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 320, 321, 323, 326, 329, 330, 331, 337, 341, 343, 358, 360, 361, 362, 363, 365, 366, 367, 369, 393, 398, 419, 432, 451, 470, 477, 478, 482, 488, 492, 496, 498, 500, 509, 517, 518, 519, 520, 522, 523, 524, 536, 541, 542, 545, 547, 553, 557, 558, 560, 565, 568, 570, 572], "warn": [13, 111, 337, 502, 540], "criteria": [13, 167, 518], "qualiti": [13, 14, 106, 126, 128, 135, 529], "return": [13, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 77, 80, 95, 96, 98, 103, 106, 108, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 132, 135, 148, 212, 213, 217, 218, 219, 222, 223, 274, 287, 302, 304, 310, 311, 322, 323, 326, 330, 331, 340, 341, 349, 352, 353, 355, 357, 358, 368, 390, 440, 450, 452, 453, 454, 455, 456, 457, 458, 459, 468, 479, 516, 519, 520, 522, 523, 530, 536, 539, 540, 541, 544, 547, 548, 551, 553, 556, 560, 569, 571], "enable_profil": [13, 542, 543, 547], "footprint": [13, 471, 493, 497, 498, 517, 518, 520, 521, 524, 541, 542], "moe": 13, "gemma": 13, "gpt": [13, 112, 497], "agnost": [13, 83, 112, 115, 118, 543, 546, 562], "unifi": [13, 16, 126, 208, 534], "binari": [13, 14, 15, 78, 83, 97, 106, 115, 216, 224, 226, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 296, 297, 298, 299, 300, 301, 305, 306, 307, 312, 354, 363, 365, 366, 493, 497, 500, 502, 504, 515, 524], "discret": [13, 15, 127, 209, 340, 420, 446, 473, 497, 543, 572], "immedi": [13, 367, 555, 567, 571], "repo": [13, 76, 111, 476, 490, 491, 496, 499, 500, 524], "hello": [13, 75, 129, 471, 476, 477, 478, 479, 482, 487, 490, 491, 501, 535, 538, 539, 542, 543, 548], "introduc": [13, 77, 79, 111, 120, 122, 224, 226, 245, 247, 248, 250, 251, 254, 256, 261, 262, 419, 468, 471, 472, 493, 494, 542, 546, 547, 551, 565, 566], "22h2": [13, 15, 547], "later": [13, 74, 123, 212, 213, 219, 473, 478, 480, 500, 524, 525, 533, 542, 552, 553], "gil": [13, 552], "free": [13, 15, 76, 83, 471, 495, 496, 497, 503, 511, 512, 524, 556, 562, 565], "creation": [13, 75, 118, 131, 136, 148, 210, 213, 216, 217, 222, 501, 520, 553], "remotetensor": [13, 218], "hold": [13, 127, 133, 212, 213, 222, 421, 422, 423, 424, 425, 426, 427, 428, 429, 468, 532, 551, 553, 571], "suit": [13, 111, 125, 126, 128, 497, 517, 534, 539], "multithread": 13, "lock": [13, 553, 567], "increas": [13, 84, 226, 471, 500, 502, 509, 518, 519, 523, 524, 537, 538, 541, 543, 546, 562, 564, 565, 566, 567], "bf16": [13, 341, 354, 356, 358, 419, 468, 498, 502, 542, 568], "wai": [13, 14, 83, 84, 85, 99, 103, 106, 114, 115, 118, 119, 122, 127, 129, 135, 167, 208, 210, 212, 216, 220, 222, 225, 248, 260, 286, 311, 314, 318, 333, 335, 336, 338, 346, 351, 355, 398, 401, 434, 436, 437, 439, 448, 460, 461, 462, 470, 481, 482, 488, 513, 514, 515, 516, 517, 519, 520, 522, 525, 529, 530, 533, 534, 537, 538, 539, 541, 544, 545, 546, 547, 549, 550, 551, 553, 554, 555, 556, 559, 560, 562, 564, 565, 568, 569, 570, 572], "handl": [13, 15, 79, 83, 106, 118, 120, 136, 213, 221, 344, 401, 499, 509, 526, 537, 542, 543, 546, 549, 553, 564, 565, 567, 568, 569, 571], "numpi": [13, 80, 111, 124, 254, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 309, 311, 349, 363, 365, 366, 367, 371, 372, 390, 398, 419, 420, 440, 468, 477, 478, 479, 497, 499, 500, 502, 525, 552, 553, 571], "prepostprocessoritem": 13, "partialshap": [13, 48, 60, 64, 80, 535, 551], "align": [13, 132, 136, 138, 141, 148, 163, 242, 314, 325, 337, 343, 346, 347, 351, 369, 371, 372, 432, 441, 468, 549, 553, 555], "cpp": [13, 83, 476, 490, 491, 504, 540], "exportmodel": 13, "import_model": [13, 212, 548, 553], "get_siz": [13, 571], "is_dynam": [13, 536], "tf": [13, 75, 80, 83, 85, 98, 99, 103, 105, 106, 107, 108, 109, 110, 111, 115, 122, 124, 132, 135, 216, 343, 511, 512, 518, 525, 530, 532], "textvector": 13, "hashtabl": 13, "dictionari": [13, 101, 108, 114, 118, 119, 120, 122, 124, 499, 535, 553, 572], "receiv": [13, 14, 111, 128, 213, 522, 538, 551, 570], "tf1": 13, "adjust": [13, 74, 85, 132, 320, 321, 327, 328, 329, 398, 471, 502, 519, 520, 526, 532, 535, 545, 561], "due": [13, 14, 81, 115, 117, 121, 122, 127, 132, 213, 225, 242, 368, 468, 521, 525, 541, 542, 543, 546, 562, 564, 565, 568, 569, 572], "extract": [13, 101, 106, 119, 123, 124, 133, 212, 216, 325, 367, 375, 394, 398, 432, 477, 478, 479, 499, 500, 544, 548, 552, 553, 572], "signatur": [13, 77, 115, 127, 529], "moduleextens": 13, "pr": 13, "23536": 13, "experiment": [13, 123, 419, 468, 529], "torch": [13, 77, 80, 85, 90, 92, 94, 95, 96, 114, 343, 440, 493, 502, 513, 518, 525, 532, 534], "fx": [13, 529, 572], "23815": 13, "backend": [13, 96, 133, 212, 213, 219, 497, 498, 502, 515, 534, 572], "string": [13, 16, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 80, 83, 97, 109, 118, 122, 123, 124, 130, 131, 132, 220, 248, 266, 275, 278, 280, 281, 282, 283, 285, 286, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 326, 330, 331, 332, 335, 336, 338, 339, 340, 341, 343, 344, 347, 348, 349, 352, 353, 354, 356, 357, 358, 361, 362, 363, 365, 366, 367, 371, 372, 374, 375, 383, 384, 385, 388, 390, 396, 401, 409, 410, 412, 413, 414, 415, 416, 417, 419, 420, 431, 433, 434, 435, 436, 438, 439, 443, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 466, 470, 499, 500, 502, 516, 535, 536, 541, 544, 546, 548, 549, 553, 559, 569], "take": [13, 75, 80, 82, 95, 104, 130, 131, 132, 133, 213, 222, 223, 225, 250, 251, 265, 269, 286, 293, 311, 314, 319, 322, 323, 324, 326, 330, 331, 332, 334, 340, 369, 371, 372, 376, 377, 378, 379, 384, 398, 437, 441, 446, 447, 449, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 476, 490, 491, 499, 502, 503, 522, 523, 524, 532, 534, 535, 539, 542, 543, 544, 545, 546, 556, 558, 562, 563], "advantag": [13, 16, 497, 529, 532, 555, 557], "reli": [13, 515, 543], "check": [13, 74, 77, 78, 82, 96, 99, 103, 118, 119, 122, 123, 127, 213, 216, 219, 221, 352, 353, 357, 358, 432, 471, 472, 473, 474, 476, 477, 478, 479, 480, 481, 482, 487, 488, 492, 493, 496, 500, 504, 525, 526, 527, 528, 529, 536, 541, 542, 546, 551, 556, 562, 563, 570, 571], "demo": [13, 14, 75, 76, 99, 101, 111, 130, 502, 503, 504, 505, 508, 509, 511, 512, 539, 546, 547, 549, 555], "sentenc": [13, 103, 110, 500, 569], "encod": [13, 93, 95, 98, 110, 124, 319, 320, 321, 332, 455, 456, 457, 458, 459, 499, 542, 555, 571], "mediapip": [13, 116, 531], "rel": [13, 95, 109, 118, 130, 224, 320, 321, 335, 336, 337, 338, 461, 523, 557, 562, 568], "relat": [13, 118, 122, 127, 148, 220, 224, 314, 440, 500, 519, 520, 540, 545, 547, 564, 569], "folder": [13, 95, 97, 99, 103, 211, 216, 477, 478, 479, 492, 498, 502, 504, 509, 548, 563], "arbitrari": [13, 132, 209, 212, 222, 242, 244, 245, 246, 247, 248, 251, 253, 254, 256, 260, 261, 262, 265, 266, 268, 269, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 359, 360, 363, 364, 365, 366, 373, 376, 377, 378, 383, 384, 388, 389, 390, 391, 392, 394, 397, 398, 399, 400, 401, 402, 405, 406, 407, 408, 409, 410, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 441, 442, 443, 445, 460, 461, 462, 466, 467, 468, 517, 536, 537, 543, 571], "without": [13, 14, 15, 79, 80, 95, 102, 103, 106, 109, 117, 118, 121, 122, 127, 131, 167, 213, 220, 222, 226, 319, 340, 355, 367, 388, 398, 444, 463, 464, 465, 493, 499, 500, 502, 504, 515, 516, 521, 523, 524, 526, 527, 528, 529, 530, 531, 533, 536, 539, 541, 542, 545, 546, 548, 550, 551, 557, 559, 560, 561, 562, 564, 568, 570, 571, 572], "kserv": 13, "properli": [13, 75, 120, 213, 472, 473, 476, 482, 490, 491, 504, 514, 537, 549, 567, 571], "json": [13, 87, 89, 98, 103, 106, 107, 110, 111, 122, 127, 502, 515], "bodi": [13, 82, 122, 216, 309, 355, 360, 570], "nvidia": [13, 213], "triton": 13, "showcas": [13, 555], "algorithm": [13, 67, 103, 108, 122, 125, 128, 209, 221, 226, 295, 296, 297, 298, 312, 325, 340, 341, 367, 368, 382, 403, 404, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 518, 522, 524], "deleg": 13, "subgraph": [13, 83, 106, 107, 115, 135, 138, 141, 216, 220, 222, 309, 522, 543, 545, 569, 570, 572], "defin": [13, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 78, 81, 82, 84, 101, 106, 108, 111, 114, 115, 118, 119, 120, 123, 124, 129, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 148, 208, 210, 212, 213, 215, 216, 219, 224, 226, 254, 308, 312, 314, 319, 329, 333, 339, 341, 353, 358, 360, 367, 368, 371, 372, 383, 384, 394, 407, 408, 409, 419, 420, 430, 434, 436, 439, 441, 448, 463, 465, 498, 499, 502, 516, 518, 519, 520, 522, 523, 530, 533, 536, 538, 539, 540, 542, 544, 546, 551, 557, 560, 562, 570, 572], "ignor": [13, 81, 148, 242, 312, 313, 314, 315, 316, 317, 318, 327, 328, 348, 369, 395, 398, 413, 414, 415, 416, 417, 440, 502, 522, 570], "scope": [13, 14, 81, 103, 122, 127, 216, 509, 542, 544, 567], "simplifi": [13, 118, 119, 213, 493, 499], "appli": [13, 77, 78, 81, 82, 96, 103, 106, 111, 120, 122, 125, 127, 129, 131, 135, 148, 208, 209, 212, 213, 220, 221, 222, 242, 245, 246, 247, 248, 250, 251, 253, 254, 255, 256, 257, 260, 262, 266, 269, 270, 275, 276, 278, 280, 281, 282, 283, 284, 285, 289, 291, 292, 293, 295, 297, 298, 299, 300, 301, 303, 305, 306, 307, 314, 315, 316, 318, 320, 321, 322, 323, 325, 326, 330, 331, 335, 336, 337, 338, 341, 347, 348, 349, 360, 361, 362, 363, 365, 366, 367, 369, 371, 372, 375, 377, 378, 380, 381, 388, 394, 400, 403, 404, 405, 406, 410, 411, 412, 413, 414, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 433, 434, 435, 436, 438, 439, 440, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 467, 468, 471, 483, 498, 502, 516, 517, 518, 521, 523, 524, 525, 529, 537, 541, 542, 543, 548, 551, 552, 553, 555, 556, 557, 558, 559, 560, 565, 568, 569, 571], "fine": [13, 517, 518, 521, 522, 543], "tune": [13, 224, 502, 517, 518, 521, 536, 543, 554], "easier": [13, 80, 85, 122, 497, 518, 524, 532, 554, 555, 556, 559, 560], "move": [13, 74, 109, 129, 135, 163, 219, 220, 370, 374, 396, 477, 478, 479, 490, 514], "translat": [13, 81, 103, 208, 224, 319, 332, 335, 336, 497, 554, 556, 561], "op": [13, 118, 119, 120, 121, 122, 123, 124, 131, 220, 242, 368, 401, 502, 516, 542, 551, 564, 572], "rwkv": [13, 500], "trie": [13, 500], "vocab": [13, 98, 103], "redesign": [13, 567], "branch": [13, 14, 109, 111, 131, 135, 163, 167], "maintain": [13, 74, 226, 401, 461, 471, 474, 496, 499, 518, 524, 572], "until": [13, 14, 74, 120, 135, 220, 340, 344, 416, 417, 502, 509, 529, 539, 550, 565, 567], "septemb": 13, "mainten": 13, "refactor": [13, 122], "directori": [13, 77, 87, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 103, 104, 106, 108, 109, 110, 111, 115, 118, 121, 213, 477, 478, 479, 480, 486, 490, 492, 496, 498, 499, 500, 502, 504, 516, 525, 526, 527, 530, 542, 572], "readm": [13, 96, 111, 115, 502, 530], "navig": [13, 479, 486, 502, 504], "content": [13, 83, 94, 110, 122, 127, 354, 371, 372, 383, 384, 441, 478, 480, 496, 529, 536, 547, 555, 571], "newli": [13, 14, 75, 118, 122, 220, 222, 499, 567], "ground": 13, "anyth": 13, "fast": [13, 493, 500, 555, 562, 572], "identif": [13, 81], "pose": [13, 76, 547, 562], "assist": [13, 494, 501], "reconstruct": 13, "id": [13, 81, 101, 111, 118, 122, 123, 127, 213, 224, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 478, 480, 499, 500, 543, 547, 553, 570], "pin": [13, 127, 330, 331, 502, 542, 564], "instead": [13, 14, 77, 83, 84, 103, 106, 118, 119, 122, 123, 127, 132, 224, 333, 360, 368, 398, 440, 477, 478, 479, 492, 498, 502, 524, 525, 527, 529, 530, 534, 540, 542, 543, 546, 547, 549, 550, 553, 556, 565, 569, 571, 572], "bring": [13, 127, 536, 541, 544], "enable_cpu_pin": [13, 507, 542, 547], "disabl": [13, 79, 118, 122, 135, 213, 220, 371, 372, 502, 523, 526, 541, 542, 543, 546, 552, 556, 570], "explicitli": [13, 74, 77, 78, 79, 83, 115, 226, 314, 502, 513, 515, 525, 530, 539, 540, 541, 542, 543, 544, 545, 546, 564, 567], "observ": [13, 539], "newer": [13, 14, 83, 542, 543], "mitig": [13, 468, 500], "modifi": [13, 83, 96, 103, 117, 118, 120, 127, 135, 220, 348, 368, 398, 500, 503, 511, 512, 519, 522, 526, 529, 530, 552, 553, 557, 572], "bio": [13, 127], "numa": [13, 502, 542, 556, 562], "menu": [13, 479], "edkii": 13, "uncor": 13, "snc": 13, "boot": [13, 127, 473, 474], "reboot": 13, "confirm": [13, 516], "numatcl": 13, "h": [13, 75, 77, 106, 109, 117, 319, 324, 325, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 345, 346, 348, 350, 351, 361, 362, 371, 372, 393, 406, 408, 411, 412, 413, 414, 415, 416, 417, 418, 433, 434, 435, 438, 439, 481, 502, 509, 516, 526, 559, 560], "expect": [13, 14, 119, 122, 130, 131, 132, 135, 222, 340, 344, 353, 358, 370, 379, 388, 389, 390, 391, 392, 395, 406, 499, 502, 505, 506, 508, 509, 520, 536, 537, 543, 544, 555, 557, 559, 562, 569], "21": [13, 15, 295, 297, 298, 340, 375, 377, 378, 380, 381, 496, 502, 508], "noteworthi": 13, "valid": [13, 14, 15, 75, 99, 117, 126, 127, 129, 130, 131, 222, 312, 313, 314, 315, 316, 317, 318, 330, 331, 375, 383, 384, 410, 413, 414, 415, 416, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 451, 452, 453, 479, 502, 508, 510, 511, 512, 518, 521, 522, 524, 537, 541, 567, 571, 572], "stablelm": 13, "alpha": [13, 132, 245, 249, 254, 256, 260, 407], "3b": [13, 524], "epoch": [13, 95, 226, 519, 520], "mixtur": [13, 497], "expert": [13, 497, 518], "pipelin": [13, 82, 85, 106, 117, 119, 120, 121, 122, 123, 133, 136, 148, 210, 212, 219, 497, 498, 500, 502, 518, 521, 524, 539, 541, 544, 549, 552, 553, 555, 556, 561, 562], "smooth": [13, 262], "kv": [13, 497, 498, 500], "tailor": [13, 311, 481], "queri": [13, 440, 494, 497, 501, 502, 536, 538, 539, 541, 542, 543, 545, 549, 556, 566, 567, 569], "chatglm": 13, "ecosystem": [13, 73, 469, 483, 499], "preserv": [13, 16, 95, 106, 137, 139, 148, 163, 220, 398, 419, 441, 461, 498, 522, 523, 524, 536, 543, 562, 569], "codenam": [13, 15], "meteor": [13, 15, 472, 547], "lake": [13, 15, 472, 547], "thread": [13, 127, 210, 212, 213, 502, 539, 543, 544, 546, 548, 550, 552, 553, 555, 556, 564, 565, 567, 569], "maco": [13, 15, 75, 480, 481, 482, 483, 486, 487, 488, 492, 493, 496, 500, 504, 515], "retriev": [13, 115, 118, 460, 461, 462, 471, 544, 551, 553, 567, 569, 571], "augment": [13, 96], "stringtensor": 13, "foundat": 13, "complianc": 13, "hub": [13, 77, 115, 116, 483, 496, 499, 504, 505, 506, 508, 509, 511, 512, 525, 530, 531], "avx512": [13, 542], "13th": [13, 15], "14th": [13, 15], "speedup": [13, 569], "dynamic_quantization_group_s": [13, 498], "kv_cache_precis": [13, 498], "u8": [13, 50, 72, 135, 148, 354, 356, 358, 468, 498, 502, 509, 510, 542, 543, 547, 557], "2025": [13, 74, 542], "valuabl": [13, 469], "igpu": [13, 476, 477, 479, 480, 481, 482, 487, 488, 490, 491, 496, 538, 539, 566], "context": [13, 104, 118, 133, 213, 219, 340, 418, 569], "decreas": [13, 106, 499, 500, 537, 542, 545, 565], "larger": [13, 79, 111, 167, 242, 320, 321, 322, 339, 340, 387, 394, 441, 498, 524, 541, 543], "yolov5": 13, "16gb": 13, "pip": [13, 14, 97, 111, 115, 477, 478, 479, 481, 490, 491, 492, 496, 498, 499, 500, 503, 504, 514, 518, 522, 524], "add_extens": [13, 103, 129, 131, 500], "behavior": [13, 83, 106, 118, 123, 216, 226, 278, 282, 343, 398, 425, 427, 434, 436, 437, 439, 461, 468, 539, 542, 543, 544, 545, 546, 551, 565, 568], "ov_property_key_cache_mod": 13, "cache_mod": 13, "optimize_s": 13, "optimize_spe": 13, "va": [13, 544], "surfac": [13, 543], "registri": 13, "linux": [13, 15, 75, 99, 108, 127, 474, 475, 480, 481, 483, 486, 487, 488, 492, 493, 496, 499, 500, 504, 514, 515, 542, 544, 547, 549], "22024": 13, "multilingu": [13, 98], "modul": [13, 77, 80, 85, 96, 114, 115, 119, 127, 316, 319, 463, 464, 465, 473, 529, 530, 532, 534, 561, 572], "patch": [13, 313, 375, 476, 490, 491], "fe": 13, "fallback": [13, 131, 539, 542], "frontend": [13, 83, 112, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 129, 481, 526, 565], "longer": [13, 74, 77, 83, 86, 109, 539, 543, 545, 563, 568], "config": [13, 53, 91, 92, 94, 95, 103, 106, 110, 111, 117, 127, 130, 213, 482, 496, 498, 502, 516, 543, 546, 556, 572], "remain": [13, 81, 103, 129, 131, 135, 226, 244, 369, 398, 402, 497, 524, 541, 570], "21523": 13, "mutabl": [13, 136, 548], "22270": 13, "u16": [13, 50, 72, 354, 356, 358, 502, 542], "u32": [13, 50, 72, 354, 356, 358, 468, 502, 542], "u64": [13, 50, 72, 354, 356, 358, 468, 502, 542], "21864": 13, "22180": 13, "crash": [13, 537, 543], "int16": [13, 83], "20838": 13, "indexerror": 13, "22326": 13, "correct": [13, 81, 106, 108, 118, 126, 127, 129, 213, 380, 461, 477, 478, 479, 492, 496, 506, 516, 522, 529, 541, 544], "integ": [13, 81, 100, 108, 111, 118, 130, 208, 252, 258, 275, 286, 290, 294, 295, 296, 297, 298, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 344, 347, 348, 349, 354, 355, 356, 358, 360, 361, 362, 369, 370, 371, 372, 373, 374, 375, 377, 378, 380, 381, 382, 383, 384, 385, 386, 388, 389, 392, 393, 394, 395, 396, 397, 398, 399, 400, 402, 407, 410, 413, 414, 415, 416, 417, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 441, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 466, 467, 468, 502, 517, 518, 521, 524, 542, 553, 557, 560, 568, 571], "22684": 13, "bad": 13, "tensorshap": 13, "22813": 13, "attribut": [13, 101, 106, 111, 119, 120, 122, 123, 124, 130, 131, 135, 148, 220, 222, 223, 224, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 347, 348, 349, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 509, 568], "22752": 13, "dict": [13, 83, 122, 123, 349, 529, 553], "tupl": [13, 77, 80, 101, 113, 114, 122, 123, 216, 310, 319, 320, 321, 322, 325, 326, 332, 335, 336, 337, 338, 349, 380, 381, 450, 451, 452, 453, 522, 528, 529, 533, 535, 559], "clearer": 13, "22821": 13, "kwarg": 13, "22397": 13, "unari": [13, 263, 264, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 279, 284, 286, 287, 288, 289, 290, 293, 294, 296, 364], "servabl": 13, "incom": [13, 81, 105, 120, 360, 542, 543], "awq": [13, 524], "ratio": [13, 119, 126, 319, 325, 327, 328, 330, 331, 338, 498, 524, 542], "compress_weight": [13, 524], "quantize_with_accuracy_control": [13, 523], "tutori": [13, 75, 78, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 476, 477, 478, 479, 482, 487, 490, 491, 494, 496, 526, 527, 528, 529, 532], "appropri": [13, 83, 226, 355, 398, 502, 504, 515, 533, 536, 557, 559], "hyperparamet": [13, 110], "tinyllama": [13, 499], "regex": [13, 522], "metadata": 13, "rt_info": [13, 220, 500], "muse": [13, 500], "openvino_token": [13, 499, 500], "mobil": 13, "mobilevlm": 13, "depthanyth": 13, "kosmo": 13, "siglip": 13, "person": [13, 127, 508, 513], "photomak": 13, "voic": 13, "tone": 13, "openvoic": 13, "surya": 13, "instantid": 13, "big": [13, 224, 244, 253, 256, 537], "chatbot": [13, 498, 569], "minicpm": 13, "2b": 13, "dpo": 13, "qwen1": 13, "baichuan2": 13, "unless": [13, 550, 570], "132376": 13, "slow": [13, 518, 542], "down": [13, 127, 348, 349, 388, 413, 414, 473, 477, 519, 535, 540], "radic": 13, "long": [13, 15, 90, 127, 224, 398, 435, 475, 481, 497, 503, 514, 516, 519, 544, 569], "gb": [13, 79, 524], "those": [13, 83, 104, 115, 129, 132, 226, 312, 313, 315, 316, 317, 320, 321, 330, 331, 340, 344, 348, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 461, 499, 524, 530, 536, 542, 553, 559, 563], "prompt": [13, 127, 477, 478, 479, 496, 498, 499, 500, 502, 504, 572], "lower": [13, 100, 101, 103, 106, 111, 127, 130, 135, 226, 244, 339, 340, 341, 368, 380, 451, 468, 473, 497, 498, 502, 518, 521, 524, 525, 536, 539, 543, 565, 568, 572], "overhead": [13, 524, 535, 536, 541, 542, 543, 544, 552, 564, 566, 567, 569], "workaround": [13, 530], "transit": [13, 74, 78, 525, 532], "last": [13, 14, 74, 81, 83, 85, 118, 132, 135, 222, 340, 345, 346, 350, 351, 355, 360, 361, 362, 380, 381, 387, 390, 391, 392, 393, 394, 398, 401, 414, 415, 416, 417, 418, 433, 434, 435, 436, 438, 439, 446, 447, 448, 477, 478, 500, 502, 509, 522, 524, 548, 556, 557], "gaussian": [13, 247, 248, 368, 451], "onnx_importer_api": 13, "perfomancemod": 13, "undefin": [13, 81, 82, 84, 108, 118, 222, 275, 278, 282, 290, 322, 323, 324, 326, 343, 368, 388, 389, 391, 392, 425, 427, 432, 434, 436, 437, 439, 450, 451, 452, 453, 460, 461, 462, 466, 467, 468, 533, 551, 569, 571], "pot": [13, 74], "git": [13, 91, 92, 95, 96, 97, 98, 99, 103, 108, 109, 110, 111, 127, 496, 500, 516], "huggingfac": [13, 504, 505, 506, 508, 509, 511, 512, 517], "top": [13, 118, 119, 122, 127, 274, 312, 313, 315, 316, 317, 319, 323, 326, 327, 328, 329, 330, 331, 344, 413, 414, 415, 416, 417, 451, 460, 462, 504, 505, 506, 509, 510, 522, 524, 534, 540, 544, 555, 571], "apach": [13, 74, 76, 83, 86, 319, 320, 321], "mxnet": [13, 74, 85, 86, 319, 320, 321], "caff": [13, 74, 85, 86, 118, 120, 121, 122, 123, 124, 320, 321, 328, 330, 331, 510], "kaldi": [13, 74, 85, 86], "dev": [13, 14, 75, 77, 115, 127, 211, 213, 473, 492, 496, 516, 522, 525, 530], "replac": [13, 74, 77, 81, 84, 95, 99, 100, 104, 107, 111, 117, 118, 122, 123, 127, 132, 163, 222, 223, 225, 244, 340, 367, 368, 398, 418, 496, 525, 526, 529, 533, 536, 542, 544, 562, 569, 570, 571], "io": [13, 115, 483, 496, 529], "handwritten": 13, "ocr": [13, 78, 84, 533], "altern": [13, 77, 78, 84, 105, 118, 127, 220, 440, 473, 490, 491, 496, 504, 529, 539, 543, 546, 567], "optic": 13, "charact": [13, 97, 367, 430, 432, 473, 501, 571], "paddleocr": 13, "paint": 13, "inpaint": 13, "interact": [13, 107, 127, 494, 498, 527, 528, 529, 544], "super": [13, 77, 94, 96, 115, 123, 530], "resolut": [13, 94, 97, 131], "paddlegan": 13, "color": [13, 82, 101, 106, 111, 501, 506, 544, 547, 557, 558, 563], "barrier": 13, "camera": [13, 502, 555, 567], "decidiffus": 13, "deepfloyd": 13, "IF": 13, "vi": 13, "databrick": [13, 498, 524], "dolli": [13, 498, 524], "fastcompos": 13, "subtitl": [13, 529], "whisper": [13, 529], "speech": [13, 76, 93, 100, 106, 569], "distil": 13, "introduct": [13, 86, 120, 132], "trick": 13, "speaker": 13, "diariz": 13, "subject": [13, 15, 96, 419, 543], "driven": [13, 555], "edit": [13, 83, 99, 122, 127, 496], "blip": [13, 529], "predict": [13, 81, 88, 95, 97, 108, 109, 120, 320, 321, 322, 323, 326, 330, 331, 451, 452, 453, 454, 455, 456, 457, 458, 459, 500, 529, 536, 549, 554, 567, 570], "yolov7": 13, "data2vec": 13, "ptq": 13, "lraspp": 13, "slowfast": 13, "live": [13, 127], "segmind": 13, "1b": [13, 499, 524], "2d": [13, 254, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 332, 333, 335, 336, 337, 338, 339, 340, 348, 349, 361, 362, 368, 369, 370, 388, 394, 398, 403, 404, 413, 414, 415, 416, 417, 418, 431, 432, 433, 434, 435, 436, 438, 439, 444, 445, 449, 450], "kidnei": 13, "monai": 13, "lightn": [13, 530], "ct": [13, 432, 435], "infring": [13, 15], "concern": [13, 15, 543], "herein": [13, 15], "agre": [13, 15], "grant": [13, 15], "exclus": [13, 15, 213, 274, 341, 394, 398], "royalti": [13, 15], "patent": [13, 15], "thereaft": [13, 15], "draft": [13, 15], "matter": [13, 15, 122, 222, 347, 348, 349, 446, 447, 448, 449, 528, 530, 531, 532], "disclos": [13, 15], "express": [13, 15, 82, 117, 118, 122, 132, 208, 209, 222, 226, 335, 336, 338, 367, 371, 372, 419, 420, 522, 535, 556], "impli": [13, 15, 83, 226, 315, 316, 368, 369, 441, 556, 564, 571], "estoppel": [13, 15], "otherwis": [13, 15, 83, 101, 102, 106, 111, 118, 123, 129, 132, 210, 220, 222, 223, 254, 274, 302, 304, 320, 321, 322, 324, 333, 337, 348, 349, 352, 357, 360, 361, 362, 385, 387, 388, 398, 402, 408, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 441, 444, 446, 447, 448, 449, 456, 457, 458, 461, 498, 502, 519, 537, 539, 541, 542, 543, 546, 549, 551, 567, 569, 570, 571], "intellectu": [13, 15, 469], "right": [13, 15, 76, 83, 101, 132, 163, 215, 242, 244, 245, 247, 248, 252, 256, 262, 308, 312, 313, 315, 316, 317, 327, 328, 329, 341, 344, 369, 370, 372, 398, 399, 413, 414, 415, 416, 417, 446, 447, 448, 449, 473, 479, 502, 517, 556, 560, 566, 572], "notic": [13, 15, 130, 132, 340, 368, 398, 502, 524], "contact": [13, 15, 127], "obtain": [13, 15, 85, 93, 112, 114, 118, 122, 123, 127, 224, 341, 368, 389, 513, 517, 525, 526, 529, 532, 538, 542, 543, 544, 553, 568], "roadmap": [13, 15], "defect": [13, 15], "errata": [13, 15], "character": [13, 15, 471], "atom": [13, 15], "arria": [13, 15], "logo": [13, 15], "countri": [13, 15], "copyright": [13, 15, 470], "reserv": [13, 15, 539], "our": [13, 15, 476, 480, 488, 490, 491, 493], "target": [14, 83, 103, 130, 132, 136, 148, 208, 209, 211, 213, 216, 226, 227, 320, 321, 360, 389, 419, 432, 440, 468, 470, 471, 497, 502, 504, 509, 514, 515, 516, 519, 522, 524, 540, 541, 542, 543, 544, 555, 556, 557, 560, 568], "year": [14, 74], "bug": [14, 83, 96, 226, 473, 526, 530], "gold": 14, "beta": [14, 118, 132, 249, 260, 262, 403, 404, 407, 524], "newest": 14, "arriv": [14, 541, 564, 567], "suitabl": [14, 98, 502, 504, 509, 515, 529, 537, 539], "frequent": [14, 526, 529, 536, 569], "becom": [14, 81, 148, 543, 544, 548, 550, 568, 569], "continu": [14, 83, 109, 127, 128, 242, 349, 456, 457, 458, 502, 504, 539, 555], "even": [14, 73, 75, 81, 106, 118, 120, 129, 286, 309, 368, 493, 494, 519, 525, 526, 532, 533, 534, 536, 537, 541, 542, 543, 545, 546, 556, 557, 562, 565, 569, 571], "There": [14, 75, 77, 81, 82, 99, 100, 101, 102, 103, 104, 106, 108, 111, 112, 115, 118, 120, 121, 122, 123, 124, 126, 129, 130, 132, 135, 222, 226, 242, 355, 420, 432, 446, 447, 448, 449, 453, 481, 482, 500, 502, 516, 525, 530, 535, 536, 540, 542, 544, 553, 559, 566, 567, 569], "upgrad": [14, 75, 487, 492, 493, 496], "challeng": [14, 470], "lifecycl": 14, "cycl": [14, 118, 562, 569], "yearli": 14, "aim": [14, 126, 208, 521, 554], "onc": [14, 75, 81, 97, 104, 211, 213, 226, 387, 471, 482, 493, 496, 497, 498, 500, 502, 504, 513, 516, 517, 522, 524, 525, 529, 532, 535, 536, 537, 539, 544, 546, 548, 550, 557, 558, 562, 564, 566, 567], "durat": [14, 219, 502, 511, 512, 550], "supersed": [14, 114], "consecut": [14, 355, 367, 375, 431, 565, 569], "discov": [14, 76, 132], "cover": [14, 77, 83, 86, 95, 109, 114, 118, 120, 132, 226, 367, 415, 416, 417, 502, 555, 558, 570], "associ": [14, 111, 120, 224, 226, 309, 340, 518, 543, 549, 551, 555, 556, 566], "guarante": [14, 135, 226, 451, 452, 453, 461, 542, 544, 547, 550, 551, 553, 555, 564, 568], "highlight": 14, "workflow": [14, 73, 125, 129, 472, 476, 480, 481, 488, 490, 491, 517, 525, 532, 534, 536], "prioriti": [14, 167, 213, 468, 502, 515, 545, 546, 548, 562], "previou": [14, 81, 85, 88, 104, 105, 118, 122, 130, 132, 135, 136, 213, 224, 226, 456, 457, 458, 477, 478, 479, 499, 516, 519, 520, 543, 544, 550, 551, 555, 558, 567, 569, 570], "workdai": 14, "master": [14, 97, 109], "fit": [14, 111, 127, 130, 148, 213, 371, 372, 468, 502, 521, 539, 557, 559], "never": [14, 109, 564, 569], "earli": 14, "progress": [14, 77, 127], "archiv": [14, 15, 75, 98, 100, 106, 110, 127, 475, 484, 485, 489, 492, 500, 504], "go": [14, 81, 84, 88, 95, 96, 98, 99, 103, 104, 111, 118, 126, 127, 128, 220, 222, 226, 452, 453, 454, 455, 459, 479, 492, 497, 504, 513, 533, 535, 549, 554], "proce": [14, 74, 81, 481, 482, 496, 497, 513, 555], "wheel": [14, 496, 500, 572], "s3": 14, "aw": [14, 497], "renam": [14, 122, 127, 477, 478, 479, 499], "extra": [14, 75, 115, 134, 214, 226, 312, 313, 314, 315, 316, 317, 318, 375, 413, 414, 415, 416, 417, 498, 500, 518, 519, 520, 526, 529, 530, 534, 543, 553, 571], "url": [14, 492, 496, 500], "storag": [14, 101, 110, 127, 477, 478, 479, 497, 500, 505, 506, 508, 509, 524, 526, 532, 542, 565, 568, 571], "candid": [14, 451, 452, 453, 546], "pass": [14, 77, 80, 81, 83, 106, 108, 113, 115, 118, 122, 130, 131, 132, 135, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 210, 212, 213, 219, 314, 344, 355, 360, 385, 432, 470, 502, 510, 516, 522, 526, 527, 528, 529, 530, 535, 536, 541, 542, 543, 544, 548, 549, 550, 551, 553, 557, 558, 563, 565, 569, 571, 572], "determin": [14, 93, 101, 108, 115, 122, 131, 219, 226, 314, 333, 340, 341, 348, 368, 375, 379, 385, 398, 402, 411, 412, 460, 461, 462, 499, 502, 536, 555, 565], "verifi": [14, 75, 127, 129, 216, 476, 490, 491, 492], "print": [14, 77, 83, 96, 98, 106, 220, 487, 492, 496, 498, 499, 500, 502, 507, 509, 524, 526, 529, 536, 542, 543, 551, 571], "__version__": 14, "unzipped_archive_root": 14, "txt": [14, 98, 111, 132, 211, 477, 478, 479, 481, 496, 503, 504], "premier": 14, "clearli": 14, "selector": [14, 75], "gite": 14, "dockerhub": [14, 473, 483], "manual": [15, 83, 95, 122, 127, 216, 220, 221, 222, 348, 468, 474, 479, 483, 496, 502, 504, 505, 508, 509, 539, 552, 557, 560, 565, 568, 569], "correctli": [15, 83, 132, 314, 416, 417, 482, 492, 504, 517], "might": [15, 127, 129, 226, 340, 344, 461, 468, 473, 476, 492, 509, 514, 524, 542, 543, 553], "kernel": [15, 81, 117, 123, 127, 129, 132, 135, 167, 212, 213, 312, 313, 314, 315, 316, 317, 318, 411, 412, 413, 414, 415, 416, 417, 418, 473, 474, 502, 516, 536, 542, 543, 544, 547, 567, 572], "These": [15, 75, 83, 106, 109, 111, 118, 127, 135, 212, 219, 220, 222, 348, 349, 355, 371, 372, 446, 447, 448, 449, 473, 498, 499, 518, 519, 520, 527, 536, 541, 542, 543, 545, 551, 557, 559, 570], "sse4": 15, "pentium": 15, "n4200": 15, "n3350": 15, "n3450": 15, "6th": [15, 109], "armv7a": 15, "higher": [15, 106, 213, 314, 318, 451, 468, 473, 474, 476, 477, 478, 479, 480, 481, 486, 490, 491, 496, 497, 502, 504, 514, 524, 529, 536, 539, 542, 543, 567, 568], "arm64": [15, 475, 477, 480, 481, 482, 486, 487, 488, 500, 504, 515, 542], "v8a": 15, "mac": [15, 127, 542], "silicon": 15, "ubuntu": [15, 127, 473, 474, 475, 476, 477, 480, 496, 514, 545, 547], "abov": [15, 75, 83, 100, 106, 109, 111, 115, 118, 120, 129, 132, 211, 213, 222, 224, 226, 367, 368, 383, 384, 398, 400, 440, 461, 473, 477, 478, 487, 492, 496, 498, 502, 515, 516, 529, 530, 536, 539, 543, 544, 545, 549, 570, 571], "cento": [15, 473, 477, 490, 496], "7": [15, 81, 83, 96, 99, 100, 101, 103, 106, 109, 111, 119, 135, 226, 242, 243, 248, 266, 275, 278, 280, 281, 282, 283, 285, 290, 291, 292, 295, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 311, 313, 319, 320, 321, 322, 325, 331, 335, 336, 337, 340, 342, 343, 360, 361, 362, 363, 365, 366, 367, 374, 375, 377, 378, 379, 380, 381, 383, 384, 387, 388, 389, 390, 391, 394, 396, 415, 417, 418, 434, 435, 436, 439, 446, 447, 451, 452, 453, 454, 455, 459, 463, 464, 465, 476, 477, 480, 490, 492, 502, 508, 509, 510, 524, 545], "red": [15, 83, 345, 346, 350, 351, 483, 496, 514, 557], "hat": [15, 403, 404, 483, 496, 514], "enterpris": [15, 496, 514], "opensus": [15, 491], "tumblewe": [15, 491], "uhd": [15, 539], "iri": [15, 539, 543], "pro": [15, 496], "xe": [15, 539, 543], "seri": [15, 362, 434, 436, 439, 497, 569], "flex": [15, 473, 497], "card": [15, 496], "old": [15, 74, 85, 226, 396], "48": [15, 340, 347, 348, 349, 370, 373, 375, 383, 384, 395, 502, 524], "23h2": [15, 547], "cmake": [15, 127, 129, 133, 216, 476, 477, 478, 479, 480, 481, 482, 488, 490, 491, 504, 515, 516], "10th": [15, 109, 509], "11th": [15, 109, 542], "12th": [15, 109], "hybrid": [15, 502], "studio": [15, 479, 496, 504, 516], "2019": [15, 96, 479, 504, 516], "xcode": [15, 478, 480, 496], "onetbb": 15, "redhat": [15, 473, 483], "tbb": [15, 515, 516], "known": [15, 81, 83, 106, 118, 135, 226, 314, 346, 348, 349, 351, 472, 510, 530, 533, 536, 542, 547, 557, 560, 569, 571], "comprehens": [16, 125, 474, 492], "convent": [16, 226, 367, 498, 502, 536, 539, 541, 545, 546, 562, 564], "namespac": [16, 80, 94, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 551], "duplic": [16, 327, 328, 383, 384, 388, 390, 391, 431, 567], "address": [16, 127, 397, 402, 492, 496, 529, 536, 543, 546, 557, 565, 569], "constexpr": [16, 548], "full_nam": [16, 542, 543, 547, 548], "full_device_nam": [16, 507], "wrapper": [31, 77, 118, 212, 213, 522, 544, 553], "node": [48, 81, 97, 100, 103, 104, 105, 106, 107, 108, 109, 111, 115, 118, 119, 120, 123, 124, 131, 132, 209, 213, 221, 222, 223, 224, 226, 355, 360, 413, 414, 415, 416, 417, 461, 502, 518, 522, 530, 535, 542, 545, 551, 556, 560, 562, 570], "nodeaddon": 48, "coreconstructor": 48, "partialshapeconstructor": 48, "tensorconstructor": 48, "typeof": 48, "prepostprocessor": [48, 66, 77, 553, 558, 560], "prepostprocessorconstructor": 48, "resizealgorithm": [48, 67, 560], "192": [48, 502], "declar": [48, 83, 129, 130, 131, 212, 213, 215, 216, 217, 219, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 352, 357, 544, 548], "193": 48, "195": 48, "194": 48, "201": [48, 502, 545], "169": [48, 64, 333], "addon": [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 127], "182": 50, "f64": [50, 72, 341, 468, 502, 542], "183": 50, "i16": [50, 72, 354, 356, 358, 468, 502, 542], "179": 50, "i32": [50, 72, 98, 103, 308, 310, 322, 326, 339, 340, 341, 343, 354, 356, 358, 388, 390, 401, 412, 416, 417, 431, 443, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 466, 468, 502, 542], "180": [50, 329], "i64": [50, 72, 109, 308, 310, 326, 340, 341, 354, 356, 358, 360, 401, 411, 412, 416, 417, 431, 443, 451, 452, 453, 454, 455, 457, 458, 459, 460, 461, 462, 468, 502, 542], "181": [50, 540], "178": 50, "176": 50, "175": 50, "177": 50, "174": 50, "resize_cub": 51, "188": 51, "resize_linear": 51, "189": 51, "resize_nearest": 51, "187": [51, 508], "createinferrequest": 52, "exportmodelsync": 52, "buffer": [52, 53, 353, 358, 470, 506, 543, 544, 557, 558, 560, 567, 569], "nameorid": [52, 59], "67": [52, 127, 330, 375], "66": [52, 127, 375, 502, 511], "85": [52, 329, 375, 502], "83": [52, 375], "compilemodel": 53, "devicenam": [53, 540, 548], "promis": [53, 55, 565], "compilemodelsync": 53, "getavailabledevic": 53, "getproperti": 53, "propertynam": [53, 548], "boolean": [53, 59, 63, 102, 135, 137, 139, 141, 213, 226, 274, 275, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 316, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 333, 344, 347, 348, 349, 354, 355, 356, 358, 361, 362, 363, 364, 365, 366, 369, 385, 388, 390, 401, 408, 409, 413, 414, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 440, 441, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 468, 524, 542], "importmodelsync": 53, "modelstream": 53, "readmodel": 53, "modelpath": 53, "weightspath": 53, "modelbuff": 53, "weightsbuff": 53, "readmodelsync": 53, "setproperti": 53, "prop": 53, "void": [53, 55, 130, 544, 569], "24": [53, 327, 328, 330, 348, 349, 360, 375, 376, 377, 378, 380, 381, 388, 397, 402, 407, 408, 409, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 441, 460, 462, 524], "45": [53, 109, 111, 135, 340, 375], "57": [53, 91, 96, 329, 375, 524], "39": [53, 329, 375, 377, 378, 502], "34": [53, 329, 375, 377, 378, 512, 524], "uint8arrai": [53, 71], "35": [53, 96, 109, 126, 330, 331, 375, 377, 378, 380, 381, 512], "37": [53, 295, 297, 298, 333, 375, 377, 378, 383, 384, 502], "52": [53, 127, 333, 341, 375, 388, 508, 557], "53": [53, 91, 111, 329, 375, 511], "getcompiledmodel": 55, "getinputtensor": 55, "idx": [55, 120, 130, 340, 499, 500], "getoutputtensor": 55, "gettensor": 55, "nameoroutput": 55, "inputdata": 55, "outputnam": 55, "inferasync": 55, "setinputtensor": 55, "idxortensor": 55, "setoutputtensor": 55, "settensor": 55, "101": [55, 557], "112": [55, 81], "106": [55, 313], "107": [55, 103, 502], "105": [55, 103], "inputnam": 55, "supportedtypedarrai": [55, 68, 69], "108": [55, 502], "110": 55, "103": [55, 91, 96], "104": [55, 78, 82, 388, 512], "102": [55, 87, 89], "inputmodelinfo": [56, 560], "preprocessstep": [56, 557, 560], "inputtensorinfo": [56, 62, 543, 560], "144": 56, "147": [56, 502], "146": 56, "145": 56, "setlayout": [57, 58, 62], "140": 57, "141": [57, 502], "setelementtyp": [58, 62], "elementtyp": [58, 62], "setshap": 58, "126": 58, "elementtypestr": [58, 62, 69], "127": [58, 80, 108, 135, 341, 496], "129": [58, 545], "getnam": 59, "isdynam": [59, 63], "70": [59, 83, 341, 375, 388, 502], "69": [59, 83, 375], "73": [59, 375, 502], "71": [59, 83, 340, 375, 502], "anynam": 60, "getanynam": 60, "getpartialshap": 60, "getshap": [60, 68], "tostr": [60, 63], "117": [60, 78, 82, 502], "118": [60, 502], "119": [60, 111], "121": [60, 111], "123": [60, 78, 82, 91, 96, 127, 398], "122": [60, 87, 89], "120": [60, 295, 297, 298, 431, 432, 502], "interfaceoutputinfo": 61, "outputtensorinfo": [61, 560], "150": [61, 84, 341, 441, 454, 455, 458, 459, 533], "151": 61, "132": [62, 398], "133": 62, "134": 62, "getdimens": 63, "isstat": 63, "163": 63, "167": [63, 502, 540], "165": 63, "164": [63, 346, 351], "166": [63, 502], "170": [64, 446, 447, 448, 449], "idxortensornam": 65, "inputinfo": 65, "outputinfo": 65, "154": [65, 504, 509], "155": 65, "156": [65, 111, 504, 509], "157": [65, 95, 504, 509], "159": 66, "160": [66, 348, 349], "136": 67, "137": 67, "getdata": 68, "getelementtyp": 68, "getsiz": 68, "88": [68, 83, 375, 399], "92": [68, 341, 375, 502, 524], "90": [68, 111, 375, 511, 524], "91": [68, 375, 502, 524], "tensordata": 69, "94": [69, 96, 329, 375], "115": [70, 87, 89, 502], "int8arrai": 71, "int16arrai": 71, "uint16arrai": 71, "int32arrai": 71, "uint32arrai": 71, "float32arrai": 71, "float64arrai": 71, "doc": [73, 127, 371, 372, 529], "apart": [73, 375, 537], "expans": [73, 125], "revolv": 73, "constitut": [73, 541, 564], "necessari": [73, 81, 82, 96, 99, 103, 106, 108, 112, 113, 115, 116, 118, 119, 122, 124, 132, 135, 210, 220, 320, 321, 368, 369, 398, 408, 440, 451, 452, 453, 454, 455, 456, 457, 458, 459, 468, 475, 479, 482, 498, 500, 502, 504, 514, 516, 523, 526, 549, 550, 557, 569], "give": [73, 74, 83, 106, 113, 115, 129, 212, 222, 474, 504, 513, 519, 526, 536, 537, 542, 543, 559, 567, 569], "function": [73, 74, 75, 77, 80, 82, 85, 96, 103, 106, 108, 109, 114, 115, 118, 120, 122, 123, 124, 126, 127, 130, 132, 133, 135, 210, 211, 212, 213, 216, 217, 218, 219, 220, 222, 226, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 269, 276, 293, 340, 361, 362, 405, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 433, 434, 435, 436, 438, 439, 440, 451, 497, 498, 502, 513, 514, 516, 518, 519, 520, 521, 522, 525, 526, 529, 530, 532, 535, 539, 540, 541, 542, 544, 546, 548, 551, 552, 555, 556, 559, 560, 565, 572], "protect": [73, 469, 470], "privaci": [73, 469], "grown": 74, "veri": [74, 94, 209, 213, 401, 406, 473, 502, 539, 542, 552, 556, 564, 567, 569], "rapidli": 74, "assur": 74, "enough": [74, 81, 83, 132, 211, 252, 258, 259, 330, 331, 368, 468, 502, 518, 526, 532, 537, 540, 541, 542, 543, 546, 565, 566, 567, 569], "tell": [74, 502, 541], "annot": [74, 75, 126, 128, 518, 545], "remov": [74, 75, 77, 81, 83, 96, 118, 120, 122, 123, 127, 220, 321, 322, 323, 326, 367, 369, 384, 398, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 444, 456, 457, 458, 475, 477, 478, 479, 482, 487, 491, 492, 518, 519, 539, 542, 543, 562, 569], "becam": 74, "light": [74, 120], "encourag": 74, "small": [74, 106, 216, 224, 226, 344, 406, 497, 502, 520, 537, 564, 567, 569, 571], "mostli": [74, 81, 85, 118, 521], "omz": 74, "script": [74, 75, 80, 90, 91, 92, 94, 95, 96, 98, 99, 103, 108, 110, 111, 113, 115, 116, 127, 129, 211, 476, 477, 478, 487, 488, 490, 491, 496, 497, 504, 505, 516, 518, 519, 520, 540, 558, 572], "workbench": 74, "stand": [74, 83, 208, 377, 378, 519, 524, 539, 545], "gui": [74, 540], "ovtf": 74, "explicit": [74, 115, 220, 224, 312, 313, 314, 315, 316, 317, 318, 367, 371, 372, 413, 414, 415, 416, 417, 418, 497, 502, 503, 505, 506, 508, 509, 510, 511, 512, 525, 533, 538, 566], "easi": [75, 81, 118, 213, 341, 368, 493, 497, 498, 517, 521, 557], "few": [75, 79, 493, 499, 518, 520, 546, 553, 555, 556], "don": [75, 479, 492, 518, 546, 563], "encount": [75, 471, 492, 516], "conflict": [75, 83, 121, 487], "venv": [75, 100, 487, 496, 499, 500, 522], "openvino_env": [75, 487, 502], "bin": [75, 100, 103, 113, 118, 127, 224, 319, 332, 335, 336, 337, 338, 478, 479, 480, 487, 496, 499, 500, 502, 505, 506, 507, 508, 509, 510, 515, 516, 525, 526, 527, 532, 539, 558], "re": [75, 106, 118, 122, 127, 132, 216, 446, 447, 476, 477, 478, 479, 486, 487, 490, 491, 502, 516, 543, 544, 550, 566], "termin": [75, 127, 330, 331, 477, 478, 480, 486, 487, 488, 496], "togeth": [75, 81, 83, 108, 127, 216, 408, 474, 479, 481, 502, 514, 516, 527, 529, 541, 549, 551], "isn": [75, 220, 347, 518], "messag": [75, 106, 113, 115, 118, 119, 124, 127, 474, 502, 509, 540, 551], "finish": [75, 122, 127, 210, 219, 382, 477, 478, 479, 519, 520, 544, 552, 557, 569], "successfulli": [75, 111, 127, 471, 479, 492, 502], "troubleshoot": [75, 84, 477, 478, 479, 495], "congratul": [75, 476, 477, 478, 479, 480, 482, 487, 488, 490, 491], "explor": [75, 81, 126, 135, 148, 163, 471, 479, 486], "scene": [75, 471, 477, 478, 479, 487, 546], "monodepth": [75, 471, 477, 478, 479, 487, 496], "insid": [75, 83, 114, 132, 135, 209, 218, 219, 220, 221, 222, 309, 337, 355, 360, 409, 477, 478, 479, 487, 496, 498, 500, 530, 542, 543, 544, 549, 550, 552, 553, 563, 569, 570], "web": [75, 126, 471, 477, 478, 479, 487, 529], "browser": [75, 477, 478, 479, 487, 493, 494, 495, 496, 572], "varieti": [75, 76], "home": [75, 127, 470, 476, 477, 478, 480, 481, 486, 487, 488, 490, 491, 502, 504], "iot": [75, 470, 477, 478, 479, 486, 487], "templat": [76, 106, 122, 129, 132, 133, 211, 213, 216, 218, 222, 223, 571], "opencv": [76, 127, 472, 502, 504, 555], "brows": [76, 477, 478], "200": [76, 77, 84, 310, 315, 320, 321, 325, 330, 335, 336, 337, 385, 386, 387, 393, 508, 529, 533, 543], "pick": [76, 496, 539], "handwrit": 76, "procedur": [76, 118, 119, 529], "adapt": [76, 111, 325, 326, 335, 336, 337, 411, 412, 452, 453, 471, 473, 498], "lightweight": [77, 210, 497, 524], "summar": [77, 108, 497, 524, 547], "input_model": [77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 116, 117, 532, 570], "plu": [77, 80, 123, 126], "checkpoint": [77, 80, 85, 95, 99, 100, 101, 103, 104, 108, 109, 110, 115, 530, 532], "unnam": 77, "output_dir": [77, 81, 83, 88, 97, 98, 103, 105, 110, 111, 127], "output_model": [77, 526], "model_nam": [77, 93, 102, 108, 111, 115, 127, 498, 530], "freez": [77, 80, 83, 85, 103, 105, 106, 110, 122], "example_input": [77, 113, 114, 525, 526, 528, 529], "compress_to_fp16": [77, 78, 79, 83, 523, 526, 532], "save": [77, 79, 80, 83, 85, 95, 96, 103, 109, 110, 112, 113, 114, 115, 116, 118, 121, 123, 124, 127, 219, 220, 498, 499, 500, 502, 508, 513, 523, 524, 525, 526, 528, 529, 530, 532, 534, 536, 541, 546, 563, 564, 569, 572], "transformations_config": [77, 83, 87, 89, 106, 107, 111, 122], "static_shap": [77, 84, 118], "freeze_placeholder_with_valu": [77, 83, 102], "use_legacy_frontend": [77, 83], "silent": [77, 220, 394, 398], "verbos": [77, 132, 526], "true": [77, 78, 81, 82, 83, 92, 98, 103, 106, 110, 115, 119, 122, 124, 127, 135, 148, 222, 223, 224, 274, 275, 295, 296, 297, 298, 302, 303, 304, 308, 309, 311, 316, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 333, 337, 340, 344, 347, 348, 349, 355, 368, 369, 382, 385, 388, 401, 408, 409, 413, 414, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 440, 441, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 468, 481, 496, 498, 500, 502, 507, 522, 524, 526, 529, 532, 539, 542, 543, 548, 552, 555, 572], "log_level": [77, 106, 540], "stream_output": 77, "share_weight": [77, 526, 530], "example_output": [77, 113], "input_model_is_text": [77, 83, 104, 115], "input_checkpoint": [77, 104, 108, 109, 115], "input_meta_graph": [77, 85, 98, 101, 105, 109, 115, 532], "saved_model_dir": [77, 78, 106, 111, 115], "saved_model_tag": 77, "tensorflow_custom_operations_config_upd": [77, 83, 122], "tensorflow_object_detection_api_pipeline_config": [77, 106], "tensorboard_logdir": [77, 106, 115], "tensorflow_custom_layer_librari": 77, "input_symbol": 77, "nd_prefix_nam": 77, "pretrained_model_nam": 77, "save_params_from_nd": 77, "legacy_mxnet_model": 77, "enable_ssd_gluoncv": [77, 83], "input_proto": 77, "caffe_parser_path": [77, 224], "k": [77, 118, 127, 313, 315, 316, 320, 321, 330, 331, 341, 367, 374, 375, 379, 380, 381, 388, 389, 390, 391, 396, 403, 404, 408, 409, 410, 411, 412, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 440, 446, 447, 448, 449, 451, 460, 461, 462], "disable_omitting_opt": 77, "enable_flattening_nested_param": 77, "remove_output_softmax": 77, "remove_memori": 77, "analog": [77, 80], "ov_model": [77, 78, 79, 80, 81, 82, 84, 85, 112, 113, 114, 115, 211, 216, 498, 505, 508, 509, 511, 512, 525, 526, 528, 529, 530, 532, 533, 543, 551], "partial_shap": [77, 536], "prep": 77, "input_nam": [77, 80, 90, 95, 132, 557], "set_layout": [77, 560], "heurist": [77, 567], "255": [77, 78, 82, 94, 96, 108, 111, 135, 163, 333, 346, 351, 420, 502], "reverse_channel": 77, "layoutmap": [77, 80], "lowlatency2": [77, 569], "use_const_initi": [77, 570], "fals": [77, 79, 96, 98, 99, 102, 103, 105, 106, 110, 115, 122, 123, 127, 135, 148, 222, 223, 274, 275, 295, 296, 297, 298, 302, 303, 304, 308, 309, 311, 316, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 333, 337, 340, 344, 347, 348, 349, 361, 362, 368, 369, 382, 385, 388, 398, 401, 408, 409, 413, 414, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 440, 441, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 468, 481, 502, 522, 523, 526, 530, 539, 541, 542, 562, 570, 572], "prune": [77, 109, 112, 113, 115, 116, 125, 517], "makest": [77, 569], "param_res_nam": [77, 570], "output_nam": [77, 90, 95, 132], "_offline_transform": 77, "apply_low_latency_transform": 77, "apply_pruning_transform": 77, "apply_make_stateful_transform": 77, "surgeri": 77, "name_op": 77, "conv1": [77, 224], "bn1": 77, "fc": 77, "resnet50": [77, 80, 85, 96, 113, 114, 115, 525, 528, 529, 530, 532], "pretrain": [77, 87, 89, 90, 92, 95, 97, 99, 101, 104, 106, 107], "float32": [77, 80, 83, 108, 110, 113, 115, 209, 341, 467, 502, 512, 528, 530, 558], "compile_model": [77, 85, 112, 499, 500, 513, 515, 525, 527, 528, 529, 530, 531, 532, 535, 536, 539, 540, 541, 542, 543, 544, 548, 549, 553, 556, 562, 565, 566], "def": [77, 83, 95, 96, 103, 106, 109, 115, 118, 119, 122, 123, 124, 349, 390, 440, 530, 572], "__init__": [77, 83, 96, 115, 123, 349, 530], "self": [77, 83, 96, 109, 111, 115, 122, 123, 127, 253, 256, 349, 524, 530], "linear1": 77, "activation1": 77, "linear2": 77, "activation2": 77, "y": [77, 81, 88, 93, 101, 113, 115, 120, 127, 130, 132, 249, 278, 282, 312, 313, 314, 315, 316, 317, 318, 319, 322, 324, 325, 330, 331, 345, 346, 349, 350, 351, 361, 362, 368, 369, 370, 374, 375, 390, 393, 395, 396, 403, 404, 406, 413, 414, 415, 416, 417, 434, 436, 439, 446, 447, 448, 449, 450, 454, 473, 477, 496, 528, 529, 530, 543, 544, 560], "cutmodel": 77, "_": [77, 341, 349, 432, 500], "cut_model": 77, "load_graph": 77, "model_path": [77, 103, 498], "graph_def": [77, 98, 99, 103, 105, 110, 115, 530], "rb": 77, "parsefromstr": 77, "as_default": [77, 103], "graph_util": [77, 98, 99, 103, 105, 110, 115, 122, 530], "import_graph_def": 77, "path_to_model": [77, 102, 111, 130, 502, 504, 505, 506, 508, 511, 512, 545], "hugectr": 77, "pb": [77, 78, 81, 82, 83, 84, 85, 97, 98, 99, 102, 103, 105, 106, 107, 108, 110, 111, 115, 118, 119, 124, 225, 525, 530, 532, 533], "matvec_3": 77, "fw": 77, "strip_unused_lib": 77, "strip_unus": 77, "as_graph_def": [77, 110, 115], "new_graph_def": 77, "as_datatype_enum": 77, "cmp_model": 77, "tensorflow_hub": [77, 115, 525, 530], "convert_to_const": [77, 115], "convert_variables_to_constants_v2": [77, 115], "tfhub": [77, 115, 525, 530], "svampeatla": 77, "embedd": [77, 500], "fungi_v2": 77, "model_func": 77, "frozen_func": [77, 115], "inceptionv4": [77, 122], "conv2d_2b_3x3": 77, "mixed_7c": 77, "input_path": 77, "yolov8x": 77, "concat_output_0": 77, "concat_3_output_0": 77, "cut_model_path": 77, "yolov8x_cut": 77, "extract_model": 77, "simpler": [78, 122, 148, 368, 572], "migrat": 78, "topologi": [78, 81, 106, 108, 114, 115, 122, 129, 216, 224, 502, 526, 530, 533], "mention": [78, 82, 118, 119, 123, 347, 348, 349, 371, 372, 498, 542, 543, 544, 546, 552, 556, 569], "overrid": [78, 81, 83, 84, 102, 118, 122, 131, 211, 213, 218, 223, 479, 496, 526, 533, 541, 542, 556], "cut": [78, 80, 84, 85, 97, 100, 103, 104, 105, 111, 117, 334, 532], "input_shap": [78, 80, 81, 87, 88, 89, 93, 101, 102, 104, 105, 106, 111, 113, 115, 118, 341, 348, 349, 370, 446, 447, 510], "unwant": 78, "unsupport": [78, 81, 100, 109, 115, 116, 118, 213, 220, 466, 467, 468, 497, 531, 545, 572], "mean_valu": [78, 80, 81, 82, 83, 87, 89, 91, 96, 108, 502], "scales_valu": 78, "insert": [78, 82, 95, 96, 98, 103, 106, 118, 220, 369, 380, 381, 398, 437, 445, 518, 560, 570], "protobuf": [78, 99, 108, 115, 118, 119, 124, 496, 527], "savedmodel": [78, 85, 532], "probabl": [78, 87, 89, 97, 98, 109, 330, 331, 333, 340, 430, 431, 432, 450, 492, 504, 505, 506, 509, 510], "pdmodel": [78, 82, 85, 113, 525, 528, 532], "recip": 78, "kept": [79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 208, 226, 320, 321, 398, 523, 544, 555, 569], "backward": [79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 226, 314, 318, 360, 368, 394, 419, 525, 572], "contemporari": [79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124], "By": [79, 83, 106, 220, 225, 274, 380, 381, 432, 481, 498, 502, 504, 505, 506, 508, 509, 526, 550, 553, 570, 572], "occupi": [79, 539, 543], "half": [79, 130, 290, 294, 346, 348, 349, 351, 542], "space": [79, 83, 85, 337, 346, 351, 367, 499, 525, 526, 532, 536, 539, 545, 546, 558, 570], "neglig": [79, 82], "save_model": [79, 500, 513, 523, 525, 526, 528, 529, 532], "sometim": [79, 81, 82, 114, 118, 222, 226, 331, 524, 526], "initi": [79, 96, 100, 103, 104, 114, 122, 132, 148, 213, 217, 218, 219, 326, 327, 328, 330, 331, 341, 357, 361, 362, 368, 371, 372, 388, 438, 452, 453, 454, 455, 459, 474, 477, 478, 492, 493, 497, 516, 519, 520, 526, 536, 539, 542, 545, 547, 569, 570, 571], "consum": [79, 80, 81, 83, 100, 106, 118, 120, 122, 129, 132, 148, 167, 220, 222, 226, 398, 402, 526, 536, 537, 540, 544, 551, 556, 562, 563, 565, 567], "overli": 79, "amount": [79, 127, 314, 318, 368, 370, 383, 384, 502, 526, 537, 542, 565, 566], "ram": [79, 496, 565], "phase": [79, 83, 106, 117, 120, 121, 123, 452, 453, 559, 560], "abil": [80, 98, 118, 213, 222, 536, 553], "leav": [80, 81, 225, 502, 524, 536], "construct": [80, 132, 213, 220, 222, 448, 501, 544, 545, 551, 571, 572], "scriptmodul": [80, 85, 96, 114, 529, 532], "scriptfunct": [80, 85, 114, 529, 532], "graphdef": [80, 85, 104, 115, 530, 532], "session": [80, 85, 98, 103, 105, 110, 115, 477, 478, 496, 524, 530, 532, 547], "np": [80, 114, 118, 124, 349, 390, 398, 499, 500, 525, 571], "inputcutinfo": 80, "ndarrai": [80, 114], "numer": [80, 109, 226, 244, 252, 255, 260, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 308, 311, 312, 313, 314, 315, 316, 317, 318, 339, 342, 343, 348, 349, 367, 372, 373, 382, 383, 384, 386, 388, 389, 390, 391, 392, 393, 403, 404, 406, 408, 421, 422, 425, 426, 427, 428, 429, 441, 443, 444, 445, 461, 462, 463, 464, 465, 542, 571], "source_layout": [80, 82], "dest_layout": 80, "scale_valu": [80, 82, 91, 96, 111, 502], "input1": [80, 115, 130, 367, 376, 460, 461, 462, 502, 530], "input2": [80, 115, 367, 376, 502, 530], "destin": [80, 120, 220, 400, 419, 466, 526, 560], "target_layout": [80, 82], "xml": [80, 81, 103, 113, 118, 127, 130, 135, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 325, 499, 500, 502, 504, 505, 506, 508, 509, 510, 511, 512, 515, 516, 525, 526, 527, 528, 529, 532, 539, 545, 558], "chapter": [81, 132, 220, 529], "cannot": [81, 84, 96, 100, 104, 108, 111, 117, 118, 123, 132, 148, 213, 221, 222, 360, 367, 371, 372, 394, 398, 408, 418, 441, 474, 497, 499, 500, 524, 525, 526, 529, 530, 535, 536, 537, 548, 558, 564, 565, 568, 570, 571, 572], "problem": [81, 83, 111, 113, 115, 117, 471, 496, 540], "identifi": [81, 83, 108, 118, 122, 123, 127, 131, 132, 213, 352, 353, 357, 358, 516, 539, 540, 548, 557, 568, 572], "problemat": [81, 570], "area": [81, 226, 312, 319, 332, 344, 347, 413, 414, 416, 418, 454, 526, 530, 537, 547, 560], "combin": [81, 83, 93, 109, 118, 129, 135, 138, 148, 216, 227, 355, 367, 389, 395, 410, 433, 434, 435, 436, 438, 439, 499, 500, 510, 525, 529, 536, 537, 543, 546, 554, 567, 568], "goe": [81, 83, 122, 148, 439, 572], "tri": [81, 83], "kind": [81, 119, 122, 124, 348, 453, 542], "classifi": [81, 500], "entri": [81, 122, 124, 129, 130, 226, 309, 355, 360, 388, 389, 390, 391, 544], "unrel": 81, "illustr": [81, 108, 129, 132, 226, 383, 384, 529, 534, 551, 570], "incept": [81, 106, 115, 117, 122], "research": [81, 98, 108], "slim": [81, 122], "neither": [81, 502, 535, 551], "nor": [81, 502, 534, 535, 551], "inception_v1": [81, 108, 115], "tensorboard": [81, 106, 110, 115, 122], "enclos": [81, 508, 529, 570], "nest": [81, 529], "inceptionv1": [81, 108], "logit": [81, 90, 98, 100, 108, 320, 321, 430, 431, 432], "reshape_1": [81, 108, 122], "predecessor": 81, "look": [81, 82, 96, 98, 105, 106, 108, 122, 127, 129, 131, 132, 135, 212, 213, 215, 217, 218, 219, 220, 401, 431, 498, 499, 502, 509, 516, 538, 539, 544, 546, 572], "output_model_dir": [81, 88, 105, 111], "286": [81, 440], "224": [81, 108, 113, 114, 115, 117, 312, 313, 314, 315, 316, 317, 318, 325, 352, 353, 356, 357, 358, 359, 403, 404, 405, 442, 443, 461, 502, 505, 509, 525, 528, 529, 536, 557, 558, 559], "frozen": [81, 83, 98, 99, 100, 103, 104, 105, 106, 226, 519, 520, 553], "omit": [81, 122, 224, 314, 318, 403, 404, 440, 533, 541, 552, 560], "match": [81, 101, 106, 107, 111, 122, 132, 135, 221, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 255, 257, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 312, 313, 314, 315, 316, 317, 318, 324, 347, 348, 349, 363, 365, 366, 367, 371, 372, 373, 375, 383, 384, 398, 399, 401, 402, 413, 414, 415, 416, 417, 419, 420, 432, 437, 440, 500, 502, 514, 526, 533, 535, 553], "389": 81, "1001": [81, 496], "num_ax": 81, "block": [81, 82, 122, 313, 370, 374, 395, 396, 470, 544, 550, 552, 553, 555, 568, 572], "conv2d_1a_7x7": 81, "blob": [81, 127, 130, 209, 332, 334, 408, 409, 496, 502, 542, 543, 545, 547, 563], "offset": [81, 111, 130, 224, 315, 316, 319, 320, 321, 324, 325, 327, 328, 329, 354, 360, 407, 463], "37632": 81, "pictur": [81, 135, 509, 515, 529, 545, 557, 570], "effect": [81, 122, 340, 375, 384, 388, 398, 461, 518, 529, 541, 542, 543, 555, 563], "come": [81, 106, 108, 118, 123, 132, 220, 222, 367, 371, 372, 437, 492, 499, 524, 536, 541, 542, 546, 550, 560], "auto_pad": [81, 123, 224, 312, 313, 314, 315, 316, 317, 318, 375, 413, 414, 415, 416, 417, 418], "same_upp": [81, 224, 312, 313, 314, 315, 316, 317, 318, 375, 413, 414, 415, 416, 417, 418], "placeholder_port_0": 81, "feed": [81, 82, 102, 105, 452, 453, 535, 539], "though": [81, 120, 461, 498, 542, 556, 557], "notat": [81, 130, 208, 340, 398, 468], "input_nod": [81, 83, 100], "everyth": [81, 82, 496], "outcom": [81, 468], "add_1": 81, "placeholder_out_port_0": [81, 103], "thu": [81, 83, 100, 118, 120, 123, 135, 208, 437, 451, 452, 453, 498, 502, 524, 542, 543, 552, 553, 556], "attempt": [81, 127, 533, 542, 544, 546, 565], "front": [81, 83, 87, 89, 106, 107, 111, 119, 120, 121, 123, 124], "reverse_input_channel": [82, 96, 101, 106, 111, 113, 502, 505, 506, 508, 509], "addition": [82, 106, 247, 314, 388, 403, 404, 461, 476, 477, 478, 479, 490, 491, 502, 514, 515, 553, 556, 569], "bgr": [82, 96, 101, 106, 111, 345, 350, 502, 505, 506, 508, 509, 557, 558, 559, 560], "rgb": [82, 96, 101, 106, 111, 346, 351, 502, 505, 506, 508, 509, 557, 558, 559, 560], "syntax": [82, 526, 570], "nasnet_larg": 82, "tf_nasnet_larg": 82, "input_1": [82, 107, 468, 502], "image_shap": 82, "yolov3": [82, 113, 528], "previous": [82, 111, 114, 132, 213, 492, 543, 546, 556, 566], "again": [82, 83, 496, 509, 539, 550], "usual": [82, 83, 93, 106, 114, 115, 116, 117, 118, 122, 124, 132, 135, 212, 213, 226, 312, 313, 315, 316, 317, 319, 369, 407, 502, 512, 516, 519, 521, 524, 527, 529, 530, 531, 532, 533, 534, 536, 541, 545, 546, 557, 560, 562, 566, 567, 568], "emb": [82, 96, 561], "opposit": [82, 118, 122, 133, 135, 216, 274, 394, 535], "shuffl": [82, 393], "alexnet": [82, 501, 505, 506, 509, 539], "divid": [82, 111, 122, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 319, 329, 332, 335, 336, 337, 338, 340, 360, 374, 393, 395, 396, 397, 401, 406, 407, 408, 409, 410, 413, 414, 415, 537, 545, 557, 559, 560, 567, 569], "reverseinputchannel": 82, "particip": [83, 222, 544], "grammar": 83, "parser": [83, 103, 118], "src": [83, 92, 103, 129, 133, 211, 213, 216, 496, 516], "exactli": [83, 95, 122, 208, 314, 319, 554, 562, 570], "customreshap": 83, "artifici": 83, "mo_caff": 83, "highli": [83, 106, 118, 226, 492, 542, 546, 554, 556], "layerparamet": 83, "customreshapeparamet": 83, "custom_reshape_param": 83, "546": 83, "blobshap": 83, "cd": [83, 91, 95, 98, 99, 100, 104, 109, 110, 111, 127, 129, 211, 367, 477, 478, 479, 496, 500, 504, 516, 540, 549], "site_packages_with_installed_openvino": 83, "generate_caffe_pb2": 83, "py": [83, 90, 91, 95, 96, 98, 99, 100, 101, 103, 108, 109, 111, 115, 118, 120, 122, 123, 124, 127, 476, 496, 502, 503, 504, 505, 507, 508, 509, 510, 511, 512, 516, 530, 572], "path_to_custom_caff": 83, "root": [83, 90, 94, 98, 111, 121, 127, 211, 220, 221, 222, 290, 327, 328, 422, 477, 496, 504, 562, 572], "path_to_prototxt": 83, "my_net": 83, "know": [83, 118, 514, 529, 557], "lessen": [83, 562], "absent": [83, 109, 135, 139, 367], "Then": [83, 108, 111, 115, 118, 122, 129, 132, 163, 216, 222, 311, 327, 328, 329, 341, 346, 351, 368, 413, 415, 446, 447, 449, 471, 473, 496, 497, 503, 506, 509, 510, 511, 512, 516, 517, 518, 529, 530, 537, 542, 543], "my_caff": 83, "netparamet": 83, "v1layerparamet": 83, "lenet": [83, 501, 509, 510], "inputparamet": 83, "num": [83, 111, 122, 333, 339, 397], "total": [83, 109, 312, 319, 320, 321, 322, 323, 326, 337, 387, 452, 453, 454, 455, 456, 457, 458, 459, 502, 545, 563, 567], "227": [83, 506], "600": [83, 106], "1000": [83, 113, 322, 323, 325, 326, 331, 335, 336, 337, 354, 369, 380, 381, 388, 389, 390, 391, 392, 450, 456, 457, 505, 506, 509, 522, 528, 539, 541, 546], "im_info": [83, 119, 326], "input_param": 83, "500": [83, 390], "nois": [83, 524], "offload": [83, 96, 472, 539, 547], "pycaff": 83, "pythonpath": [83, 99], "At": [83, 96, 100, 104, 111, 118, 127, 208, 320, 321, 360, 373, 398, 440, 496, 505, 506, 508, 509, 510, 522, 537, 562], "flag": [83, 103, 110, 124, 127, 130, 211, 320, 321, 322, 326, 327, 328, 329, 330, 331, 333, 347, 348, 349, 361, 362, 408, 409, 430, 431, 432, 433, 434, 451, 452, 453, 454, 455, 456, 457, 458, 459, 502, 509, 526, 542, 552], "That": [83, 100, 115, 132, 221, 222, 226, 360, 530, 542], "mandatori": [83, 106, 119, 122, 123, 135, 136, 320, 321, 331, 355, 367, 499, 526, 539, 551], "56": [83, 249, 251, 252, 253, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 337, 341, 363, 364, 365, 366, 373, 375, 419, 420, 466, 467, 468, 502], "simultan": [83, 502, 515, 539, 541, 542, 543, 549, 550, 555, 556, 562, 564, 566, 567], "ambigu": [83, 529], "satisfi": [83, 106, 117, 132, 216, 340, 367, 368, 446, 447, 448], "node_nam": [83, 106], "truncat": [83, 130, 282, 341, 538, 543], "resolv": [83, 84, 100, 104, 113, 115, 492, 533], "none": [83, 96, 103, 115, 118, 120, 123, 127, 130, 242, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 309, 311, 314, 322, 323, 325, 333, 355, 360, 363, 365, 366, 388, 390, 398, 420, 433, 434, 435, 436, 438, 439, 440, 451, 452, 453, 460, 461, 462, 502, 510, 522, 525, 530, 541, 556], "subgraphmatch": [83, 122], "single_input_nod": [83, 122], "suppli": [83, 454, 455, 456, 457, 458, 459, 544], "node_by_pattern": 83, "_add_output_nod": 83, "did": [83, 556], "shortcut": [83, 477], "unspecifi": [83, 394], "prerequisit": [83, 504], "interpret": [83, 87, 89, 106, 209, 312, 314, 341, 348, 369, 385, 393, 406, 441, 446, 447, 448, 449, 499, 544, 553], "layer_nam": 83, "uint8": [83, 295, 296, 297, 298, 345, 346, 350, 351, 512], "float16": [83, 209, 341, 542], "doubl": [83, 340, 341, 408, 468, 496, 541, 542, 570], "int64": [83, 124, 274, 308, 310, 322, 339, 341, 349, 355, 379, 387, 390, 391, 401, 408, 409, 411, 412, 414, 416, 417, 431, 432, 437, 443, 446, 447, 448, 449, 451, 452, 453, 455, 457, 458, 461, 462, 463, 464, 465, 500], "uint16": 83, "uint32": [83, 341, 466], "uint64": [83, 341], "str": [83, 96, 103, 123, 349, 535, 571], "incorrectli": [83, 113, 115, 492], "suffici": [83, 129, 212, 546], "desir": [83, 129, 216, 329, 477, 478, 479, 502, 524, 526, 530], "bracket": [83, 541, 559], "whose": [83, 320, 321, 322, 358, 551, 569], "overwritten": [83, 213, 388, 390, 540], "green": [83, 120, 345, 346, 350, 351, 557], "blue": [83, 345, 346, 350, 351, 557], "didn": 83, "match_kind": [83, 111, 122], "start_point": [83, 122], "end_point": [83, 122], "schema": [83, 126, 226, 529], "strictli": [83, 115, 132], "lead": [83, 118, 339, 377, 378, 380, 381, 393, 497, 498, 521, 523, 524, 526, 529, 530, 533, 543, 545, 562, 564, 567, 569], "close": [83, 96, 103, 106, 127, 326, 452, 453, 542, 568], "unambigu": 83, "loss": [83, 135, 432, 466, 467, 468, 518, 524, 548, 568, 569], "_arg": 83, "_aux": 83, "python_param": [83, 119], "rpn": [83, 119], "proposal_lay": [83, 119], "proposallay": [83, 119], "param_str": [83, 119], "feat_strid": [83, 119, 330, 331], "ancestor": 83, "proposalpythonexampleop": 83, "nx": 83, "multidigraph": [83, 118, 120], "attr": [83, 119, 120, 123, 124, 349], "excluded_class": 83, "prevent": [83, 106, 117, 135, 541], "potenti": [83, 113, 115, 125, 432, 472, 523, 524, 536, 538, 546, 551, 552, 563, 566, 567, 569], "input_memori": 83, "checksum": 83, "16896": 83, "rebuild": [83, 551], "straightforward": [83, 220, 221, 541, 542], "flavor": [83, 132, 224, 544], "deeplab": 83, "classic": [83, 367], "interp_inf": 83, "accord": [83, 103, 118, 122, 123, 126, 132, 136, 148, 226, 227, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 296, 297, 298, 299, 300, 301, 305, 306, 307, 311, 314, 322, 325, 330, 331, 335, 336, 337, 338, 342, 343, 344, 348, 349, 355, 363, 365, 366, 370, 376, 377, 378, 388, 390, 394, 395, 398, 400, 406, 409, 433, 434, 440, 441, 446, 447, 448, 449, 451, 454, 466, 468, 501, 509, 515, 527, 545, 564, 565], "comment": [83, 123, 557, 572], "val1": 83, "val2": 83, "val3": 83, "gluoncv": 83, "possibli": [83, 468], "utf": [83, 571], "codec": [83, 103], "byte": [83, 130, 224, 354, 553, 568, 571], "0xe0": 83, "spatialtransformerparamet": 83, "transform_typ": 83, "fall": [83, 344, 541, 572], "back": [83, 117, 120, 121, 123, 127, 135, 208, 209, 225, 252, 259, 274, 296, 355, 360, 368, 379, 393, 398, 408, 409, 461, 499, 541, 544, 545, 555, 556, 572], "use_new_frontend": 83, "benefici": [84, 533, 536, 541, 542, 552], "consumpt": [84, 498, 533, 542, 544, 567], "300": [84, 106, 119, 127, 319, 522, 529, 533], "conjunct": 84, "pair": [84, 132, 210, 323, 326, 333, 341, 344, 353, 358, 367, 369, 455, 456, 457, 458, 459, 468, 500, 516, 525, 533, 544, 569, 570], "seq_len": [84, 95, 100, 434, 436, 439, 533], "vice": [84, 208, 371, 372, 533, 535, 560], "versa": [84, 208, 371, 372, 533, 535, 560], "boundari": [84, 109, 308, 316, 533], "ellipsi": [84, 367, 398, 533, 559], "practic": [84, 122, 124, 126, 127, 208, 398, 470, 498, 529, 533, 537, 539, 546, 552, 571], "relax": [84, 117, 353, 358, 541, 564], "extent": [85, 224, 556], "drive": [85, 127, 502, 525, 557, 562, 572], "read_model": [85, 112, 129, 470, 500, 502, 505, 506, 508, 509, 511, 512, 513, 515, 527, 528, 530, 531, 532, 536, 553, 558, 563], "choos": [85, 111, 114, 117, 127, 409, 415, 416, 417, 469, 478, 479, 480, 495, 499, 532, 537, 539, 540, 546, 569, 570], "saved_model_directori": [85, 115, 532], "inference_graph": [85, 98, 105, 115, 530, 532], "pbtxt": [85, 104, 115, 530, 532], "metagraph": [85, 100, 115, 530, 532], "saved_model": [85, 115, 530, 532], "ov_compiled_model_t": [85, 532], "null": [85, 532], "ov_core_compile_model_from_fil": [85, 532], "tflite": [85, 116, 525, 531, 532], "paddl": [85, 113, 132, 515, 528, 532], "hapi": [85, 113, 528, 532], "fluid": [85, 113, 528, 532], "dygraph": [85, 113, 528, 532], "executor": [85, 113, 133, 210, 212, 213, 528, 532], "offici": [85, 109, 111, 115, 118, 126, 492, 518, 530, 572], "written": [86, 119, 129, 132, 133, 208, 216, 329, 492, 499, 515, 520, 534, 541], "maskrcnn": [87, 89], "sha": [87, 89, 90, 92, 94], "8883e49e68de7b43e263d56b9ed156dfa1e03117": [87, 89], "fasterrcnn": 87, "800": [87, 89, 324, 325], "9801": [87, 89], "9465": [87, 89], "7717": [87, 89], "faster_rcnn": 87, "coordin": [87, 89, 101, 314, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 344, 348, 349, 374, 375, 394, 396, 451, 452, 453, 454, 455, 456, 457, 458, 459, 508, 550], "press": [88, 473, 496], "gpt2": 88, "z": [88, 313, 314, 317, 318, 349, 361, 362, 367, 369, 375, 413, 414, 415, 416, 417, 433, 434, 446, 447, 529], "mask_rcnn_r_50_fpn_1x": 89, "mask_rcnn": 89, "6849": 89, "sink_port_0": [89, 309], "goal": [90, 91, 124, 132, 135, 209, 210, 226, 368, 553, 554], "out_bas": 90, "e5be564156f194f1becb0d82aeaf6e762d9eb9": 90, "input_id": [90, 98, 110, 499, 500], "input_mask": [90, 98, 110], "segment_id": [90, 98, 465], "valid_posit": 90, "steve": 90, "went": [90, 113, 115], "pari": 90, "dtype": [90, 108, 115, 124, 349, 499, 500, 530, 553, 571], "valid_id": 90, "ner_model": 90, "tknizr": 90, "model_config": 90, "load_model": [90, 103, 115, 530], "no_grad": 90, "dynamic_ax": [90, 95], "batch_siz": [90, 95, 102, 103, 105, 127, 330, 331, 340, 349, 361, 362, 382, 433, 434, 435, 436, 438, 439, 502, 541], "opset_vers": [90, 92, 95, 96, 529], "sequence_length": [90, 103, 362, 431, 434, 436, 439, 570], "mmlab": 91, "mmdetect": 91, "pytorch2onnx": 91, "cascade_rcnn": 91, "cascade_rcnn_r101_fpn_1x_coco": 91, "cascade_rcnn_r101_fpn_1x_coco_20200317": 91, "0b6a2fbf": 91, "pth": [91, 96], "dir": [91, 115, 127, 133, 224, 481, 488, 540, 563], "675": [91, 505, 506, 509], "116": [91, 96, 111], "395": 91, "375": 91, "fusion": [92, 220], "feedback": 92, "focu": [92, 403, 404, 498, 540, 568], "salient": 92, "weijun88": 92, "cfg": [92, 96, 111], "snapshot": 92, "path_to_checkpoint_dir": 92, "352": 92, "export_param": 92, "do_constant_fold": 92, "eecace3adf1e8946b571a4f4397681252f9dc1b8": 92, "model_dir": [92, 93, 105, 135], "nemo": 93, "asr": 93, "nemo_asr": 93, "encdecctcmodel": 93, "from_pretrain": [93, 498, 500, 524, 525], "quartznet15x5bas": 93, "en": [93, 103, 486, 547], "decoder_qn": 93, "encoder_qn": 93, "qn": 93, "qt": 93, "encoder_qt": 93, "decoder_qt": 93, "audio": [93, 100, 226, 493, 497, 566], "mel": [93, 100], "spectrogram": [93, 100], "residu": 94, "argpars": 94, "rcan_testcod": 94, "n_feat": 94, "n_resblock": 94, "n_resgroup": 94, "data_train": 94, "div2k": 94, "res_scal": 94, "n_color": 94, "rgb_rang": 94, "eval": [94, 96, 114, 529], "dummy_input": [94, 114], "360": [94, 332], "640": [94, 345, 346, 350, 351, 398, 557, 560], "3339ebc59519c3bb2b5719b87dd36515ec7f3ba7": 94, "mlcommon": 95, "revis": 95, "r1": [95, 109], "shallow": [95, 553], "skip": [95, 105, 111, 112, 113, 115, 116, 135, 398, 416, 417, 451, 452, 453, 477, 478, 479, 496, 500, 502, 516, 520, 525, 542, 563], "rnnt_for_openvino": 95, "checkout": [95, 96, 98, 99, 103, 111], "head": [95, 109, 286, 496, 508], "speech_recognit": 95, "rnnt": 95, "place": [95, 111, 122, 361, 362, 387, 433, 434, 497, 498, 506, 509, 539, 545], "mkdir": [95, 100, 104, 108, 110, 127, 129, 211, 477, 478, 479, 496, 504, 516], "unix": [95, 98, 100, 515], "wget": [95, 98, 100, 101, 104, 108, 110, 476], "zenodo": 95, "record": [95, 123], "3662521": 95, "distributeddataparallel_1576581068": 95, "9962234": 95, "pt": [95, 498, 525], "taken": [95, 104, 122, 130, 330, 331, 375, 379, 384, 407, 468, 515, 522, 539, 543, 545, 546], "sh": [95, 103, 127, 476, 477, 478, 490, 491, 492, 496, 500, 504, 540, 549], "speech_recoginitin": 95, "subfold": [95, 115, 525, 530], "pip3": [95, 100, 111, 127], "toml": 95, "export_rnnt_to_onnx": 95, "mlcommons_inference_path": 95, "sy": [95, 98, 572], "load_and_migrate_checkpoint": 95, "ckpt_path": [95, 103], "map_loc": [95, 96], "migrated_state_dict": 95, "state_dict": [95, 96], "joint_net": 95, "del": [95, 119, 122, 479], "audio_preprocessor": 95, "fb": 95, "inferen": 95, "checkpoint_path": 95, "config_toml": 95, "rnnt_vocab": 95, "model_separable_rnnt": 95, "feature_config": 95, "input_ev": 95, "load_state_dict": 95, "seq_length": [95, 103, 362, 386, 434, 436, 439], "feature_length": 95, "240": [95, 345, 346, 350, 351], "inp": 95, "longtensor": 95, "x_pad": 95, "x_len": 95, "rnnt_encod": 95, "symbol": [95, 103, 213, 375, 430, 477, 478, 479, 502, 571], "hidden": [95, 100, 104, 221, 361, 362, 433, 434, 435, 436, 438, 439, 569, 570], "320": [95, 111, 313, 329, 345, 346, 350, 351, 381, 446, 447, 448, 449, 502, 508], "rnnt_predict": 95, "hidden_in_1": 95, "hidden_in_2": 95, "hidden_out_1": 95, "hidden_out_2": 95, "rnnt_joint": 95, "hardcod": [95, 98, 106, 122, 570], "coeffici": [96, 406], "deform": [96, 315, 316, 319], "argument": [96, 103, 111, 114, 129, 130, 132, 135, 148, 210, 213, 218, 369, 375, 398, 502, 503, 505, 506, 508, 509, 511, 512, 523, 526, 529, 530, 536, 542, 543, 544, 547, 548, 550, 551, 553, 565, 570, 572], "dump": [96, 103, 115, 502, 545], "writabl": [96, 103], "yolact_onnx_export": 96, "diff": [96, 103], "76deb67d4f09f29feda1a633358caa18335d9e9f": 96, "mon": 96, "sep": 96, "2001": 96, "fri": 96, "mar": 96, "2021": [96, 106, 127, 227, 496, 540], "0300": 96, "547bc0a": 96, "bde0680": 96, "100644": [96, 103], "593": 96, "9": [96, 103, 106, 111, 243, 248, 261, 274, 286, 290, 311, 315, 316, 326, 330, 333, 336, 339, 340, 344, 360, 367, 375, 377, 378, 379, 380, 381, 383, 384, 387, 390, 391, 392, 394, 401, 403, 404, 408, 409, 415, 417, 418, 432, 436, 448, 449, 452, 453, 459, 463, 464, 465, 476, 477, 480, 490, 496, 502, 509, 510, 511, 524, 529], "badhash": 96, "evalimag": 96, "save_path": [96, 99, 110, 115, 530], "from_numpi": 96, "cv2": 96, "imread": 96, "cuda": 96, "is_avail": 96, "fastbasetransform": 96, "pred": 96, "img_numpi": 96, "prep_displai": 96, "undo_transform": 96, "cc7a73a": 96, "2420603": 96, "623": [96, 103], "backbon": 96, "img": [96, 127, 529], "d83703b": 96, "f8c787c": 96, "cudnn": [96, 213], "timer": 96, "movingaverag": 96, "make_net": 96, "17108": 96, "current_devic": 96, "dataparallel": [96, 519, 520], "use_jit": 96, "device_count": 96, "turn": [96, 131, 515, 525, 535, 542, 546, 569], "scriptmodulewrapp": 96, "els": [96, 118, 122, 311, 314, 327, 328, 336, 339, 348, 349, 381, 420, 437, 440, 446, 447, 451, 452, 453, 454, 455, 459, 502, 516], "script_method_wrapp": 96, "script_method": 96, "fn": 96, "_rcn": 96, "loc": 96, "prior": [96, 106, 321, 324, 327, 328, 329, 333, 395, 525], "boxes_result1": 96, "boxes_result2": 96, "boxes_result": 96, "extra_param": 96, "476": 96, "479": 96, "load_weight": 96, "673": 96, "679": 96, "pred_out": 96, "conf": 96, "pop": 96, "unus": [96, 398, 516, 537, 543], "dbolya": 96, "57b8f2d95e62e2e649b382f516ab41f949b57239": 96, "attach": [96, 122, 127, 130, 525], "yolact_base_54_800000": 96, "trained_model": 96, "score_threshold": [96, 322, 451, 452, 453, 454, 455, 456, 457, 458, 459], "jpg": [96, 99, 106, 502, 505, 506, 508, 509, 545], "fail": [96, 106, 123, 132, 468, 539, 540, 565, 572], "gain": [96, 524, 546, 569], "fpn": [96, 106], "resnet101": 96, "78": [96, 375, 502], "darknet53": 96, "emedvedev": 97, "egg": 97, "frozengraph": 97, "sent": [97, 210], "frozen_graph": [97, 99], "tensorarraystack": 97, "86": [97, 329, 375], "transpose_1": 97, "transpose_2": 97, "chines": [98, 113, 528], "unzip": [98, 110], "uncased_l": 98, "12_h": [98, 110], "768_a": [98, 110], "bert_config": 98, "bert_model": 98, "ckpt": [98, 99, 103, 104, 108, 109, 110, 115, 530], "00000": [98, 115, 530], "00001": [98, 115, 530], "pooler": 98, "placeholder_1": 98, "placeholder_2": 98, "eedf5716c": 98, "glue": [98, 497], "gist": 98, "githubusercont": [98, 127, 496], "w4ngatang": 98, "60c2bdb54d156a41194446737ce03e2": 98, "17b8dd0d724281ed7c3b2aeeda662b92809aadd5": 98, "download_glue_data": 98, "mrpc": 98, "editor": [98, 122, 477, 478], "923": 98, "924": 98, "non_static_index": 98, "run_classifi": 98, "645": 98, "graph_io": [98, 99, 103, 105, 110, 115, 530], "get_default_graph": 98, "sess": [98, 99, 103, 105, 110, 115, 530], "assignment_map": 98, "initialized_variable_nam": 98, "get_assignment_map_from_checkpoint": 98, "trainable_vari": 98, "init_checkpoint": [98, 110], "init_from_checkpoint": [98, 110], "global_variables_initi": [98, 110, 115, 530], "convert_variables_to_const": [98, 99, 103, 105, 110, 115, 530], "write_graph": [98, 99, 103, 105, 110, 115], "as_text": [98, 99, 103, 105, 110, 115], "dirnam": 98, "__file__": 98, "total_loss": 98, "per_example_loss": 98, "create_model": 98, "is_train": [98, 110], "label_id": 98, "num_label": 98, "use_one_hot_embed": 98, "bert_base_dir": 98, "bert_repo_dir": 98, "task_nam": 98, "do_ev": 98, "data_dir": 98, "glue_data": 98, "vocab_fil": 98, "bert_config_fil": 98, "abl": [98, 106, 115, 127, 209, 401, 468, 474, 502, 518, 530, 539, 554, 557, 567], "maybeshewil": 99, "crnn_tensorflow": 99, "64f1f1867bffaacfeacc7a80eebf5834a5726122": 99, "demo_shadownet": 99, "saver": [99, 103, 105, 110], "restor": [99, 105, 115, 213, 333, 530], "weights_path": [99, 103], "shadow": 99, "lstmlayer": 99, "transpose_time_major": 99, "image_path": 99, "test_imag": 99, "test_01": 99, "shadownet": 99, "shadownet_2017": 99, "47": [99, 375, 502], "199999": 99, "mozilla": 100, "v0": [100, 496, 551], "tar": [100, 101, 108, 127, 477, 478, 479], "gz": [100, 101, 108, 127], "xvfz": [100, 127], "virtualenv": [100, 496], "checkpoint_dir": 100, "export_dir": 100, "output_graph": 100, "audiospectrogram": 100, "mfcc": 100, "computation": 100, "expens": [100, 529, 552], "previous_state_c": 100, "previous_state_h": 100, "figur": [100, 108, 118, 127, 208, 209, 518], "assum": [100, 103, 104, 112, 120, 132, 316, 340, 398, 430, 435, 440, 446, 447, 448, 449, 461, 513, 515, 519, 520, 529, 536, 537, 538, 539, 542, 545, 564], "time_len": 100, "input_length": 100, "cudnn_lstm": 100, "multi_rnn_cel": 100, "cell_0": 100, "cudnn_compatible_lstm_cel": 100, "gathernd_1": 100, "96e1fe": 101, "d4": 101, "referenc": [101, 387], "googleapi": [101, 110], "tpu": 101, "coco2": 101, "zxvf": 101, "image_s": [101, 325, 327, 328, 329, 506], "efficientdet_model_param_dict": 101, "hparams_config": 101, "incorrect": [101, 106, 111, 122, 380], "image_id": 101, "y_min": 101, "x_min": 101, "y_max": 101, "x_max": 101, "confid": [101, 320, 321, 330, 331, 451, 504, 508], "class_id": [101, 320, 321, 451, 452, 453, 505, 508, 509, 529], "left": [101, 132, 163, 244, 245, 247, 248, 252, 256, 262, 308, 312, 313, 315, 316, 317, 319, 327, 328, 329, 330, 331, 344, 367, 369, 370, 398, 399, 413, 414, 415, 416, 417, 441, 446, 447, 448, 449, 496], "corner": [101, 319, 320, 321, 327, 328, 329, 330, 331, 347, 454, 455, 456, 457, 458, 459], "upper": [101, 244, 339, 341, 368, 416, 417, 451, 454, 455, 459, 536, 543, 567], "redund": [102, 106, 122, 123, 518, 519], "phase_train": 102, "nmt": 103, "gnmt_infer": 103, "2cbef07": 103, "e185490": 103, "__future__": 103, "print_funct": 103, "attention_model": 103, "gnmt_model": 103, "start_sess_and_load_model": 103, "infer_model": 103, "loaded_infer_model": 103, "inference_dump_graph": 103, "path_to_dump": 103, "hparam": 103, "model_cr": 103, "get_model_cr": 103, "model_help": 103, "create_infer_model": 103, "get_config_proto": 103, "print_out": 103, "inference_gnmt_graph": 103, "output_node_nam": 103, "index_to_string_lookup": 103, "frozen_gnmt_inference_graph": 103, "inference_input_fil": 103, "inference_output_fil": 103, "f5823d8": 103, "a733748": 103, "310": 103, "add_argu": 103, "num_intra_thread": 103, "intra_op_parallelism_thread": 103, "dump_inference_model": 103, "narg": 103, "create_hparam": 103, "396": 103, "403": 103, "language_model": 103, "num_inter_thread": 103, "613": 103, "create_or_load_hparam": 103, "run_main": 103, "default_hparam": 103, "train_fn": 103, "inference_fn": 103, "target_sess": 103, "inference_dump": 103, "job": [103, 539, 543, 544, 553, 555], "jobid": 103, "653": 103, "663": 103, "out_dir": 103, "hparams_path": 103, "save_hparam": 103, "inference_indic": 103, "inference_list": 103, "latest_checkpoint": [103, 105], "gfile": 103, "makedir": 103, "elif": [103, 122, 349, 382, 390, 420, 440], "trans_fil": 103, "693": 103, "721": 103, "unused_argv": 103, "__name__": 103, "__main__": 103, "b278487980832417ad8ac701c672b5c3dc7fa553": 103, "wmt16_gnmt_4_layer": 103, "wmt16_gnmt_8_layer": 103, "outdat": 103, "incompat": 103, "german": 103, "henc": [103, 340, 446, 447, 449, 537, 541, 553, 555, 566], "greedi": [103, 430, 431, 500, 545], "de": [103, 110, 499], "tgt": 103, "standard_hparam": 103, "vocab_prefix": 103, "bpe": [103, 500], "32000": 103, "infer_mod": 103, "beam_search": 103, "appear": [103, 123, 129, 367, 398, 529, 536, 546, 548, 560], "wmt16_en_d": 103, "mismatch": [103, 106, 242], "vocabulari": 103, "extend_hparam": 103, "508": 103, "src_vocab_s": 103, "tgt_vocab_s": 103, "dynamic_seq2seq": 103, "hash_table_lookup_1": 103, "hash_table_lookup": [103, 109], "lookuptablefindv2": [103, 109], "max_sequence_length": 103, "eo": [103, 500], "placeholder_out_port_1": 103, "beam_siz": 103, "input_data_tensor": 103, "inference_engin": 103, "ienetwork": 103, "iecor": 103, "input_data": [103, 349, 525], "ie": [103, 124, 126, 340, 545], "extension_path": 103, "libcpu_extens": 103, "device_nam": [103, 505, 506, 508, 510, 511, 512, 539, 543, 548, 563], "exec_net": 103, "load_network": 103, "result_i": 103, "lm_1b": 104, "lm_lstm_cnn": 104, "2016": [104, 432, 496], "all_shard": 104, "char": [104, 130, 516], "softmax0": 104, "softmax1": 104, "softmax2": 104, "softmax3": 104, "softmax4": 104, "softmax5": 104, "softmax6": 104, "softmax7": 104, "softmax8": 104, "hierarchi": 104, "variable_1": 104, "reassign": 104, "rememb": [104, 220], "9216": 104, "softmax_out": 104, "lstm_0": 104, "concat_2": 104, "lstm_1": 104, "char_embed": 104, "embeddinglookupuniqu": 104, "ncf": 105, "import_meta_graph": 105, "rate": [105, 375, 497, 519, 520, 542, 549, 550, 555, 568], "zoom": 105, "embedding_lookup": 105, "embedding_1": 105, "embedding_2": 105, "embedding_3": 105, "image_info": [106, 502], "fed": 106, "moreov": [106, 222, 475, 565], "closer": [106, 132, 539], "trigger": [106, 118, 119, 122, 124, 355, 360, 398, 529, 539, 541], "operation_to_add": 106, "spatial": [106, 117, 312, 313, 314, 315, 316, 317, 318, 319, 324, 327, 328, 329, 332, 335, 336, 337, 347, 348, 349, 370, 374, 375, 395, 396, 408, 410, 411, 412, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 535, 536, 560], "path_to_frozen": 106, "OR": [106, 111, 297, 365, 388, 390], "path_to_saved_model": 106, "path_to_subgraph_replacement_configuration_fil": 106, "python_site_packag": [106, 108], "ssd_v2_support": 106, "inclus": [106, 274, 341, 348, 349, 394, 398, 446, 447, 448, 449], "ssd_support_api_v": 106, "efficient_det_support_api_v": 106, "faster_rcnn_support": 106, "faster_rcnn_support_api_v1": 106, "faster_rcnn_support_api_v2": 106, "mask_rcnn_support": 106, "mask_rcnn_support_api_v1": 106, "mask_rcnn_support_api_v2": 106, "rfcn_support": 106, "rfcn": 106, "rfcn_support_api_v1": 106, "path_to_pipelin": 106, "hyper": 106, "inceptionv2": 106, "tmp": [106, 115, 490, 496], "ssd_inception_v2_coco_2018_01_28": 106, "frozen_inference_graph": 106, "stretch": 106, "image_res": 106, "pad_to_max_dimens": 106, "bmp": [106, 130, 502, 504, 505, 508, 509, 560], "preprocessor": [106, 557], "fixed_shape_res": 106, "snippet": [106, 115, 132, 213, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 355, 390, 500, 522, 523, 524, 539, 543, 544, 556], "keep_aspect_ratio_res": 106, "constraint": [106, 220, 446, 447, 448], "min_dimens": 106, "max_dimens": 106, "w": [106, 117, 319, 324, 325, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 345, 346, 348, 349, 350, 351, 361, 362, 371, 372, 393, 406, 408, 411, 412, 413, 414, 415, 416, 417, 418, 433, 434, 435, 436, 438, 439, 502, 559, 560], "hard": [106, 117, 226, 249, 250, 251, 551, 572], "calculate_shape_keeping_aspect_ratio": 106, "ratio_min": 106, "ratio_max": 106, "recogn": [106, 129, 225, 569], "contrast": [106, 118, 224, 408, 555, 556, 558, 569, 571], "who": [106, 127, 544], "event": [106, 555], "1333": 107, "retinanet_resnet50_coco_best_v2": 107, "endpoint": 107, "os": [108, 481, 482, 486, 487, 488], "tf_model": [108, 525], "inception_v1_2016_08_28": 108, "xzvf": 108, "export_inference_graph": 108, "output_fil": 108, "inception_v1_inference_graph": 108, "summarize_graph": 108, "preprocessing_factori": 108, "preprocessing_fn_map": 108, "inception_preprocess": 108, "preprocess_for_ev": 108, "convert_image_dtyp": 108, "firstli": [108, 135, 213], "dimension": [108, 118, 344, 368, 369, 380, 381, 398, 403, 404, 440, 442, 443, 559], "arrai": [108, 118, 124, 130, 132, 219, 242, 245, 256, 340, 349, 372, 375, 398, 411, 412, 460, 462, 471, 500, 502, 553, 560, 571], "similarli": [108, 118, 122, 124, 132, 344, 530, 539, 562, 567, 571], "memor": 109, "spars": [109, 209, 463, 464, 465], "sequenti": [109, 118, 398, 520, 525, 552], "feature_column": 109, "hash": [109, 547], "r2": 109, "wide_deep": 109, "build_model_column": 109, "census_dataset": 109, "ag": [109, 127], "numeric_column": 109, "education_num": 109, "capital_gain": 109, "capital_loss": 109, "hours_per_week": 109, "educ": [109, 496], "categorical_column_with_vocabulary_list": 109, "bachelor": 109, "grad": 109, "9th": 109, "colleg": 109, "assoc": 109, "acdm": 109, "7th": 109, "8th": 109, "doctor": 109, "prof": 109, "school": 109, "preschool": 109, "marital_statu": 109, "marri": 109, "civ": 109, "spous": 109, "divorc": 109, "af": 109, "widow": 109, "relationship": [109, 318], "husband": 109, "wife": 109, "child": [109, 122, 413, 414, 415, 416, 417, 551], "unmarri": 109, "workclass": 109, "emp": 109, "privat": [109, 132, 515], "gov": 109, "feder": 109, "pai": [109, 553, 571], "occup": 109, "categorical_column_with_hash_bucket": 109, "hash_bucket_s": 109, "_hash_bucket_s": 109, "age_bucket": 109, "bucketized_column": 109, "55": [109, 130, 375, 502, 545], "60": [109, 347, 375, 380, 388, 502, 511], "base_column": 109, "crossed_column": 109, "wide_column": 109, "deep_column": 109, "indicator_column": 109, "census_main": 109, "linear_model": 109, "to_sparse_input": 109, "dense_shap": 109, "input_from_feature_column": 109, "input_lay": 109, "education_ind": 109, "marital_status_ind": 109, "relationship_ind": 109, "workclass_ind": 109, "cased_l": 110, "xlnet_model": 110, "piec": [110, 360, 397, 566], "spiec": 110, "xlnet_config": 110, "zihangdai": 110, "released_model": 110, "zip": [110, 349, 479], "try_sav": 110, "python2": 110, "namedtupl": 110, "model_util": 110, "init_ckpt_path": 110, "xlnet_cased_l": 110, "xlnet_config_path": 110, "use_tpu": 110, "xlnetconfig": 110, "json_path": 110, "run_config": 110, "runconfig": 110, "use_bfloat16": 110, "dropatt": 110, "sentence_features_input_idx": 110, "sentence_features_segment_id": 110, "seg_id": 110, "sentence_features_input_mask": 110, "xlnetmodel": 110, "disk": [110, 127, 498, 525, 532, 557], "dropout_2": 110, "graph_def_freez": 110, "model_frozen": 110, "write": [110, 118, 122, 127, 131, 132, 133, 134, 212, 213, 223, 353, 358, 398, 471, 477, 478, 479, 493, 497, 499, 504, 539, 547, 558, 562, 571], "summari": [110, 118, 496, 540], "filewrit": 110, "logdir": 110, "writer": 110, "flush": [110, 542], "1024_a": 110, "24_h": 110, "darknet": 111, "darkflow": 111, "david8862": 111, "model_convert": 111, "path_to_cfg_fil": 111, "path_to_weight": 111, "image_input": 111, "608": [111, 113], "ed60b90": 111, "extractor": [111, 118, 121, 123], "author": [111, 127, 129], "badli": 111, "idea": [111, 209, 220, 524, 559], "mystic123": 111, "pil": [111, 529], "pillow": [111, 348], "convert_weights_pb": 111, "class_nam": 111, "data_format": 111, "weights_fil": 111, "entiti": [111, 522], "gast": 111, "416": 111, "yolov3_608": 111, "solv": [111, 368, 471, 496], "yolo_v3": 111, "openvino_install_dir": 111, "model_optim": 111, "tfyolov3": 111, "custom_attribut": [111, 122], "anchor": [111, 122, 323, 326, 330, 331, 333], "33": [111, 375, 377, 378, 502, 511, 543], "61": [111, 329, 375, 390, 502, 524], "59": [111, 341, 375, 390, 511], "198": 111, "373": 111, "326": 111, "coord": [111, 122, 333, 349, 508], "entry_point": 111, "reshape_4": 111, "reshape_8": 111, "titl": 111, "pars": [111, 118, 119, 122, 123, 124, 502, 509, 525, 546, 555], "miss": [111, 130, 213, 398, 481], "thtrieu": 111, "savepb": 111, "path_to_dataset_labels_fil": 111, "built_graph": 111, "subdirectori": [111, 211, 496], "recreat": 111, "yolo_config": 111, "pdiparam": [113, 528], "im_shap": 113, "scale_factor": 113, "save_infer_model": 113, "scale_0": 113, "tmp_1": 113, "scale_1": 113, "aforement": [113, 517, 542], "inputspec": [113, 528], "enable_stat": [113, 528], "ex": [113, 502, 504, 516, 528], "cpuplac": [113, 528], "default_startup_program": [113, 528], "explanatori": [113, 115], "typograph": [113, 115], "wrong": [113, 115, 213, 533], "Such": [114, 122, 132, 216, 225, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 548, 562, 563, 571], "instanti": [114, 118, 123, 216, 463, 464, 465, 522], "regular": [114, 122, 129, 222, 225, 253, 275, 312, 314, 315, 316, 317, 318, 319, 355, 360, 420, 454, 468, 477, 499, 517, 522, 536, 555, 571], "somemodel": 114, "dummi": [114, 537], "ner": 114, "rcan": 114, "yolact": 114, "whether": [115, 122, 127, 213, 216, 308, 320, 321, 322, 324, 326, 330, 331, 340, 347, 348, 349, 355, 383, 384, 388, 401, 408, 409, 430, 434, 436, 439, 451, 452, 453, 454, 461, 515, 516, 530, 533, 554, 556, 562, 568], "simpli": [115, 388, 390, 496, 539], "checkpoint_fil": [115, 530], "asset": [115, 530], "tensorboard_log": 115, "eager": [115, 572], "statefulpartitionedcal": 115, "trainabl": [115, 530], "name_of_the_output_nod": [115, 530], "indirectli": [115, 530], "deriv": [115, 129, 131, 212, 313, 314, 317, 318, 437, 529, 530, 542, 543, 544], "human": [115, 499, 547, 562], "readabl": [115, 499, 559], "hdf5": [115, 530], "essenti": [115, 226, 496, 499, 500, 541, 555, 562, 564, 568], "concret": [115, 379], "concrete_func": 115, "default_serving_signature_def_kei": 115, "lower_control_flow": 115, "aggressive_inlin": 115, "add_shap": 115, "customlay": [115, 530], "custom_lay": [115, 530], "custom_object": [115, 530], "hack": [115, 516, 530], "resav": [115, 530], "plain": [115, 121, 566, 571], "log_dir": 115, "word_id": 115, "type_id": 115, "imagenet": [115, 317, 325, 525, 530, 532], "keraslay": [115, 525, 530], "mobilenet_v1_100_224": [115, 525, 530], "mymodul": [115, 530], "variable1": 115, "var1": [115, 530], "variable2": 115, "var2": [115, 530], "__call__": [115, 349, 530, 552, 553], "simple_modul": [115, 530], "inp1": [115, 530], "inp2": [115, 530], "input_signatur": [115, 530], "tensorspec": [115, 530], "func": [115, 349, 390, 454, 455, 459, 530], "save_directori": [115, 530], "unabl": [115, 539, 545], "facenet": 115, "eighti": [116, 531], "percent": [116, 531], "impos": 117, "restrict": [117, 148, 407, 571], "logic": [117, 118, 121, 122, 148, 167, 219, 226, 295, 296, 297, 298, 363, 364, 365, 366, 367, 369, 388, 390, 423, 424, 506, 539, 541, 542, 546, 550, 555, 556, 566, 567], "global": [117, 127, 130, 340, 341, 401, 405, 496, 553], "commonli": [117, 224, 567], "architect": 117, "h1": 117, "w1": 117, "h2": 117, "w2": 117, "break": [117, 500], "famili": [117, 560], "diagram": [117, 118, 122, 517, 535, 572], "freeli": 117, "lose": [117, 127, 220, 367, 553], "alter": 118, "instabl": 118, "futur": [118, 127, 148, 524, 541, 543, 552, 556, 562, 566, 567], "lack": [118, 565], "familiar": [118, 520], "huge": [118, 121, 568], "inherit": [118, 119, 121, 123, 542], "networkx": [118, 120], "travers": [118, 119, 121, 122, 123, 124, 221, 222, 434, 436, 439, 572], "my_nod": 118, "my_attr": 118, "num_split": [118, 120, 397], "independ": [118, 120, 121, 125, 128, 133, 208, 218, 347, 348, 349, 369, 407, 409, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 451, 452, 453, 454, 455, 456, 457, 458, 459, 509, 515, 537, 545, 548, 566, 569, 571], "abstract": [118, 120, 130, 218, 551], "manipul": [118, 120, 123, 126, 131, 220, 222, 441, 442, 443, 444, 445, 553, 557, 563], "meanwhil": [118, 226], "prone": 118, "strongli": [118, 554], "explan": [118, 119, 312, 313, 314, 315, 316, 317, 432], "loader": [118, 473], "proto": 118, "throw": [118, 213, 334, 551], "depict": [118, 120], "mathemat": [118, 129, 132, 148, 244, 245, 246, 247, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 265, 268, 269, 270, 272, 273, 276, 284, 287, 289, 290, 293, 364, 403, 404, 413, 415, 417, 418], "fact": [118, 120, 122, 520, 562], "perspect": [118, 127, 560], "themselv": 118, "black": 118, "customlayersmap": 118, "peculiar": [118, 545], "let": [118, 120, 127, 132, 135, 148, 163, 220, 222, 244, 329, 340, 368, 398, 399, 403, 404, 446, 447, 448, 449, 452, 453, 454, 455, 459, 502, 539, 555, 556, 562, 568], "But": [118, 136, 148, 163, 221, 222, 431, 562], "topknorm": 118, "seem": [118, 558], "flattenonnx_to_reshap": 118, "shapeof": [118, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 421, 422, 423, 424, 425, 426, 427, 428, 429, 440], "fold": [118, 131, 135, 545], "happen": [118, 209, 242, 398, 466, 525, 534, 541, 542, 555], "data2_0": 118, "topolog": [118, 122, 220, 222], "thrown": [118, 213, 542, 563], "po": 118, "staticmethod": [118, 119, 123, 349], "soft_get": [118, 122], "in_port": [118, 120, 122], "get_shap": [118, 120, 551], "new_shap": 118, "get_valu": [118, 120], "output_shap": [118, 314, 348, 349, 375, 377, 378, 446, 447], "out_port": [118, 120, 122], "set_valu": [118, 120], "set_shap": [118, 120, 536], "output_port": 118, "op_nod": 118, "in_nod": [118, 120, 122], "out_nod": [118, 120, 122], "some_valu": 118, "five": [118, 319, 332, 367, 529], "nchw_shape": 118, "nhwc_shape": 118, "applypermut": 118, "insertlayoutpropagationtranspos": 118, "marksubgraphswithcorrectlayout": 118, "applynhwctonchwpermut": 118, "layoutchangeforconstantshapepath": 118, "opset": [118, 123, 213, 220, 222, 440, 529, 542, 551], "uniformli": 118, "backend_attr": [118, 123, 124], "supported_attr": [118, 123, 124], "prepare_emit_ir": 118, "prototxt": 119, "bottom": [119, 312, 313, 315, 316, 317, 344, 413, 414, 415, 416, 417, 540], "rpn_cls_prob_reshap": 119, "rpn_bbox_pr": 119, "caffepythonfrontextractorop": [119, 123], "frontextractorop": [119, 124], "proposalop": 119, "proposalpythonfrontextractor": 119, "extract_proposal_param": 119, "param": [119, 130, 135], "parse_param_str": 119, "update_attr": 119, "update_node_stat": [119, 124], "classmethod": [119, 124], "cl": [119, 124, 130, 544], "base_s": [119, 330, 331], "min_siz": [119, 323, 326, 327, 328, 330, 331], "pre_nms_topn": [119, 330, 331], "6000": [119, 330], "post_nms_topn": [119, 330, 331], "nms_thresh": [119, 330, 331], "belong": [120, 122, 123, 210, 220, 226, 344, 367, 380, 381, 387, 463, 465], "add_edges_from": 120, "add_nod": 120, "out_edg": 120, "node_id": 120, "lowest": [120, 323, 326, 330, 331, 340, 468], "get_output": 120, "insert_node_aft": 120, "n1": [120, 440], "create_edg": 120, "n2": [120, 440], "get_connect": [120, 122], "get_sourc": [120, 122], "set_destin": [120, 122], "dest_port": 120, "hide": [120, 497, 553, 555, 567], "safe": [120, 468, 541, 542, 550, 553, 555], "in_ports_count": [120, 122, 123, 124], "out_ports_count": [120, 123, 124], "add_input_port": 120, "add_output_port": 120, "delete_input_port": 120, "delete_output_port": 120, "outgo": [120, 122], "op1": 120, "op2": 120, "op3": 120, "op4": 120, "yellow": 120, "purpl": 120, "middl": [120, 121, 123], "get_destin": 120, "rais": [120, 122, 220, 341, 368, 388, 389, 390, 392, 407, 444, 468, 469, 533, 572], "disconnect": 120, "another_port": 120, "reus": [120, 483, 500, 521, 525, 526, 543, 547, 552, 563, 569], "encapsul": [120, 497], "data_3_0": 120, "set_sourc": [120, 122], "seamlessli": [120, 562], "inject": 121, "my_ext": 121, "framework_1": 121, "framework_2": 121, "histor": [121, 122, 226], "mo_enabled_transform": 122, "mo_disabled_transform": 122, "comma": [122, 367, 502, 539, 545, 546, 559], "nonmalizetonormalizel2": 122, "normalizetonormalizel2": 122, "run_not_recurs": 122, "force_clean_up": 122, "clean": [122, 126, 127, 135, 213, 496], "cleanup": 122, "reachabl": 122, "force_shape_infer": 122, "need_shape_infer": 122, "graph_condit": 122, "run_befor": 122, "run_aft": 122, "noth": 122, "overridden": 122, "premiddlestart": 122, "postmiddlestart": 122, "isomorph": 122, "frontreplacementsubgraph": 122, "frontreplacementpattern": 122, "replace_sub_graph": 122, "generate_sub_graph": 122, "complic": [122, 222, 516, 537, 550, 555, 560, 572], "third": [122, 127, 132, 311, 319, 322, 323, 324, 342, 343, 367, 376, 377, 378, 389, 391, 392, 398, 415, 416, 417, 441, 446, 447, 448, 449, 470, 500, 536, 542, 559], "mish_fus": 122, "softplus_fus": 122, "softplusfus": 122, "activation_op": 122, "subgraph_match": 122, "rename_nod": 122, "mishfus": 122, "formula": [122, 130, 132, 208, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 260, 262, 265, 266, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 280, 281, 282, 283, 284, 285, 287, 289, 290, 291, 292, 293, 294, 313, 314, 315, 316, 322, 325, 329, 336, 341, 342, 343, 345, 346, 348, 349, 350, 351, 361, 362, 364, 380, 381, 387, 400, 408, 411, 412, 432, 433, 434, 435, 438, 448, 454], "mul_nam": 122, "input_port_idx": 122, "create_nod": 122, "reconnect": [122, 127], "tbr": 122, "frontreplacementop": 122, "replace_op": 122, "partial_inf": 122, "int64_arrai": 122, "create_op_with_const_input": 122, "pack_nam": 122, "ind": [122, 349], "unsqueeze_nod": 122, "find_and_replace_pattern": 122, "squeezenorm": 122, "older": [122, 226, 473, 475, 543], "ax": [122, 312, 313, 314, 315, 316, 317, 318, 336, 347, 348, 349, 368, 369, 370, 371, 372, 385, 387, 394, 399, 400, 407, 408, 409, 410, 413, 414, 415, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 446, 447, 448, 449, 560], "uncondition": 122, "squeeze_nod": 122, "get_op_nod": 122, "squeeze_dim": 122, "has_valid": 122, "dims_nod": 122, "good": [122, 471, 497, 498, 533, 542, 557, 560, 569], "put": [122, 127, 130, 222, 224, 270, 446, 447, 448, 515, 516, 526, 539, 549, 553, 572], "prefix": [122, 515], "v4": 122, "mixed_5b": 122, "mixed_5c": 122, "mixed_5d": 122, "extrem": [122, 536, 542], "inceptionblock": 122, "frontreplacementfromconfigfilesubgraph": 122, "attr1_kei": 122, "attr1_valu": 122, "attr2_kei": 122, "123456": 122, "inceptionblocktransform": 122, "branch_2": 122, "conv2d_0a_1x1": 122, "branch_3": 122, "avgpool_0a_3x3": 122, "branch_1": 122, "branch_0": 122, "denot": [122, 312, 313, 315, 316, 317, 320, 321, 327, 328, 329, 340, 344, 361, 362, 377, 378, 380, 381, 433, 434], "mixed_5a": 122, "th": [122, 274, 302, 304, 310, 315, 316, 340, 341, 343, 360, 368, 394, 397, 398, 402, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432], "output_nod": 122, "ssd_support_api_v1": 122, "code_typ": [122, 320, 321], "priorboxparamet": [122, 320, 321], "center_s": [122, 320, 321], "pad_mod": [122, 383, 384], "resizeparamet": 122, "resize_mod": 122, "warp": 122, "clip_before_nm": [122, 320, 321, 330, 331], "clip_after_nm": [122, 320, 321, 330, 331], "objectdetectionapissdpostprocessorreplac": 122, "include_inputs_to_sub_graph": 122, "include_outputs_to_sub_graph": 122, "detection_box": 122, "detection_scor": 122, "num_detect": 122, "postprocessor": 122, "scale_logit": 122, "cast_1": 122, "frontreplacementfromconfigfilegener": 122, "transform_graph": 122, "replacement_descript": 122, "yolo_v1_tini": 122, "tfyolo": 122, "do_softmax": [122, 333], "no_op_eras": 122, "nooperas": 122, "standalone_const_eras": 122, "standaloneconsteras": 122, "regionyoloop": 122, "yoloregionaddon": 122, "yoloregion": 122, "chain": [122, 432, 464, 552, 562], "replacement_id": 122, "op_output": 122, "last_nod": 122, "op_param": 122, "end_axi": [122, 333], "region_lay": 122, "region_layer_nod": 122, "dim_attr": 122, "remove_nod": 122, "middlereplacementpattern": 122, "replace_pattern": 122, "l2normtonorm": 122, "checkforcycl": 122, "shufflenetrelureord": 122, "backreplacementpattern": 122, "gathernorm": 122, "short": [123, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 536, 539, 541, 546, 569], "involv": [123, 132, 415, 416, 417, 499, 502, 519, 524, 539, 541, 542, 562, 569], "emit": [123, 129, 430, 431], "type_inf": 123, "get_op_class_by_nam": 123, "constructor": [123, 132, 135, 148, 210, 218, 522, 544, 553, 570, 571], "__class__": 123, "opset1": [123, 224, 226, 227, 309], "interchang": [123, 226], "spatial_dim": 123, "pads_begin": [123, 224, 312, 313, 314, 315, 316, 317, 318, 347, 348, 349, 383, 384, 395, 413, 414, 415, 416, 417, 418], "get_backend_pad": 123, "pads_end": [123, 224, 312, 313, 314, 315, 316, 317, 318, 347, 348, 349, 383, 384, 395, 413, 414, 415, 416, 417, 418], "pool_method": 123, "exclude_pad": 123, "rounding_typ": [123, 413, 414, 415, 416, 417, 418], "const_ext": 124, "tf_dtype_extractor": 124, "tf_tensor_shap": 124, "tf_tensor_cont": 124, "constextractor": 124, "pb_tensor": 124, "helper": [124, 131, 213, 218, 219, 220, 222, 539, 545, 553, 559], "tensor_shap": 124, "numpy_help": 124, "to_arrai": 124, "onnx_attr": 124, "constantextractor": 124, "tensorproto": 124, "keyword": 124, "pb_valu": 124, "emitt": 124, "filter": [125, 126, 312, 313, 314, 315, 316, 317, 318, 320, 321, 330, 331, 337, 413, 414, 415, 416, 417, 451], "binar": [125, 420, 518], "sparsiti": [125, 209, 518], "conda": [125, 475, 484, 485, 489, 490, 491, 496, 500], "forg": [125, 484, 485, 489], "filtrat": 126, "merger": 126, "geti": 126, "cvat": [126, 128], "eas": [126, 497, 556], "enjoi": 126, "datum": 126, "corrector": 126, "categori": [126, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 504, 529], "choic": [126, 477, 478, 502, 516, 534, 539, 560, 568], "exactmerg": 126, "intersectmerg": 126, "unionmerg": 126, "subset": [126, 327, 328, 329, 367, 486, 524], "splitter": 126, "splittask": 126, "unsatisfactori": [126, 128, 517], "skill": 126, "refin": [126, 322], "peopl": 127, "kvm": 127, "brief": [127, 135, 519], "triangl": [127, 451], "ovsatool": 127, "cryptograph": 127, "collater": 127, "materi": [127, 471, 493, 494, 525, 549], "respond": 127, "internet": [127, 502], "against": [127, 514, 515, 564], "swtpm": 127, "vtpm": 127, "tpm": 127, "firmwar": [127, 515], "trust": [127, 492], "dtpm": 127, "ftpm": 127, "onlin": [127, 471, 495, 525, 569], "statu": [127, 220], "protocol": 127, "ocsp": 127, "ellipt": 127, "curv": [127, 497], "cryptographi": [127, 470], "ecc": 127, "install_host_dep": 127, "halt": 127, "restart": [127, 492], "minut": 127, "dmesg": [127, 474], "grep": [127, 476, 490, 491, 492], "presenc": [127, 320, 321, 551], "tpm0": 127, "tpmrm0": 127, "ok": 127, "info": [127, 131, 135, 219, 322, 323, 326, 502, 505, 506, 507, 508, 509, 510, 511, 512, 540, 541, 556], "sudo": [127, 476, 477, 478, 483, 490, 491, 496, 504, 545], "apt": [127, 473, 475, 484, 492, 496, 504, 545], "qemu": 127, "libvirt": 127, "bridg": 127, "virt": 127, "x86_64": [127, 473, 477, 480, 481, 482, 486, 487, 488, 496, 515], "libtpm": 127, "tpm2": 127, "tss": 127, "abmrd": 127, "behind": [127, 209, 492, 539, 546], "proxi": [127, 492, 502, 539, 546], "sw": [127, 476, 490], "ip": [127, 496, 502], "init": [127, 388, 516], "yaml": 127, "eno1": 127, "br0": 127, "virbr0": 127, "netplan": 127, "dhcp4": 127, "dhcp": 127, "ssh": 127, "multicast": 127, "lower_up": 127, "mtu": 127, "1500": 127, "qdisc": 127, "noqueu": 127, "qlen": 127, "1000inet": 127, "brd": 127, "321": 127, "ifup": 127, "nic": 127, "fi": 127, "ifconfig": 127, "brctl": 127, "addif": 127, "ifdown": 127, "delif": 127, "ovsa_isv": 127, "virsh": 127, "libvirtd": 127, "iso": 127, "amd64": [127, 473, 504], "qcow2": 127, "ovsa_isv_dev_vm_disk": 127, "20g": 127, "8192": 127, "virtio": 127, "cdrom": 127, "e1000": 127, "netdev": 127, "hostnet1": 127, "54": [127, 375], "d1": [127, 373, 374, 396], "5f": [127, 322], "tap": 127, "downscript": 127, "vnc": 127, "screen": 127, "ovsa_isv_dev": 127, "shut": 127, "ONE": 127, "install_guest_dep": 127, "ovsa": 127, "On": [127, 502, 533, 542, 544, 545, 567, 568], "provis": 127, "p": [127, 312, 313, 315, 316, 392, 430, 432, 448, 496, 542], "vtpm_isv_dev": 127, "xdg_config_hom": 127, "usr": [127, 473, 476, 490, 491, 515], "swtpm_setup": 127, "tpmstate": 127, "ek": 127, "cert": 127, "overwrit": [127, 388, 502], "pcr": 127, "bank": 127, "start_ovsa_isv_dev_vm": 127, "increment": [127, 355, 394, 398], "nvram": 127, "8280": 127, "ctrl": [127, 477, 496], "tcp": 127, "8281": 127, "tpm2_startup": 127, "clear": [127, 222, 559, 568], "ovsa_write_hwquote_swtpm_nvram": 127, "pkill": 127, "unixio": 127, "sock": 127, "smp": 127, "hostnet0": 127, "6f": 127, "chardev": 127, "chrtpm": 127, "tpmdev": 127, "emul": [127, 209, 419, 516, 537, 543, 556], "ti": 127, "ovsa_runtime_vm_disk": 127, "hostnam": 127, "ovsa_runtim": 127, "hostnamectl": 127, "nano": 127, "rm": [127, 477, 478, 496], "systemd": 127, "ovsa_ovsa_runtime_vm_disk": 127, "vtpm_runtim": 127, "start_ovsa_runtime_vm": 127, "8380": 127, "8381": 127, "hostnet2": 127, "hostnet3": 127, "start_ovsa_isv_vm": 127, "model_serv": 127, "docker_build": 127, "security_addon": 127, "release_fil": 127, "ovsa_release_path": 127, "pwd": 127, "scp": 127, "usernam": 127, "useradd": 127, "passwd": 127, "opt": [127, 477, 478, 496, 497, 502, 505, 524, 572], "setupvar": [127, 477, 478, 479, 492, 496, 500, 504, 549], "license_serv": 127, "firewal": [127, 492], "usermod": 127, "0004": [127, 502], "ovsa_dev_artefact": 127, "csr": 127, "keygen": 127, "storekei": 127, "ecdsa": 127, "isv_keystor": 127, "IN": 127, "cn": 127, "localhost": 127, "keystor": 127, "crt": 127, "storecert": 127, "curl": [127, 473, 477, 478, 479, 496], "004": 127, "open_": 127, "models_bin": 127, "uuid": [127, 547], "uuidgen": 127, "controlaccess": 127, "face_detection_model": 127, "dat": 127, "masterl": 127, "encrypt": [127, 469, 549], "ovsaruntim": 127, "face_detect_runtime_vm": 127, "licgen": 127, "timelimit": 127, "l30": 127, "30daylicens": 127, "ovsa_license_server_cert_pin": 127, "__": 127, "sale": 127, "l": [127, 255, 325, 341, 368, 440, 477, 478, 479], "custkeystor": 127, "lic": 127, "databas": [127, 492, 525], "db": 127, "ovsa_store_customer_lic_cert_db": 127, "ovsa_rumtim": 127, "ovsa_runtime_artefact": 127, "ovsa_dev": 127, "ask": 127, "cp": 127, "example_runtim": 127, "vp": 127, "fd": 127, "custom_loader_config_list": 127, "loader_nam": 127, "library_path": 127, "lib": [127, 482, 500, 515, 572], "libovsaruntim": 127, "model_config_list": 127, "base_path": 127, "sampleload": 127, "custom_loader_opt": 127, "controlled_access_fil": 127, "start_secure_ovsa_model_serv": 127, "scikit": 127, "face_detect": 127, "example_cli": 127, "inferenc": [127, 216, 471, 502, 541, 562, 567], "people1": 127, "jpeg": [127, 502], "grpc_port": 127, "3335": 127, "input_images_dir": 127, "tl": 127, "server_cert": 127, "modelserv": 127, "pem": 127, "client_cert": 127, "client_kei": 127, "ran": [127, 504], "accur": [128, 518, 520, 522, 524], "opportun": [128, 536], "rare": 129, "plug": [129, 133, 473, 544], "rule": [129, 208, 209, 220, 226, 254, 266, 275, 278, 280, 281, 282, 283, 285, 286, 291, 292, 295, 297, 298, 299, 300, 301, 303, 305, 306, 307, 309, 311, 328, 341, 349, 355, 360, 363, 365, 366, 367, 369, 371, 372, 383, 384, 394, 398, 399, 400, 414, 416, 420, 446, 447, 448, 449, 468, 541, 564, 570], "decomposit": [129, 132, 136, 148, 220, 368], "feasibl": [129, 522], "bulki": 129, "constitu": [129, 572], "decompos": [129, 135, 148, 163, 368, 529, 566, 572], "bare": [129, 483, 567], "metal": [129, 483], "minimalist": [129, 132], "openvino_create_extens": 129, "macro": [129, 131, 213, 216, 220], "find_packag": [129, 211, 488, 549], "template_extens": 129, "dopenvino_dir": 129, "openvino_dir": [129, 500, 549], "codepath": 130, "lib_path": 130, "cldnn_global_custom_kernel": 130, "set_properti": [130, 540, 541, 548], "config_fil": 130, "trivial": [130, 398], "hello_classif": [130, 505, 545], "classification_sampl": 130, "bvlc_alexnet_fp16": 130, "validation_set": 130, "daili": 130, "227x227": 130, "apron": 130, "absolute_path_to_config": 130, "custom_layer_exampl": 130, "simplegpu": 130, "filenam": 130, "arg": [130, 400], "bfyx": 130, "byxf": 130, "yxfb": 130, "fyxb": 130, "lowercas": [130, 367], "queu": 130, "arithmet": [130, 135, 209, 225, 226, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 299, 300, 301, 305, 306, 426], "example_relu_kernel": 130, "custom_layer_kernel": 130, "neg_slop": 130, "negative_slop": 130, "mad": 130, "num_input": 130, "global_works": 130, "global_worksize_s": 130, "local_works": 130, "local_worksize_s": 130, "_dim": 130, "_dims_siz": 130, "_type": 130, "datatyp": [130, 295, 296, 297, 298, 468], "_format_": 130, "tensor_format": 130, "ifdef": 130, "endif": [130, 516], "_lower_pad": 130, "_lower_padding_s": 130, "_upper_pad": 130, "_upper_padding_s": 130, "_pitch": 130, "adjac": [130, 312, 313, 315, 316, 317, 416, 417], "_pitches_s": 130, "_offset": 130, "bypass": [130, 547], "input0": 130, "output0": [130, 417, 418], "input0_dims_s": 130, "input0_dim": 130, "96": [130, 375, 512], "pragma": [130, 516], "cl_khr_fp16": 130, "__kernel": 130, "__global": 130, "input0_typ": 130, "output0_typ": 130, "uint": 130, "get_global_id": 130, "idi": 130, "idbf": 130, "nd": [130, 369], "output0_dim": 130, "pitch": 130, "in_id": 130, "input0_pitch": 130, "input0_offset": 130, "out_id": 130, "output0_pitch": 130, "output0_offset": 130, "printf": 130, "care": [130, 220, 222], "excess": 130, "openvino_op": [131, 132], "nodetypeinfo": 131, "get_input_partial_shap": 131, "get_input_element_typ": 131, "set_output_typ": 131, "deseri": 131, "attributevisitor": 131, "walk": [131, 471, 499], "on_attribut": 131, "int64_t": 131, "openvino_contrib": 132, "correspondingli": [132, 208, 369, 377, 378, 446, 447, 448, 571], "predefin": [132, 216, 498, 502, 537, 543], "surround": 132, "templateextens": 132, "myrelu": 132, "sai": [132, 220], "opset8": [132, 227, 309, 321, 378, 381, 551], "visit_attribut": 132, "imagin": 132, "customoper": 132, "attr1": 132, "attr2": 132, "fw_attr1": 132, "fw_attr2": 132, "variant": [132, 543], "customelu": 132, "lbrace": [132, 245], "ll": 132, "textrm": [132, 400], "newlin": 132, "0f": [132, 392], "customop": 132, "customopv3": 132, "attributes_map": 132, "attributes_valu": 132, "m_mode": 132, "m_axi": 132, "secondli": 132, "thirdli": 132, "cmakelist": [132, 211, 481], "target_link_librari": 132, "target_nam": 132, "outpu": 132, "fragment": 132, "get_values_from_const_input": 132, "fetch": [132, 565], "nodecontext": 132, "get_input": 132, "get_attribut": 132, "namedoutput": 132, "top_k_v2": 132, "namedoutputvector": 132, "raw_op": 132, "create_plugin_engin": 133, "lpt": [135, 208], "unsign": [135, 148, 270, 309, 340, 466, 467, 468, 516, 524, 557, 560], "principl": [135, 136, 148, 360, 520], "interv": [135, 136, 138, 148, 163, 308, 327, 328, 330, 331, 332, 338, 375, 542, 551], "histori": 135, "whitepap": 135, "convolutionbackpropdata": [135, 172, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 318], "groupconvolut": [135, 167, 173, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 318], "interpol": [135, 174, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 316, 319, 332, 335, 336, 337, 338, 344], "normalizel2": [135, 186, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "variadicsplit": [135, 184, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "compens": 135, "rework": [135, 226], "matcher": [135, 220, 221], "pullreshapethroughdequant": [135, 143], "pulltransposethroughdequant": [135, 143], "linopsequencefus": [135, 143], "markupbia": [135, 148], "markupcanbequant": [135, 136], "markupprecis": [135, 136], "markuppertensorquant": [135, 136], "markupavgpoolprecisionpreserv": [135, 136], "propagateprecis": 135, "alignquantizationinterv": [135, 136], "alignquantizationparamet": [135, 136], "addtransform": [135, 163], "avgpooltransform": [135, 163], "clamptransform": [135, 163], "batchtospacetransform": [135, 163], "concattransform": [135, 163], "convolutiontransform": [135, 163], "convolutionbackpropdatatransform": [135, 163], "depthtospacetransform": [135, 163], "fakequantizedecompositiontransform": [135, 136, 163], "fakequantizetransform": [135, 163], "interpolatetransform": [135, 163], "groupconvolutiontransform": [135, 163], "gathertransform": [135, 163], "matmultransform": [135, 163], "maxpooltransform": [135, 163], "multiplypartialtransform": [135, 163, 169], "mvntransform": [135, 163], "normalizel2transform": [135, 163], "prelutransform": [135, 163], "reducemaxtransform": [135, 163], "reducemeantransform": [135, 163], "reducemintransform": [135, 163], "reducesumtransform": [135, 163], "relutransform": [135, 163], "reshapetransform": [135, 163], "squeezetransform": [135, 163], "shufflechannelstransform": [135, 163], "spacetobatchtransform": [135, 163], "splittransform": [135, 163], "stridedslicetransform": [135, 163], "transposetransform": [135, 163], "unsqueezetransform": [135, 163], "variadicsplittransform": [135, 163], "wise": [135, 208, 225, 226, 242, 244, 245, 246, 247, 248, 249, 253, 254, 255, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 315, 316, 322, 361, 362, 363, 364, 365, 366, 367, 403, 404, 419, 420, 433, 435, 451, 466, 467, 498, 524, 564], "least": [135, 210, 309, 367, 373, 403, 404, 440, 468, 496, 502, 516, 536, 556], "eliminatefakequantizetransform": [135, 200], "foldconverttransform": [135, 200], "foldfakequantizetransform": [135, 200], "fuseconverttransform": [135, 200], "fusemultiplytofakequantizetransform": [135, 200], "fusesubtracttofakequantizetransform": [135, 200], "multiplytogroupconvolutiontransform": [135, 200], "lost": 135, "simplest": [135, 516, 521, 522, 523, 529], "met": [135, 483, 502, 567], "omz_download": 135, "omz_quant": 135, "dataset_dir": 135, "niter": [135, 502, 516, 539, 546], "sync": [135, 434, 436, 439, 501, 502, 510, 555, 556], "report_typ": [135, 502], "average_count": [135, 502], "report_fold": [135, 502], "pc_report_dir": 135, "ultim": 135, "customiz": [135, 497], "lowprecis": [135, 148], "updateprecis": 135, "member": [135, 319, 551], "layertransform": 135, "callback": [135, 210, 212, 220, 509, 550, 556, 566], "asymmetr": [135, 208, 336, 348, 349, 522, 524], "isasymmetricquant": 135, "weightablelayertransform": 135, "isasymmetriconweight": 135, "avgpoolprecisionpreserv": [136, 148], "intervalsalign": [136, 148], "precisionpreserv": [136, 148], "quantizationalign": [136, 148], "granular": [136, 142, 564], "quantizationgranular": 136, "pertensorquant": [136, 148], "avgpoolprecisionpreservedattribut": 137, "intervalsalignmentattribut": 138, "precisionpreservedattribut": 139, "precisionsattribut": 140, "quantizationalignmentattribut": 141, "quantizationgranularityattribut": 142, "low_precis": [144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207], "bia": [148, 209, 361, 362, 403, 404, 405, 406, 407, 522], "createattribut": 148, "createprecisionsdependentattribut": 148, "propagatethroughprecisionpreserv": 148, "propagatetoinput": 148, "updatesharedprecisionpreserv": 148, "concat1": [148, 163], "convolution1": 148, "concat2": [148, 163], "convolution2": [148, 163], "bold": 148, "padtransform": 163, "fakequantize1": 163, "fakequantize2": 163, "fakequantize3": 163, "volum": [167, 441], "parent": [167, 220, 382, 551, 553], "y_": [167, 252, 255, 258, 259, 325], "ch": 167, "scale1_": 167, "x1_": 167, "shift1_": 167, "scale2_": 167, "x2_": 167, "shift2_": 167, "multiplyparti": 169, "result_": 171, "a_": [171, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 278, 279, 280, 281, 282, 283, 284, 287, 288, 289, 290, 291, 292, 293, 299, 300, 301, 305, 306, 307, 363, 364, 365, 366, 466], "cdot": [171, 247, 248, 251, 253, 254, 256, 262, 283, 313, 316, 346, 351, 368, 407, 411, 412, 446, 447, 448, 449], "b_": [171, 266, 275, 278, 280, 281, 282, 283, 291, 292, 299, 300, 301, 305, 306, 307, 363, 365, 366, 370, 395, 403, 404, 446, 447, 448, 449], "scalar": [171, 242, 249, 262, 274, 309, 316, 339, 340, 341, 342, 343, 347, 354, 355, 356, 358, 367, 369, 373, 376, 377, 378, 382, 383, 384, 387, 388, 389, 392, 397, 401, 402, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 437, 440, 442, 443, 444, 445, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 465, 468], "foldfakequant": 190, "batchtospac": [195, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "spacetobatch": [197, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 370], "fake": [208, 419, 420], "former": [208, 522, 547], "latter": [208, 332, 344, 522], "requant": 208, "fig": [208, 209], "dq": [208, 517], "rq": 208, "standpoint": 208, "input_low": [208, 420], "input_high": [208, 420], "output_high": [208, 420], "output_low": [208, 420], "scheme": [208, 432, 515, 522, 534], "mix": [208, 468, 493, 502, 518, 522, 524, 547, 568], "depthwis": 208, "symmetr": [208, 383, 384, 522, 524], "guidanc": [209, 469], "influenc": 209, "reproject": 209, "2020": [209, 226, 227], "substanti": [209, 498, 566], "iasyncinferrequest": [210, 212], "m_pipelin": 210, "shared_ptr": [210, 220, 551], "itaskexecutor": 210, "stop_and_wait": 210, "destructor": 210, "destroi": [210, 219, 571], "m_cancel_callback": 210, "interrupt": [210, 219], "m_wait_executor": 210, "infer_preprocess_and_start_pipelin": 210, "submit": 210, "wait_pipelin": 210, "infer_postprocess": 210, "m_request_executor": [210, 212], "overlap": [210, 212], "m_callback_executor": [210, 212], "callback_executor": 210, "infrastructur": [211, 216, 352, 353, 354, 355, 356, 357, 358, 359, 360, 543], "dcmake_build_typ": [211, 481, 504, 516], "openvinodeveloperpackageconfig": 211, "targets_develop": 211, "tree": 211, "pugixml": 211, "xbyak": 211, "header": [211, 213, 217, 218, 474, 516, 544], "gtest": 211, "gtest_main": 211, "gmock": 211, "common_test_util": 211, "func_test_util": 211, "unit_test_util": 211, "builder": [211, 496, 560], "funcsharedtest": [211, 216], "ov_dev_target": 211, "dopenvinodeveloperpackage_dir": 211, "enable_test": 211, "enable_functional_test": 211, "denable_functional_test": 211, "icompiledmodel": 212, "m_task_executor": 212, "m_request_id": 212, "distinguish": [212, 262, 326, 375, 553], "m_cfg": [212, 213], "m_model": 212, "m_loaded_from_cach": 212, "pointer": [212, 213, 544, 551, 555, 571], "transform_model": 212, "model_stream": 212, "host": [212, 213, 473, 483, 492, 540, 542, 543, 544, 546, 547, 549, 550, 555, 572], "upload": [212, 219], "schedul": [212, 497, 499, 519, 539, 542, 543, 546, 547, 554, 555, 566, 567], "dev_api": 213, "iplugin": 213, "m_backend": 213, "m_waitexecutor": 213, "device_id": 213, "perf_count": [213, 502, 507], "streams_executor_config": 213, "istreamsexecutor": 213, "performance_mod": [213, 515, 539, 541, 542, 543, 547, 556, 562], "performancemod": [213, 502, 515, 539, 541, 542, 543, 556, 562], "disable_transform": 213, "exclusive_async_request": [213, 507], "improp": 213, "set_device_nam": 213, "alloc": [213, 219, 470, 496, 526, 529, 536, 544, 545, 550, 565, 571], "friendli": [213, 521, 545, 553, 555, 569, 570], "perfectli": [213, 557], "get_rt_info": [213, 500, 545], "supportedopsmap": 213, "ideal": [213, 497, 524, 566], "suppos": [213, 341, 344, 451, 452, 453, 454, 455, 459], "decis": [213, 220, 536], "export_model": 213, "remotecontext": [213, 550], "ov_define_plugin_create_funct": 213, "single_layer_test": 216, "googletest": 216, "convlayertestparamsset": 216, "instantiate_test_suite_p": 216, "subgraph_test": 216, "repetit": 216, "query_model": [216, 545, 548, 553], "artifact": 216, "iremotecontext": 217, "m_name": 217, "m_properti": [217, 218], "stl": 218, "iremotetensor": 218, "recal": [218, 526], "m_element_typ": 218, "m_shape": 218, "m_stride": 218, "m_data": 218, "m_dev_nam": 218, "isyncinferrequest": 219, "m_profiling_task": 219, "handle_t": 219, "numofstag": 219, "m_durat": 219, "m_backend_input_tensor": 219, "m_backend_output_tensor": 219, "m_execut": 219, "m_eval_context": 219, "m_variable_st": 219, "set_tensor": [219, 543, 544, 550, 555], "get_tensor": [219, 550, 554, 564], "asyncinferrequest": 219, "talk": 220, "replace_nod": 220, "old_nod": 220, "new_nod": 220, "replace_output_update_nam": 220, "rewrit": [220, 572], "matcher_scop": 220, "matcherpass": [220, 221], "matcher_nam": 220, "run_on_model_scop": 220, "run_on_model": [220, 223], "arrang": 220, "copy_runtime_info": 220, "forget": 220, "constantfold": 220, "openvino_deprec": 220, "unknown": [220, 394, 545], "validate_nodes_and_infer_typ": 220, "downgrad": 220, "graphrewrit": [220, 221, 222], "ov_profile_pass_en": 220, "ov_enable_visualize_trac": 220, "svg": 220, "temporari": [221, 369, 470, 525, 539], "registr": 221, "predic": [221, 222], "entranc": 222, "register_new_nod": 222, "register_match": 222, "graphrewit": 222, "any_input": 222, "wrap_typ": 222, "passpattern": 222, "commut": 222, "clear_stat": 222, "modelpass": 223, "made": [223, 437, 525, 545], "counterpart": [224, 553], "tag": [224, 226], "accompani": [224, 526], "model_file_nam": [224, 226], "element_typ": [224, 226, 309, 354, 356, 440, 571], "6912": 224, "output_pad": [224, 314, 318], "meta_data": 224, "auxiliari": [224, 516], "mo_vers": 224, "cli_paramet": 224, "blobs_as_input": 224, "consequ": [225, 529, 542], "suggest": 225, "rather": [226, 344, 516, 529, 532, 536, 539, 555, 557, 564, 567], "imposs": [226, 516], "deal": [226, 523, 562], "movement": [226, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402], "unchang": [226, 244], "field": [226, 313, 315, 316, 473, 542, 571], "opset2": [226, 227], "differenti": 226, "occurr": [226, 390, 398, 401, 432], "opsetn": 226, "grow": [226, 565, 567], "constantli": 226, "evolv": 226, "evolution": 226, "accumul": [226, 343, 368, 398, 568], "meant": 226, "ngraph": 226, "cadenc": 226, "alias": [226, 347, 348, 349], "evolut": 226, "fraction": [226, 348, 349, 566], "opset14": 227, "opset13": [227, 440], "opset12": 227, "opset11": 227, "opset10": 227, "opset9": [227, 326], "opset7": [227, 367, 377], "opset6": [227, 322, 323, 324, 325, 431, 450], "opset5": 227, "opset4": 227, "opset3": 227, "batchnorminfer": [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "convertlik": [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 419, 440], "deformablepsroipool": [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "groupconvolutionbackpropdata": [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "reducelogicaland": [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "reducelogicalor": [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243], "adaptiveavgpool": [229, 230, 231, 232, 233, 240, 241, 243], "adaptivemaxpool": [229, 230, 231, 232, 233, 240, 241, 243], "ctcgreedydecoderseqlen": [229, 230, 231, 232, 233, 238, 239, 240, 241, 243], "dft": [229, 230, 231, 232, 233, 239, 240, 241, 243], "embeddingbagoffsetssum": [229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "embeddingbagpackedsum": [229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "embeddingsegmentssum": [229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "experimentaldetectrondetectionoutput_6": [229, 230, 231, 232, 233, 238, 239, 240, 241], "experimentaldetectrongenerateproposalssingleimage_6": [229, 230, 231, 232, 233, 238, 239, 240, 241], "experimentaldetectronpriorgridgenerator_6": [229, 230, 231, 232, 233, 238, 239, 240, 241], "experimentaldetectronroifeatureextractor_6": [229, 230, 231, 232, 233, 238, 239, 240, 241], "experimentaldetectrontopkrois_6": [229, 230, 231, 232, 233, 238, 239, 240, 241], "generatepropos": [229, 230, 231, 232, 233, 241, 243], "gridsampl": [229, 230, 231, 232, 233, 241, 243], "hsigmoid": [229, 230, 231, 232, 233, 237, 238, 239, 240, 241, 243], "hswish": [229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "idft": [229, 230, 231, 232, 233, 239, 240, 241, 243], "i420tobgr": [229, 230, 231, 232, 233, 240, 241, 243], "i420torgb": [229, 230, 231, 232, 233, 240, 241, 243, 345], "irdft": [229, 230, 231, 232, 233, 241, 243], "isinf": [229, 230, 231, 232, 233, 243], "isnan": [229, 230, 231, 232, 233, 243], "matrixnm": [229, 230, 231, 232, 233, 240, 241, 243], "multiclassnm": [229, 230, 231, 232, 233, 240, 241], "nv12tobgr": [229, 230, 231, 232, 233, 240, 241, 243], "nv12torgb": [229, 230, 231, 232, 233, 240, 241, 243, 346, 350], "rdft": [229, 230, 231, 232, 233, 241, 243], "readvalu": [229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243, 352, 353, 569, 570], "scatterelementsupd": [229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 243], "scatterndupd": [229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 243], "bitwiseand": [232, 233, 243], "bitwiseor": [232, 233, 243], "bitwisexor": [232, 233, 243], "bitwisenot": [232, 233, 243], "fakeconvert": [232, 233, 243], "nmsrotat": [232, 233, 243], "scaleddotproductattent": [232, 233, 243], "convertpromotetyp": [233, 243], "roialignrot": [233, 243], "gathernd_5": [237, 238, 239], "implicit": [242, 266, 275, 283, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 363, 365, 366, 367, 369, 420, 541], "prepend": [242, 399], "implicitli": [242, 314, 515, 516, 541, 543, 545, 560, 569, 571], "onto": [242, 309, 355, 360, 502], "trail": [242, 393], "won": [242, 549, 571], "leftmost": 242, "target_shap": [242, 371, 372], "isfinit": 243, "multiclassnonmaxsuppress": 243, "min_valu": 244, "max_valu": 244, "x_": [244, 313, 325, 403, 404, 413], "_valu": 244, "clamp_nod": 244, "quad": [245, 256, 327, 328, 329, 399, 400], "leq": [245, 306, 370], "\u03b1": [245, 249, 254, 256], "phi": [247, 248], "frac": [247, 248, 250, 251, 252, 257, 258, 259, 261, 275, 294, 313, 327, 328, 329, 370, 395, 403, 404, 407, 408, 409, 411, 412, 413, 432, 446, 447, 448, 449], "\u03c6": [247, 248], "cumul": [247, 248, 274, 340, 370, 539], "approxim": [247, 248], "approx": [247, 248], "pi": [247, 248, 276, 446, 447, 448, 449], "044715": [247, 248], "approximation_mod": 248, "gauss": [248, 276], "formul": [249, 252, 255, 257, 258, 259, 340, 368, 403, 404, 413, 415, 417, 418], "\u03b2": [249, 262], "0d": [249, 354, 356, 358, 377, 378, 390, 391, 437, 444, 445], "elementwis": [250, 251, 254, 266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 363, 365, 366, 367, 371, 372, 401, 420], "multidimension": [251, 255, 367, 444], "logarithm": [252, 279, 322], "ln": [252, 253, 432, 477, 478], "z_": [252, 258, 259], "sum_": [252, 258, 259, 313, 315, 316, 403, 404, 407, 408, 413, 432], "monoton": [253, 262], "geq": [254, 260, 301], "learnabl": [254, 315, 316, 403, 404], "slope": 254, "1d": [254, 256, 309, 313, 314, 317, 318, 322, 323, 327, 328, 329, 330, 331, 335, 336, 337, 339, 340, 341, 347, 348, 349, 355, 362, 367, 369, 370, 371, 372, 376, 377, 378, 383, 384, 385, 386, 387, 388, 389, 392, 394, 398, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 415, 416, 417, 418, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 438, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 459, 460, 462, 463, 571], "snn": 256, "mbox": 256, "\u03bb": 256, "mathrm": 260, "stabil": [260, 403, 404, 406, 408, 525, 546, 565], "1e": [260, 405, 406, 408, 409, 410], "digit": [260, 510], "decim": [260, 524], "neuron": 261, "sigma": [262, 455, 459], "vert": 263, "arcco": 264, "hyperbol": [265, 268, 270, 273, 289, 294], "arccosh": 265, "auto_broadcast": [266, 275, 278, 280, 281, 282, 283, 285, 291, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 309, 311, 363, 365, 366, 420], "o_": [266, 275, 278, 280, 281, 282, 283, 290, 291, 292, 299, 300, 301, 305, 306, 307, 363, 365, 366, 403, 404, 408, 409, 466], "pdpd": [266, 275, 283, 292, 295, 297, 298, 299, 300, 301, 305, 306, 307, 311, 363, 365, 366, 420], "sine": [267, 268, 288, 289], "arcsin": 267, "arcsinh": 268, "tangent": [269, 270, 293, 294], "arctang": 269, "arctangenth": 270, "numeric_limit": 270, "lceil": [271, 411, 412], "rceil": [271, 411, 412], "summat": [274, 367, 410, 429], "j": [274, 325, 348, 349, 367, 376, 379, 388, 389, 390, 391, 392, 398, 400, 405, 411, 412, 413, 430, 432, 460, 461, 462], "t_axi": [274, 377, 378, 388, 389, 392, 394, 397, 400, 401], "divis": [275, 278, 282, 334, 370, 395, 397, 406, 408, 409, 410, 417, 418, 537], "m_pythondiv": 275, "int_": [276, 499], "dt": 276, "lfloor": [277, 411, 412], "rfloor": [277, 411, 412], "modulo": [278, 282, 466], "remind": [278, 282], "_mod": 278, "divisor": 278, "truncated_mod": 282, "dividend": 282, "o_i": [285, 314], "a_i": 285, "b_i": [285, 368, 370, 395, 452, 453, 454, 455, 459], "nearest": [286, 290, 294, 344, 347, 348, 349], "halv": 286, "half_to_even": 286, "awai": [286, 517], "half_away_from_zero": 286, "nan": [287, 302, 304], "angl": [288, 337, 454], "radian": [288, 293, 337, 454], "6457512": 290, "1622777": 290, "substract": 291, "25534192": 293, "54630249": 293, "2sigmoid": 294, "bitwis": [295, 296, 297, 298, 312, 341], "AND": [295, 363, 388, 390], "00010101": [295, 297, 298], "01111000": [295, 297, 298], "00000011": [295, 296, 297, 298], "00100101": [295, 297, 298], "00000001": [295, 296], "00100000": 295, "negat": [296, 364], "11111110": 296, "11111100": 296, "254": 296, "252": 296, "00010111": 297, "01111101": 297, "125": [297, 333, 380, 381, 388, 389, 390, 391, 392], "00010110": 298, "01011101": 298, "t_bool": [299, 300, 301, 363, 364, 365, 366, 423, 424], "finit": [302, 340, 542], "infin": [302, 303, 388, 416, 417, 433, 434, 435, 436, 438, 439], "inf": [302, 304, 415, 416, 417, 440], "infinit": [303, 344, 355], "detect_neg": 303, "detect_posit": 303, "t_in": [303, 304, 340], "output_typ": [308, 310, 339, 341, 343, 411, 412, 443, 451, 452, 453, 454, 455, 457, 458, 459], "with_right_bound": 308, "t_boundari": 308, "t_ind": [308, 322, 377, 378, 379, 380, 381, 388, 389, 390, 391, 392, 394, 398, 407, 408, 409, 410, 414, 416, 417, 421, 422, 423, 424, 425, 426, 427, 428, 429, 443, 446, 447, 448, 449, 451, 452, 453, 455, 457, 458, 461, 462, 463, 464, 465], "then_bodi": 309, "else_bodi": 309, "cond": [309, 311, 355], "port_map": [309, 355, 360], "then_port_map": 309, "else_port_map": 309, "external_port_id": [309, 355, 360], "internal_layer_id": [309, 355, 360], "add_x": 309, "add_z": 309, "add_w": 309, "num_non_zero": 310, "t_out": [310, 327, 328, 329, 468], "t_cond": 311, "blend": 311, "behav": [312, 344, 348, 349, 388, 390, 433, 434, 567], "thorough": [312, 313, 314, 315, 316, 317], "xnor": 312, "popcount": 312, "input_patch": 312, "distanc": [312, 313, 315, 316, 317, 327, 328, 329, 334, 375, 413, 414, 415, 416, 417], "slide": [312, 313, 315, 316, 317, 330, 331, 413, 414, 415, 416, 417], "neighbor": [312, 313, 315, 316, 317, 360], "pad_valu": [312, 383, 384], "odd": [312, 313, 314, 315, 316, 317, 318, 375, 413, 414, 415, 416, 417], "same_low": [312, 313, 314, 315, 316, 317, 318, 375, 413, 414, 415, 416, 417, 418], "t1": [312, 314, 318, 343, 344, 362, 385, 386, 395, 399, 402, 432, 434, 436, 437, 439, 467, 468], "c_in": [312, 313, 317, 318, 319], "t2": [312, 314, 318, 343, 362, 385, 386, 395, 399, 402, 432, 434, 436, 437, 439, 467, 468], "c_out": [312, 313, 317, 318], "t3": [312, 343, 385], "u1": [312, 354, 356, 358, 542, 543], "correl": 313, "n_": [313, 446, 447, 448, 449], "2p": 313, "recept": [313, 315, 316], "jump": [313, 500], "j_": [313, 446, 447, 448, 449], "r_": [313, 341], "start_": 313, "w_": [313, 315, 316, 411, 412], "o_z": 314, "o_x": 314, "i_z": 314, "i_i": 314, "i_x": 314, "y_i": 314, "x_i": [314, 368], "k_i": 314, "total_pad": 314, "unlock": [314, 318, 541], "c_input": 314, "c_output": 314, "aren": 314, "deduc": [314, 541, 548, 554, 556, 567], "upsampling_nod": [314, 318], "447": [314, 318], "450": 314, "demystifi": [315, 316], "displaystyl": [315, 316], "p_": [315, 316, 376, 377, 378, 395, 432], "delta": [315, 316, 322, 323, 326, 330, 331], "3x3": [315, 316], "deformable_group": [315, 316], "ncyx": [315, 316], "kernel_i": [315, 316], "kernel_x": [315, 316], "oiyx": [315, 316], "noyx": [315, 316], "220": [315, 316, 509], "convnet": 316, "m_": [316, 446, 447, 448, 449], "bilinear_interpolation_pad": 316, "shift": [316, 327, 328, 329, 337, 339, 341, 387, 403, 404, 419, 541, 562, 564, 569], "convolv": 317, "_convolution_": 317, "score": [319, 320, 321, 322, 323, 326, 330, 331, 332, 361, 362, 451, 452, 453, 454, 455, 456, 457, 458, 459, 524, 529, 534], "batch_id": [319, 320, 321, 332, 338], "x_1": [319, 320, 321, 332, 335, 336, 338, 368], "y_1": [319, 320, 321, 332, 335, 336, 338], "x_2": [319, 320, 321, 332, 335, 336, 338, 368], "y_2": [319, 320, 321, 332, 335, 336, 338], "group_siz": [319, 332, 524], "pooled_s": 319, "output_dim": [319, 332], "spatial_scal": [319, 332, 335, 336, 337, 338], "h_out": [319, 344, 411, 412, 413, 414, 415, 416, 417, 418], "w_out": [319, 344, 411, 412, 413, 414, 415, 416, 417, 418], "spread": 319, "bilinear_deform": 319, "hi": 319, "spatial_bins_x": [319, 332], "spatial_bins_i": [319, 332], "trans_std": 319, "offest": 319, "magnitud": [319, 524], "part_siz": 319, "n_in": 319, "h_in": 319, "w_in": 319, "num_roi": [319, 326, 335, 336, 337, 338], "num_class": [319, 320, 321, 322, 451, 452, 453, 454, 455, 456, 457, 458, 459], "0625": 319, "882": 319, "7938": 319, "392": 319, "yield": [320, 321, 355, 431, 461, 502, 541, 564], "kmn": [320, 321], "background_label_id": [320, 321], "variance_encoded_in_target": [320, 321], "share_loc": [320, 321], "nms_threshold": [320, 321, 322, 323, 326], "confidence_threshold": [320, 321], "decrease_label_id": [320, 321], "input_height": [320, 321, 349], "input_width": [320, 321, 349], "objectness_scor": [320, 321], "num_prior_box": [320, 321], "num_loc_class": [320, 321], "priors_batch_s": [320, 321], "prior_box_s": [320, 321], "019999999552965164": [320, 321], "44999998807907104": [320, 321], "5376": [320, 321], "2688": [320, 321], "detectionoutput_1": 321, "cls_pred_shap": 321, "x1_new": 322, "ctr_x": 322, "dx": [322, 326, 544], "d_log_w": 322, "max_delta_log_wh": 322, "box_w": 322, "y0_new": 322, "ctr_y": 322, "dy": [322, 326], "d_log_h": 322, "box_h": 322, "y1_new": 322, "x1": [322, 340, 341, 455, 456, 457, 458, 459], "x0": [322, 341], "y1": [322, 455, 456, 457, 458, 459], "y0": 322, "deltas_tensor": 322, "roi_idx": 322, "class_idx": 322, "deltas_weight": 322, "class_agnostic_box_regress": 322, "post_nms_count": [322, 323, 326], "max_detections_per_imag": 322, "maxim": [322, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 471, 497, 502, 567], "number_of_roi": [322, 325, 450], "image_height": [322, 323, 324, 326, 327, 328, 329, 330, 331, 346, 351], "image_width": [322, 323, 324, 326, 327, 328, 329, 330, 331, 346, 351], "scale_height_and_width": [322, 323, 326, 330, 331], "135166645050049": 322, "81": [322, 333, 375, 502], "2000": 322, "05000000074505806": 322, "324": 322, "highest": [323, 326, 330, 331, 368, 450, 452, 453, 454, 455, 456, 457, 458, 459, 504, 519, 524, 539], "pre_nms_count": [323, 326], "number_of_channel": [323, 324, 325], "fourth": [323, 377, 378, 398, 441, 536, 559], "699999988079071": [323, 326], "12600": 323, "grid": [324, 327, 328, 329, 344, 395], "centr": 324, "featmap_height": 324, "featmap_width": 324, "layer_height": 324, "layer_width": 324, "stride_h": 324, "stride_w": 324, "stride_x": 324, "stride_i": 324, "number_of_prior": 324, "42": [324, 325, 327, 328, 333, 375], "1344": [324, 325], "3150": 324, "pyramid": 325, "inputpyramid": 325, "pyramidlevelmapp": 325, "canon": 325, "output_s": [325, 327, 328, 329, 411, 412], "sampling_ratio": [325, 335, 336, 337], "roi_width": [325, 335, 336, 337, 338], "output_width": [325, 349], "likewis": 325, "pyramid_scal": 325, "enlist": 325, "layer_s": 325, "largest": [325, 348, 349, 416, 417, 461], "math": [325, 328, 349, 408], "reorder": [325, 382, 400, 543], "336": 325, "168": 325, "bbox": 326, "adaptive_nms_threshold": 326, "nms_eta": [326, 452, 453], "adaptive_threshold": [326, 452, 453], "rpnroisnum": 326, "eta": [326, 452, 453], "roi_num_typ": 326, "num_batch": [326, 331, 451, 452, 453, 454, 455, 456, 457, 458, 459], "scale_height": [326, 330, 331], "scale_width": [326, 330, 331], "number_of_anchor": 326, "xmin": [326, 327, 328, 329, 451, 452, 453], "ymin": [326, 327, 328, 329, 451, 452, 453], "xmax": [326, 327, 328, 329, 451, 452, 453], "ymax": [326, 329, 451, 452, 453], "boxesdelta": 326, "dw": 326, "dh": 326, "rpnroi": 326, "rpnscore": 326, "aspect": [327, 328], "center_x": [327, 328, 329, 337], "center_i": [327, 328, 329, 337], "equiv": [327, 328, 329], "_size": [327, 328], "max_siz": [327, 328], "aspect_ratio": [327, 328], "scale_all_s": [327, 328], "fixed_ratio": [327, 328], "fixed_s": [327, 328], "densiti": [327, 328], "t_int": [327, 328, 329, 370, 383, 384, 444, 445], "priors_per_point": [327, 328, 329], "672": [327, 328], "16128": [327, 328], "min_max_aspect_ratios_ord": 328, "preced": [328, 367], "_width": 329, "_height": 329, "overlin": [329, 448], "width_": 329, "height_": 329, "recalcul": 329, "step_w": 329, "step_h": 329, "neighborhood": 329, "142": 329, "6840": 329, "foreground": [330, 331], "bbox_delta": 330, "intersect": [330, 331, 452, 453, 454, 455, 456, 457, 458, 459], "union": [330, 331, 452, 453, 454, 455, 456, 457, 458, 459], "_thresh": [330, 331], "box_size_scal": [330, 331], "box_coordinate_scal": [330, 331], "7000": 331, "2nd": [332, 347, 348, 349, 369, 371, 372, 376, 463], "3240": 332, "yolo9000": 333, "stronger": 333, "paper": [333, 341, 361, 362, 419, 433, 435, 542], "flat_dim": 333, "135": 333, "344": 333, "319": 333, "21125": 333, "reorgan": 334, "reorg": 334, "uniform": [335, 336, 337, 338, 341, 518, 553], "pooled_h": [335, 336, 337, 338], "pooled_w": [335, 336, 337, 338], "cei": 335, "roi_height": [335, 336, 337, 338], "malform": [335, 336, 338], "ind_t": [335, 336, 337], "aligned_mod": 336, "resized_shap": 336, "original_shap": 336, "x_origin": [336, 349], "half_pixel_for_nn": 336, "half_pixel": [336, 348, 349], "rotat": [337, 454], "clockwise_mod": 337, "regularli": 337, "closest": 337, "achiv": 337, "bin_points_h": 337, "bin_points_w": 337, "clockwis": [337, 454], "counterclockwis": [337, 454], "062500": 338, "matric": [339, 368, 369, 560], "diagon": [339, 367, 368, 451, 455, 456, 457, 458, 459], "everywher": 339, "diagonal_index": 339, "num_row": 339, "num_column": 339, "batch_shap": 339, "t_num": 339, "prob": [340, 505, 506, 508, 509, 545], "randomli": [340, 502, 511, 512, 545], "mathbb": 340, "x2": [340, 455, 456, 457, 458, 459], "xn": 340, "log_prob": 340, "cdf": 340, "ith": 340, "xi": 340, "ascend": [340, 401, 451, 452, 453, 460, 461, 462], "with_replac": 340, "afterward": [340, 408], "convert_typ": 340, "num_sampl": 340, "36": [340, 375, 377, 378, 502, 540], "5184705528587072464087": 340, "1318815734": 340, "07": [340, 524], "5184705528587072464090": 340, "5184705528588391279824": 340, "class_siz": 340, "unnorm": 340, "global_se": [340, 341], "seed": [340, 341], "op_se": [340, 341], "t_sampl": 340, "draw": [340, 508], "234": [340, 341, 502], "148": [340, 341], "minval": 341, "maxval": 341, "underli": [341, 534, 566, 567, 571], "philox": 341, "pseudo": [341, 440, 544], "determinist": 341, "4x32_10": 341, "_to": 341, "_uint32": 341, "cast_to_uint32": 341, "mullo": 341, "mulhi": 341, "oplu": [341, 366], "l_": 341, "0xd2511f53": 341, "0xcd9e8d57": 341, "0x9e3779b9": 341, "0xbb67ae85": 341, "expon": [341, 407, 419], "mantissa": [341, 419, 468, 542], "x_uint16": 341, "val": [341, 342, 343], "0x3ffu": 341, "0x7fffffu": 341, "1023": 341, "concatin": 341, "mantissa_h": 341, "0xfffffu": 341, "mantissa_l": 341, "7011236": 341, "30539632": 341, "93931055": 341, "9456035": 341, "11694777": 341, "50770056": 341, "5197197": 341, "22727466": 341, "991374": 341, "65927959": 341, "23122376": 341, "67008206": 341, "36423758": 341, "t_shape": [341, 372, 411, 412, 441], "accumulate_typ": 343, "fp64": 343, "toward": [343, 387, 388, 542], "conceptu": 344, "denorm": [344, 551], "align_corn": [344, 347, 348, 349], "extrema": 344, "border": 344, "inher": [344, 497, 502, 555, 556, 562, 566], "bicub": 344, "padding_mod": 344, "repeatedli": [344, 502, 535], "i420": [345, 346, 544], "720": [345, 346, 350, 351, 559], "480": [345, 346, 350, 351, 557, 560], "yuv": [346, 351, 506, 558, 560], "596": [346, 351], "813": [346, 351], "391": [346, 351], "018": [346, 351], "shall": [346, 351, 555, 557, 560], "nyxc": [346, 351], "5x": [346, 351], "bigger": [346, 351, 354, 369, 468], "target_spatial_shap": 347, "cubic": [347, 348, 349], "antialia": [347, 348, 349], "anti": [347, 348, 349], "pads_beg": 347, "linear_onnx": [348, 349], "bilinear_pillow": 348, "bicubic_pillow": 348, "shape_calculation_mod": [348, 349], "scales_or_s": 348, "coordinate_transformation_mod": [348, 349], "x_resiz": [348, 349], "pytorch_half_pixel": [348, 349], "tf_half_pixel_for_nn": [348, 349], "nearest_mod": [348, 349], "round_prefer_floor": [348, 349], "round_prefer_ceil": [348, 349], "smallest": [348, 349, 461], "downsampl": [348, 349, 415, 416, 417], "antialias": 348, "cube_coeff": [348, 349], "t_scale": [348, 349], "t_size": [348, 349, 446, 447, 448, 449], "t_ax": [348, 349], "unord": [348, 349, 446, 447, 448, 449], "enum": 349, "getnearestpixel": 349, "prefer_floor_func": 349, "prefer_ceil_func": 349, "floor_func": 349, "ceil_func": 349, "simple_func": 349, "is_downsampl": 349, "getoriginalcoordin": 349, "half_pixel_func": 349, "pytorch_half_pixel_func": 349, "asymmetric_func": 349, "tf_half_pixel_for_nn_func": 349, "align_corners_func": 349, "x_scale": 349, "length_res": 349, "length_origin": 349, "get_cubic_coeff": 349, "coeff": 349, "triangle_coeff": 349, "dz": 349, "shapecalculationmod": 349, "interpolatecalcul": 349, "nearest_interpol": 349, "linear_interpol": 349, "cubic_interpol": 349, "onnx_linear_interpol": 349, "get_original_coordin": 349, "get_coordinate_transformation_mod": 349, "get_nearest_pixel": 349, "shape_inf": 349, "enumer": [349, 539, 543, 546, 548], "correct_pad": 349, "pad_len": 349, "astyp": 349, "ndim": 349, "padded_data": 349, "num_of_ax": 349, "all_scal": 349, "clip_coord": 349, "ndindex": [349, 390], "input_coord": 349, "cubic_coeff": 349, "in_coord": 349, "in_coord_int": 349, "summa": 349, "coords_for_sum": 349, "coeffs_prod": 349, "prod_of_a": 349, "icoord": 349, "float64": 349, "icoords_r": 349, "wsum": 349, "inner_coord": 349, "onnx_linear_interpolation5d": 349, "reshaped_data": 349, "num_channel": 349, "input_depth": 349, "output_depth": 349, "output_height": 349, "depth_scal": 349, "height_scal": 349, "width_scal": 349, "z_origin": 349, "y_origin": 349, "in_z1": 349, "in_z2": 349, "in_y1": 349, "in_y2": 349, "in_x1": 349, "in_x2": 349, "dz1": 349, "dz2": 349, "dy1": 349, "dy2": 349, "dx1": 349, "dx2": 349, "in_z": 349, "in_i": 349, "in_x": 349, "x111": 349, "x211": 349, "x121": 349, "x221": 349, "x112": 349, "x212": 349, "x122": 349, "x222": 349, "temp": [349, 516], "onnx_linear_interpolation4d": 349, "x11": 349, "x21": 349, "x12": 349, "x22": 349, "nearest_pixel": 349, "nv12": [350, 351, 501, 543], "uv": [350, 351, 544, 560], "variable_id": [352, 353, 357, 358, 569], "reset": [352, 353, 357, 358, 361, 362, 500, 569], "new_valu": [352, 353], "lstm_state_1": [352, 353, 357, 358], "coher": [353, 358], "recurr": [355, 360, 361, 362, 432, 433, 434, 435, 436, 438, 439], "trip": 355, "trip_count": 355, "whenev": [355, 398, 451, 452, 453, 455, 456, 457, 458, 459, 543, 556, 569], "back_edg": [355, 360], "executioncondit": 355, "current_iter": 355, "execution_condit": 355, "u4": [356, 358], "i4": [356, 358], "init_valu": [357, 358], "stateapi": 358, "variable_shap": 358, "variable_typ": 358, "unrol": [360, 570], "partit": [360, 572], "si": 360, "3145728": 360, "768": [360, 433, 446, 447, 448, 449], "3145744": 360, "hidden_s": [360, 361, 362, 433, 434, 435, 436, 438, 439], "3149840": 360, "auaugrucel": 361, "augru": [361, 362], "gate": [361, 362, 433, 434, 435, 436, 438, 439], "arxiv": [361, 362, 406], "1809": [361, 362], "03672": [361, 362], "hadamard": [361, 362, 433, 435], "rt": [361, 362, 433], "xt": [361, 362, 433, 435, 438], "wr": [361, 362, 433], "ht": [361, 362, 433, 435, 438], "rr": [361, 362, 433], "wbr": [361, 362, 433], "rbr": [361, 362, 433], "zt": [361, 362, 433], "wz": [361, 362, 433], "rz": [361, 362, 433], "wbz": [361, 362, 433], "rbz": [361, 362, 433], "wh": [361, 362, 433], "rh": [361, 362, 433, 477], "rbh": [361, 362, 433], "wbh": [361, 362, 433], "linear_before_reset": [361, 362, 433, 434], "activations_alpha": [361, 362, 433, 434, 435, 436, 438, 439], "activations_beta": [361, 362, 433, 434, 435, 436, 438, 439], "input_s": [361, 362, 433, 434, 435, 436, 438, 439], "h_t": [361, 362], "zrh": [361, 362, 433, 434], "ho": [361, 362, 433, 434, 435, 436, 438, 439], "num_direct": [362, 434, 436, 439], "wedg": 363, "lnot": 364, "lor": 365, "einstein": 367, "operand": 367, "algebra": 367, "inputn": 367, "alphabet": [367, 516, 559], "letter": [367, 540, 559], "capit": 367, "forth": [367, 545], "bcd": 367, "bc": 367, "ca": 367, "abcd": 367, "aac": 367, "abd": 367, "ddde": 367, "ijkj": 367, "ij": 367, "a1": 367, "a2": 367, "kii": 367, "ki": 367, "ijk": 367, "kij": 367, "multidirect": 367, "recov": 367, "hand": [367, 494, 497, 533, 566, 568], "dbbc": 367, "recoveri": 367, "abc": 367, "acb": 367, "blank": [367, 431, 432], "0020": 367, "ac": 367, "adjoint": 368, "conjug": 368, "invert": [368, 400, 524], "theorem": 368, "slightli": [368, 475, 524, 563], "adjug": 368, "adj": 368, "det": 368, "lu": 368, "pivot": 368, "triangular": [368, 451], "spot": 368, "x_n": 368, "col_i": 368, "iff": 368, "pseudocod": [368, 382], "neq": 368, "swap": [368, 369, 398], "elimin": [368, 451, 452, 453, 529], "ly": [368, 394], "substitut": [368, 499], "ux": 368, "b1": [368, 454], "b2": [368, 454], "bn": 368, "col": 368, "batch_dim_1": 369, "batch_dim_2": 369, "batch_dim_k": 369, "row_index_dim": 369, "col_index_dim": 369, "transposit": [369, 371, 372], "transpose_a": 369, "transpose_b": 369, "block_shap": [370, 395], "crops_begin": 370, "crops_end": 370, "d_1": [370, 392, 395, 446, 447, 448], "d_2": [370, 395], "d_": [370, 392, 395, 411, 412, 446, 447, 448], "b_1": [370, 395], "prime": 370, "b_2": [370, 395], "cb_1": 370, "ce_1": 370, "cb_2": 370, "ce_2": 370, "cb_": 370, "ce_": 370, "b_0": [370, 395, 446, 447, 448, 449, 452, 453, 454, 455, 459], "cb_i": 370, "ce_i": 370, "cb_0": 370, "ce_0": 370, "d_i": 370, "evenli": [370, 374, 393, 396, 397, 415, 417, 418, 564], "replic": [371, 372, 399], "3rd": [371, 372, 437, 463, 464], "axes_map": [371, 372], "axis_map": [371, 372], "shouldn": [371, 372, 383], "taget_shap": 371, "fly": [371, 372, 471, 498, 510, 541, 564], "behaviour": [372, 432, 571], "d2": [373, 374, 396], "d_axi": 373, "rearrang": [374, 396, 502, 505, 508, 509], "dk": [374, 396], "blocks_first": [374, 396], "block_siz": [374, 396], "d3": 374, "depth_first": [374, 396], "new_depth": 374, "size_row": 375, "size_col": 375, "stride_row": 375, "stride_col": 375, "rate_row": 375, "rate_col": 375, "far": [375, 534], "patch_sizes_eff": 375, "patch_siz": 375, "subsampl": [375, 394], "in_row": 375, "in_col": 375, "out_row": 375, "out_col": 375, "bmatrix": 375, "79": [375, 502], "98": [375, 502, 508, 524], "51": [375, 449, 502, 557], "p_0": [376, 377, 378, 395], "p_1": [376, 377, 378, 395], "i_b": [377, 378], "i_": [377, 378, 380, 381, 408, 409], "batch_dim": [377, 378, 380, 381, 533], "indices_shap": [377, 378], "data_shap": [377, 378, 386, 393, 395, 448, 449, 502], "exce": [378, 452, 453, 454, 455, 456, 457, 458, 459, 527], "lesser": 379, "i_0": [380, 381, 390, 391, 392], "gathernd_8": 380, "sixth": [380, 381], "step_id": 382, "parent_id": 382, "past": [382, 497], "end_token": 382, "final_id": 382, "beam_width": 382, "max_sequence_in_beam": 382, "max_tim": 382, "max_seq_len": 382, "marker": 382, "untouch": 385, "batch_axi": 386, "seq_axi": 386, "compris": [386, 548, 554], "t_ind_1": 387, "t_ind_2": 387, "n_dim": 387, "use_init_v": 388, "264": 388, "scatter_nd_update_15": 390, "ndidx": 390, "4x4": [390, 391], "i_j": [390, 391], "i_1": [390, 391, 392], "i_k": [390, 391, 392], "s_j": [390, 391], "3600": 390, "d_0": [392, 395, 446, 447, 448], "d_n": 392, "forall_": 392, "t_numer": 392, "400": 393, "vertex": 394, "int_max": 394, "int_min": 394, "interleav": 395, "p_2": 395, "p_i": 395, "_output": [397, 402], "_tensor": [397, 402], "dotsc": [397, 402, 403, 404], "_split": 397, "_mask": 398, "_axi": 398, "bitmask": 398, "necessarili": [398, 556, 571], "_index": 398, "handsid": 398, "till": 398, "newaxi": [398, 500], "keepdim": 398, "unaffect": 398, "concis": 398, "flexibl": [398, 493, 497, 536, 567], "condens": 398, "10d": 398, "opeart": 398, "begin_mask": 398, "end_mask": 398, "new_axis_mask": 398, "shrink_axis_mask": 398, "ellipsis_mask": 398, "6d": 398, "1234": 398, "4321": 398, "9876": 398, "241": 398, "unequ": 398, "penultim": 398, "promot": [399, 468], "out_i": 399, "input_i": 399, "inner_dim": 399, "input_ord": 400, "subtensor": 401, "index_element_typ": [401, 412, 416, 417, 460, 461, 462], "count_element_typ": 401, "ascendingli": [401, 461], "xdim": 401, "variad": 402, "split_length": 402, "_length": 402, "covari": [403, 404], "epsilon": [403, 404, 406, 408, 409], "gamma": [403, 404], "mini": [403, 404], "mathcal": [403, 404], "bn_": [403, 404], "mu_": [403, 404, 408], "leftarrow": [403, 404], "sigma_": [403, 404, 408], "span": [403, 404], "99e": [403, 404], "l2": [405, 410, 422, 516, 524], "i0": [405, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429], "i1": [405, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 460, 461, 462], "iN": [405, 410, 421, 422, 423, 424, 425, 426, 427, 428, 429, 460, 461, 462], "1803": 406, "08494": 406, "num_group": 406, "data_": 407, "sqr_sum": 407, "0e": 407, "across_channel": 408, "nc": [408, 502], "reduction_ax": 408, "normalize_vari": [408, 409], "ep": [408, 409, 410], "001": 408, "eps_mod": [409, 410], "inside_sqrt": 409, "outside_sqrt": 409, "j0": [410, 421, 422, 423, 424, 425, 426, 427, 428, 429], "jn": [410, 421, 422, 423, 424, 425, 426, 427, 428, 429], "jk": [410, 421, 422, 423, 424, 425, 426, 427, 428, 429], "ik": [410, 421, 422, 423, 424, 425, 426, 427, 428, 429], "lcl": [411, 412], "h_": [411, 412], "d_out": [411, 412, 413, 414, 415, 416, 417, 418], "strategi": [413, 414, 565, 567], "came": [413, 414], "output_": 413, "ceil_torch": [414, 416, 418], "biggest": [415, 460, 462], "pads_valu": [416, 417], "output1": [417, 418], "wchich": 418, "destination_typ": [419, 466, 467], "f8e4m3": [419, 468], "f8e5m2": [419, 468], "fp8": 419, "t_f": [419, 420, 430, 431, 432], "broadcast_rul": 420, "l1": [421, 516], "keep_dim": [421, 422, 423, 424, 425, 426, 427, 428, 429], "prod_": [430, 432], "c_": 430, "sequence_mask": 430, "sequence_mass": 430, "last_sequence_symbol": 430, "ctc_merge_rep": [430, 432], "blank_index": [430, 431, 432], "ctc": [430, 431, 432], "shorter": [430, 563], "merge_rep": 431, "abb": 431, "abbbb": 431, "abbb": 431, "classes_index_typ": 431, "sequence_length_typ": 431, "t_i": 431, "t_ind1": 431, "t_ind2": 431, "connectionist": 432, "tempor": 432, "unseg": 432, "grave": 432, "et": [432, 451, 455, 459], "al": [432, 451, 455, 459], "likelihood": 432, "briefli": 432, "logit_length": 432, "label_length": 432, "c1": 432, "c2": 432, "g1": 432, "g2": 432, "substr": 432, "preprocess_collapse_rep": 432, "l_i": 432, "primarili": [432, 524, 541, 548], "underflow": [432, 542], "overflow": 432, "wherein": 432, "followint": 433, "initial_hidden_st": [433, 434, 435, 436], "ot": 435, "wi": [435, 438], "ri": [435, 438], "wbi": [435, 438], "rbi": [435, 438], "ft": 435, "wf": 435, "rf": [435, 496], "wbf": 435, "rbf": 435, "wc": 435, "rc": 435, "wbc": 435, "rbc": 435, "wo": 435, "ro": [435, 548], "wbo": 435, "rbo": 435, "initial_cell_st": [435, 436], "fico": [435, 436], "on_valu": 437, "off_valu": 437, "4nd": 437, "hot": [437, 540], "attn_mask": 440, "attn_bia": 440, "attn_weight": 440, "attention_mask": [440, 499, 500], "ev": 440, "signal": [440, 446, 447, 448, 449, 571], "285": [440, 506], "scaled_dot_product_attention_0": 440, "n3": 440, "287": 440, "special_zero": 441, "overal": [441, 518, 519, 542, 549, 550, 552, 555, 556, 561, 566, 567], "fourier": 446, "imaginari": [446, 447, 448], "signal_s": [446, 447, 448, 449], "trim": [446, 447, 448, 449, 570], "simplic": [446, 447, 448, 449, 477, 478, 479, 525], "m_0": [446, 447, 448, 449], "s_0": [446, 447, 448, 449, 452, 453, 454, 455, 459], "s_": [446, 447, 448, 449], "j_0": [446, 447, 448, 449], "j_k": [446, 447, 448, 449], "n_0": [446, 447, 448, 449], "limits_": [446, 447, 448, 449], "m_qj_q": [446, 447], "s_q": [446, 447], "im": [446, 447], "unsort": [446, 447, 448, 449], "580": [446, 447, 448, 449], "258": [446, 447, 448, 449], "2056": [446, 447, 448, 449], "s_1": [448, 449], "s_a": [448, 449], "normalized_ax": [448, 449], "j_p": 448, "m_p": 448, "m_a": 448, "s_b": [448, 449], "m_bj_b": [448, 449], "161": [448, 449], "513": 449, "1029": 449, "descend": [450, 451, 452, 453, 460, 461, 462], "max_roi": 450, "number_of_input_roi": 450, "5000": 450, "decai": 451, "wang": 451, "background_class": [451, 452, 453], "post_threshold": 451, "pairwis": 451, "iou": [451, 452, 453, 454, 455, 456, 457, 458, 459], "intersectionoverunion": 451, "x_cmax": 451, "decay_factor": 451, "gaussian_sigma": 451, "decay_funct": 451, "sort_result": [451, 452, 453], "sort_result_across_batch": [451, 452, 453], "selected_indic": [451, 452, 453, 454, 455, 456, 457, 458, 459], "valid_output": [451, 452, 453, 454, 455, 459], "selected_output": [451, 452, 453], "box_scor": [451, 452, 453, 454, 455, 459], "selected_num": [451, 452, 453], "b_n": [452, 453, 454, 455, 459], "s_n": [452, 453, 454, 455, 459], "iou_threshold": [452, 453, 454, 455, 456, 457, 458, 459], "s_i": [452, 453, 454, 455, 459], "roisnum": 453, "rotated_i": 454, "intersection_point": 454, "intersection_area": 454, "polygon": 454, "sholeac": 454, "union_area": 454, "b1_area": 454, "b2_area": 454, "max_output_boxes_per_class": [454, 455, 456, 457, 458, 459], "sort_result_descend": [454, 455, 456, 457, 458, 459], "x_center": [454, 455, 456, 457, 458, 459], "y_center": [454, 455, 456, 457, 458, 459], "t_max_box": [454, 455, 457, 458, 459], "t_threshold": [454, 455, 457, 458, 459], "triplet": [454, 455, 456, 457, 458, 459, 488], "batch_index": [454, 455, 456, 457, 458, 459], "class_index": [454, 455, 456, 457, 458, 459], "box_index": [454, 455, 456, 457, 458, 459], "selected_scor": [454, 455, 459], "soft_nms_sigma": [455, 459], "box_encod": [455, 456, 457, 458, 459], "y2": [455, 456, 457, 458, 459], "soft": [455, 459], "bodla": [455, 459], "output_valu": 461, "output_indic": 461, "gthat": 461, "bag": [463, 464, 465], "embeddingbag": [463, 464], "emb_tabl": [463, 464, 465], "lookup": [463, 464, 465], "num_emb": [463, 464, 465], "emb_dim1": [463, 464, 465], "emb_dim2": [463, 464, 465], "num_indic": [463, 465], "default_index": [463, 465], "per_sample_weight": [463, 464, 465], "per_sample_weigth": [463, 464, 465], "indices_per_bag": 464, "segments_id": 465, "num_seg": 465, "141592": [466, 467], "notabl": 466, "congruent": 466, "294": 466, "967": 466, "295": 466, "input_0": 468, "promote_unsaf": 468, "pytorch_scalar_promot": 468, "unexpect": 468, "widen": 468, "i128": 468, "u64_integer_promotion_target": 468, "lhs_type": 468, "rhs_type": 468, "promoted_common_typ": 468, "iee": 468, "754": [468, 542], "f8m4e3": 468, "f8m5e3": 468, "f8": 468, "unsaf": 468, "decrypt": 470, "authent": 470, "parti": [470, 500, 542], "openssl": 470, "guard": [470, 572], "sgx": 470, "secret": 470, "welcom": 471, "quickli": [471, 502, 518, 524, 525], "cluster": [471, 572], "anywher": [471, 493, 497, 539], "arbitrarili": [471, 536], "formerli": [472, 547], "gthub": 472, "770": 473, "i915": 473, "dkm": 473, "xpu": 473, "smi": 473, "tm": [473, 496, 507, 548], "icd": [473, 482, 496], "deb": [473, 476], "ocl": [473, 482, 496, 543, 544], "libopencl1": 473, "gpg": [473, 476, 490], "agent": 473, "dearmor": 473, "keyr": [473, 476], "echo": [473, 476, 504], "arch": 473, "focal": 473, "tee": [473, 476, 490], "ubi": [473, 496], "yum": [473, 475, 477, 484, 492, 496, 504], "igc": [473, 496], "cm": [473, 496], "gmmlib": [473, 496], "ocloc": 473, "rpm": [473, 490, 491, 496, 514], "ivh": [473, 496], "mirror": [473, 492, 496], "appstream": [473, 496], "el8": [473, 496], "arrow": 473, "9955": 473, "powershel": [473, 479, 504, 549], "wsl2": [473, 483], "shutdown": [473, 496], "drx": 473, "dri": 473, "ci": [473, 483, 496, 514], "dockerfil": [473, 483, 496, 514], "consol": [474, 494, 501], "797": 474, "193201": 474, "drm": 474, "intel_vpu": 474, "0000": 474, "0b": 474, "multimedia": 474, "zypper": [475, 484], "homebrew": [475, 484, 485, 496], "vcpkg": [475, 484, 485, 489], "conan": [475, 484, 485, 489], "pub": [476, 490, 496], "gnupg": 476, "ubuntu22": [476, 477], "ubuntu20": [476, 477], "ubuntu18": [476, 477], "ve": [476, 477, 478, 479, 480, 482, 486, 487, 488, 490, 491], "build_sampl": [476, 490, 491, 504], "hello_query_devic": [476, 507, 538, 543], "autoremov": [476, 490], "glanc": [476, 490, 491], "debian9": 477, "armhf": [477, 504], "centos7": 477, "rhel8": 477, "rhel": [477, 490, 496], "devtoolset": 477, "scl": 477, "epel": [477, 496], "keyboard": 477, "alt": 477, "administr": [477, 479], "userspac": 477, "user_hom": [477, 478, 479], "l_openvino_toolkit_ubuntu22_2024": 477, "15008": [477, 478, 479], "f4afc983258_x86_64": [477, 478, 479], "tgz": [477, 478], "openvino_2024": [477, 478, 479], "xf": [477, 478, 479], "l_openvino_toolkit_ubuntu20_2024": 477, "l_openvino_toolkit_ubuntu18_2024": 477, "l_openvino_toolkit_rhel8_2024": 477, "l_openvino_toolkit_centos7_2024": 477, "f4afc983258_arm64": [477, 478], "l_openvino_toolkit_debian9_2024": 477, "f4afc983258_armhf": 477, "install_depend": 477, "install_openvino_depend": 477, "unlink": [477, 478], "install_dir": [477, 478, 479, 492, 504, 549], "throughout": [477, 478, 479], "temporarili": [477, 478, 479], "bashrc": [477, 492], "favorit": [477, 478, 479, 541, 556], "extracted_fold": [477, 478, 479], "path_to_arch": [477, 478, 479], "m_openvino_toolkit_macos_12_6_2024": 478, "zshrc": 478, "msbuild": 479, "desktop": [479, 496], "msi": 479, "wizard": 479, "environment": 479, "privileg": 479, "w_openvino_toolkit_windows_2024": 479, "sha256": 479, "certutil": 479, "hashfil": 479, "ticket": 479, "ren": 479, "mklink": 479, "ps1": [479, 504, 549], "bat": [479, 504, 516, 549], "rmdir": [479, 496], "brew": [480, 496], "thing": [480, 488, 490, 491, 544, 555, 557, 568], "conanfil": 481, "cmakedep": 481, "cmaketoolchain": 481, "cmake_layout": 481, "conan_toolchain": 481, "enable_intel_gpu": 481, "enable_onnx_frontend": 481, "dcmake_toolchain_fil": [481, 488], "py310": 482, "cxx": 482, "env": [482, 496, 540], "ld_library_path": 482, "conda_prefix": 482, "reactiv": 482, "linkag": 482, "exectuion": 483, "quai": [483, 496], "subsystem": 483, "membership": 483, "openshift": [483, 496], "opendata": 483, "scienc": [483, 491, 496], "rhod": 483, "toolset": 483, "available_devic": [487, 492, 507, 539, 542, 543, 547, 548], "x64": [488, 497, 516], "vcpkg_root": 488, "buildsystem": 488, "amazon": [490, 496], "rocki": 490, "alma": 490, "oracl": 490, "fedora": [490, 496], "openeul": 490, "anoli": 490, "eof": 490, "baseurl": 490, "gpgcheck": 490, "repo_gpgcheck": 490, "gpgkei": 490, "repolist": 490, "addrepo": 491, "opensuse_tumblewe": 491, "refresh": [491, 496], "lr": 491, "se": 491, "devel": [491, 496], "china": 492, "aliyun": 492, "get_vers": 492, "vv": 492, "beginn": 492, "premis": 493, "cheat": 493, "sheet": 493, "love": 493, "perfmorm": 493, "kubernet": 493, "discoveri": 493, "lighter": 493, "accommod": [494, 524, 541, 564], "experienc": 494, "binder": 495, "colab": 495, "scm": 496, "redistribut": 496, "python36": 496, "mesa": 496, "libgl": 496, "bash": [496, 541], "fssl": 496, "azur": 496, "ml": 496, "8gb": 496, "caption": [496, 529], "openvino_notebook": 496, "thoth": 496, "station": 496, "s2i": 496, "ubi8": 496, "py38": 496, "helena": 496, "kloosterman": 496, "jupyter_enable_lab": 496, "enable_micropipenv": 496, "upgrade_pip_to_latest": 496, "web_concurr": 496, "thoth_advis": 496, "thoth_error_fallback": 496, "thoth_dry_run": 496, "thamos_debug": 496, "thamos_verbos": 496, "thoth_provenance_check": 496, "nodej": 496, "dos2unix": 496, "sl": 496, "nodesourc": 496, "setup_14": 496, "libsndfil": 496, "sec": 496, "moder": [496, 567], "dnf": 496, "vault": 496, "filesystem": [496, 527], "23726": 496, "i419": 496, "media": [496, 505, 506, 508, 509, 543], "mediasdk": 496, "libmfxgen1": 496, "libvpl2": 496, "libva": 496, "ib01": 496, "fedoraproject": 496, "clinfo": 496, "assembl": 496, "patch_notebook": 496, "validate_notebook": 496, "ignore_treon_dock": 496, "crlf": 496, "ownership": 496, "chown": 496, "lab": 496, "cmd": [496, 504, 549], "setuptool": 496, "anaconda": [496, 502], "8888": 496, "shm": 496, "8g": 496, "ipynb": 496, "sidebar": 496, "hit": [496, 541, 547, 564], "kernelspec": 496, "tip": [496, 543, 567], "feel": [496, 503, 511, 512], "broad": 497, "rapid": [497, 542], "fewer": [497, 525, 536], "gptq": [497, 498], "mpt": 497, "xl": [497, 498], "multimod": 497, "rotari": 497, "specul": 497, "stateless": [497, 569], "constrain": 497, "effort": [497, 518, 540, 541, 564], "prototyp": 497, "centric": 497, "paid": 497, "incur": 497, "cheaper": 497, "automodelforcausallm": 498, "ovmodelforcausallm": [498, 524], "model_id": [498, 500, 524], "hf": [498, 524, 525], "automodelforcasuallm": 498, "ovmodelforcasuallm": 498, "automodel": 498, "ovmodelforseq2seqlm": 498, "causallm": 498, "save_pretrain": [498, 524], "new_model_nam": 498, "ov_llama_2": 498, "llama_openvino": 498, "load_in_8bit": [498, 524], "optimized_model_path": 498, "billion": [498, 524], "ovweightquantizationconfig": 498, "quantization_config": 498, "asym": 498, "ptb": 498, "autotoken": [498, 500, 524], "weather": [498, 524], "return_tensor": [498, 525], "max_new_token": 498, "skip_special_token": 498, "insignific": 498, "manner": [498, 550, 572], "ov_config": 498, "performance_hint": [498, 502, 507, 556, 572], "downstream": 498, "baselin": [498, 519, 520, 524], "lora_adaptor": 498, "use_cach": 498, "peftmodelforcausallm": 498, "merge_and_unload": 498, "get_base_model": 498, "fused_lora_model": 498, "simplif": [499, 569], "invok": 499, "lora": 499, "openvino_llm": 499, "equip": [499, 541, 556], "convert_token": [499, 500], "llama2": [499, 532], "whoisharrypott": 499, "detoken": [499, 571], "openvino_model": 499, "compiled_token": 499, "compiled_detoken": 499, "openvino_detoken": [499, 500], "text_input": [499, 500], "brown": [499, 500], "fox": [499, 500], "ov_input": [499, 551], "li": 499, "new_tokens_s": 499, "prompt_siz": 499, "input_dict": 499, "any_nam": [499, 500], "hstack": [499, 500], "token_id": 499, "ov_token_id": 499, "ov_output": 499, "string_output": [499, 500], "forest": 499, "he": 499, "someth": 499, "textual": [499, 549, 571], "stringsplit": 500, "staticrexexpreplac": 500, "stringlow": 500, "wordpiec": 500, "unigram": 500, "sentencepiec": 500, "tiktoken": 500, "nightli": [500, 572], "dep": 500, "prebuild": 500, "linux_x86": 500, "intel64": [500, 502, 504, 515, 516], "linux_arm64": 500, "aarch64": [500, 504], "macos_x86": 500, "macos_arm64": 500, "libopenvino_token": 500, "dylib": 500, "user_ov_extens": 500, "bundl": 500, "pathlib": 500, "tokenizer_dir": 500, "ov_token": 500, "ov_detoken": 500, "hf_token": 500, "with_detoken": 500, "model_input": 500, "position_id": 500, "beam_idx": 500, "signifi": 500, "eos_token": 500, "eos_token_id_nam": 500, "tokens_result": 500, "reset_st": [500, 569], "max_inf": 500, "start_async": [500, 544, 549, 550, 552, 553, 555, 556], "output_token": 500, "get_output_tensor": [500, 550], "text_result": 500, "ascii": 501, "googlenet": [501, 504, 505, 509, 511, 512, 545], "shapeinf": 501, "async": [501, 502, 539, 549, 550, 554, 566], "focus": [502, 526, 554], "whichev": [502, 550], "overclock": 502, "thermal": 502, "model2": [502, 509], "modern": 502, "satur": [502, 515, 546, 564, 566, 567], "purposefulli": 502, "number_of_iter": [502, 570], "png": [502, 505], "path_to_input": 502, "test1": 502, "reconvert": [502, 505, 506, 508, 509], "pm": 502, "no_count": 502, "detailed_count": 502, "benchmark_no_counters_report": 502, "csv": [502, 516], "benchmark_average_counters_report": 502, "benchmark_detailed_counters_report": 502, "paths_to_input": 502, "target_devic": [502, 504, 522], "cumulative_throughput": [502, 546], "number_iter": 502, "path_to_cldnn_config": 502, "cdir": 502, "cache_dir": [502, 507, 542, 543, 547, 572], "lfile": 502, "load_from_fil": 502, "nireq": [502, 516], "number_infer_request": 502, "nstream": [502, 556], "number_stream": 502, "inference_onli": 502, "infer_precis": 502, "iop": 502, "input_output_precis": 502, "nthread": 502, "number_thread": 502, "NO": [502, 507, 540], "hybrid_awar": 502, "latency_percentil": 502, "pcsort": 502, "no_sort": 502, "simple_sort": 502, "pcseq": 502, "dump_config": 502, "load_config": 502, "file_1": 502, "dir1": 502, "file_2": 502, "dir2": 502, "input_4": 502, "file_4": 502, "dir4": 502, "input_2": 502, "file_3": 502, "dir3": 502, "npy": 502, "functionalityi": 502, "dib": 502, "jpe": 502, "jp2": 502, "pbm": 502, "pgm": 502, "ppm": 502, "sr": 502, "ra": 502, "tiff": 502, "tif": 502, "perf_hint": 502, "api_typ": 502, "dimes": 502, "448": 502, "device1": 502, "nstreams1": 502, "device2": 502, "nstreams2": 502, "although": [502, 524, 539, 541, 554, 555, 556, 567, 568], "input_precis": 502, "output_precis": 502, "quot": [502, 541, 570], "infer_threads_pin": 502, "percentil": 502, "median": [502, 511, 512, 541], "json_stat": 502, "perf_counts_sort": 502, "hotpoint": 502, "num_stream": [502, 507, 542, 543, 547, 556], "device_properti": 502, "inference_precision_hint": [502, 507], "input3": 502, "filll": 502, "separated_devices_list": 502, "ctput": [502, 541], "input4": 502, "absolute_path": 502, "cnnnetwork": 502, "dev1": 502, "dev2": 502, "asl": 502, "omz_model": 502, "benchmark_tool": 502, "7750": 502, "c1109a7317": 502, "py_cpp_align": 502, "took": [502, 541], "974": 502, "network_nam": 502, "optimal_number_of_infer_request": [502, 541, 546, 547, 548, 556, 566, 567], "inference_num_thread": [502, 507, 542], "performance_hint_num_request": [502, 507], "60000": 502, "5380": 502, "60036": 502, "989": 502, "5470": 502, "60028": 502, "portion": [502, 562, 569], "2811": 502, "60271": 502, "207": 502, "773": 502, "339": 502, "205": 502, "545": 502, "383": 502, "305": 502, "dyn": 502, "204": 502, "2783": 502, "60326": 502, "208": 502, "237": 502, "743": 502, "348": 502, "206": 502, "578": 502, "387": 502, "388": 502, "327": 502, "unlik": [503, 511, 512, 524, 536, 554], "enforc": [503, 542], "bert_benchmark": 503, "sample_dir": 504, "openvino_c_samples_build": 504, "openvino_cpp_samples_build": 504, "unam": 504, "path_to_build_directori": 504, "build_samples_msvc": 504, "processor_architectur": 504, "sln": 504, "proceed": [504, 549], "pexel": 504, "userprofil": 504, "openvino_samples_build": 504, "path_to_media": 504, "dog": [504, 509], "classification_sample_async": [504, 509], "classid": [504, 505, 506, 509, 510], "6875963": 504, "blenheim": 504, "spaniel": 504, "215": [504, 509], "0868125": 504, "brittani": 504, "218": [504, 509], "0784114": 504, "welsh": 504, "springer": 504, "212": [504, 509], "0597296": 504, "setter": 504, "217": [504, 509], "0212105": 504, "219": [504, 509], "0194193": 504, "cocker": 504, "247": 504, "0086272": 504, "saint": 504, "bernard": 504, "st": 504, "0058511": 504, "papillon": 504, "216": 504, "0057589": 504, "clumber": 504, "0052615": 504, "pekines": 504, "pekinges": 504, "peke": 504, "startup": [505, 506, 508, 509, 510, 543, 547, 558, 563], "path_to_imag": [505, 506, 508], "hello_classification_c": 505, "banana": [505, 508, 509], "car": [505, 506, 509], "954": [505, 509], "9703885": 505, "666": [505, 506, 509], "0219518": 505, "659": [505, 509], "0033120": 505, "435": [505, 506, 509], "0008246": 505, "809": [505, 509], "0004433": 505, "502": [505, 509], "0003852": 505, "618": [505, 509], "0002906": 505, "910": [505, 509], "0002848": 505, "951": [505, 509], "0002427": 505, "961": [505, 509], "0002213": 505, "656": [505, 506, 509], "8139648": 505, "654": [505, 506, 509], "0550537": 505, "468": 505, "0178375": 505, "436": [505, 506, 509], "0165405": 505, "705": [505, 509], "0111694": 505, "817": [505, 506], "0105820": 505, "581": [505, 506, 509], "0086823": 505, "575": 505, "0077515": 505, "734": [505, 509], "0064468": 505, "785": 505, "0043983": 505, "666479": 505, "112940": 505, "068487": 505, "874": [505, 506, 509], "033385": 505, "026132": 505, "016731": 505, "010980": 505, "511": [505, 506], "010592": 505, "569": [505, 506], "008178": 505, "717": [505, 506], "006336": 505, "pretti": [506, 509, 551], "hello_nv12_input_classif": 506, "hello_nv12_input_classification_c": 506, "uncompress": 506, "ffmpeg": 506, "gstreamer": 506, "pix_fmt": 506, "640x480": [506, 557, 560], "wherea": 506, "640x720": 506, "6668988": 506, "1125269": 506, "0679280": 506, "0340229": 506, "0257744": 506, "0169367": 506, "0110199": 506, "0106134": 506, "0083373": 506, "0061734": 506, "091733": 506, "876": 506, "081725": 506, "999": 506, "069305": 506, "587": 506, "043726": 506, "038957": 506, "419": 506, "032892": 506, "030309": 506, "700": 506, "029941": 506, "696": 506, "021628": 506, "855": 506, "020339": 506, "supported_properti": [507, 541, 542, 543, 547, 548], "i5": 507, "8350u": 507, "70ghz": 507, "optimization_cap": 507, "range_for_async_infer_request": [507, 542, 543, 547], "range_for_stream": [507, 542, 543, 547, 567], "import_export_support": 507, "dump_exec_graph_as_dot": 507, "0013": 508, "hello_reshape_ssd": 508, "test_data": [508, 509], "person_detect": 508, "276": 508, "210": 508, "render": 508, "rectangl": 508, "resmobnet_v4": 508, "lrelu": 508, "544": 508, "detection_out": 508, "960x1699": 508, "960": 508, "1699": 508, "716309": 508, "852": 508, "983": 508, "520": 508, "hello_reshape_ssd_output": 508, "ubyt": 509, "comma_separated_devices_list": 509, "9707602": 509, "0216788": 509, "0032558": 509, "0008082": 509, "0004359": 509, "0003860": 509, "0002867": 509, "0002866": 509, "0002410": 509, "0002193": 509, "5120340": 509, "1142275": 509, "0697167": 509, "0615163": 509, "0552262": 509, "0304179": 509, "0151660": 509, "0151582": 509, "627": 509, "0148493": 509, "757": 509, "0120964": 509, "8935547": 509, "0608215": 509, "0217133": 509, "0105667": 509, "0018835": 509, "0018730": 509, "152": 509, "0015745": 509, "0012817": 509, "0010099": 509, "model_creation_sampl": 510, "path_to_weights_fil": 510, "0000000": 510, "output_tensor": 510, "sens": 511, "0200": [511, 512], "sync_benchmark": 511, "2333": 511, "10003": 511, "233": 511, "992": 511, "15009": 511, "throughput_benchmark": 512, "2817": 512, "10012": 512, "281": 512, "1577": 512, "15024": 512, "quickest": 513, "prebuilt": 514, "debian": 514, "furthermor": [514, 536, 564], "grab": [514, 515], "openvino_c": [514, 515], "openvino_intel_cpu_plugin": [514, 515], "openvino_": 514, "_plugin": 514, "openvino_ir_frontend": [514, 515], "_frontend": 514, "linker": 515, "openvino_intel_gpu_plugin": 515, "openvino_arm_cpu_plugin": 515, "system32": 515, "libopencl": 515, "openvino_auto_plugin": 515, "openvino_hetero_plugin": 515, "openvino_batch_plugin": 515, "openvino_tensorflow_frontend": 515, "openvino_tensorflow_lite_frontend": 515, "openvino_onnx_frontend": 515, "openvino_paddle_frontend": 515, "openvino_pytorch_frontend": 515, "openvino_auto_batch_plugin": 515, "unnecessari": [516, 555], "particularli": [516, 546], "tradeoff": [516, 552], "lean": 516, "conditional_compilation_guid": 516, "conditional_compilation_developer_guid": 516, "selective_build": 516, "denable_profiling_itt": [516, 540], "ON": [516, 540, 551], "selective_build_stat": 516, "statistics_data": 516, "inact": 516, "submodul": [516, 522, 547, 572], "dselective_build": 516, "collector": 516, "sea_itt_lib": 516, "thirdparti": 516, "itt_collector": 516, "runtool": 516, "sea_runtool": 516, "bindir": 516, "openvino_library_dir": 516, "my_model_result": 516, "my_model": 516, "conditional_compil": 516, "ccheader": 516, "stat": 516, "csv_file": 516, "conditional_compilation_gen": 516, "tbb_bind_tbbbindsystemtopologi": 516, "tbb_bind_task_arena_initi": 516, "ov_opset_opset1_paramet": 516, "ov_opset_opset1_const": 516, "ov_opset_opset1_convolut": 516, "ov_opset_opset1_add": 516, "ov_opset_opset1_relu": 516, "ov_opset_opset1_groupconvolut": 516, "ov_opset_opset3_shapeof": 516, "ov_opset_opset1_squeez": 516, "ov_opset_opset4_rang": 516, "ov_opset_opset1_reducemean": 516, "ov_opset_opset1_softmax": 516, "ov_opset_opset1_result": 516, "ov_op_v0_parameter_visit_attribut": 516, "ov_op_v0_parameter_validate_and_infer_typ": 516, "ov_op_v0_parameter_clone_with_new_input": 516, "ov_op_v0_constant_visit_attribut": 516, "ov_op_v0_constant_clone_with_new_input": 516, "ov_op_v1_convolution_visit_attribut": 516, "ov_op_v1_convolution_validate_and_infer_typ": 516, "ov_op_v1_convolution_clone_with_new_input": 516, "ov_op_v0_util_binaryelementwisearithmetic_visit_attribut": 516, "ov_op_v1_add_visit_attribut": 516, "ov_op_v0_util_binaryelementwisearithmetic_validate_and_infer_typ": 516, "ov_op_v1_add_clone_with_new_input": 516, "ov_op_v0_relu_visit_attribut": 516, "ov_op_util_unaryelementwisearithmetic_validate_and_infer_typ": 516, "ov_op_v0_relu_clone_with_new_input": 516, "ov_op_v1_groupconvolution_visit_attribut": 516, "ov_op_v1_groupconvolution_validate_and_infer_typ": 516, "ov_op_v1_groupconvolution_clone_with_new_input": 516, "ov_op_v3_shapeof_visit_attribut": 516, "ov_op_v3_shapeof_validate_and_infer_typ": 516, "ov_op_v3_shapeof_clone_with_new_input": 516, "ov_op_v0_squeeze_visit_attribut": 516, "dselective_build_stat": 516, "absolute_path_to_statistics_fil": 516, "dbuild_shared_lib": 516, "sku": 516, "stock": 516, "sde": 516, "spr": 516, "adl": 516, "tgl": 516, "icl": 516, "skl": 516, "l3": [516, 542], "dnnl": 516, "impl": 516, "get_per_core_cache_s": 516, "selective_build_analyz": 516, "l2_cache_s": 516, "getenv": 516, "ov_cc_l2_cache_s": 516, "atoi": 516, "l3_cache_s": 516, "ov_cc_l3_cache_s": 516, "l1_cache_s": 516, "ov_cc_l1_cache_s": 516, "numactl": 516, "core_num": 516, "cpuid": 516, "vc": 516, "vcvar64": 516, "openvino_hom": 516, "work_path": 516, "build_cc": 516, "ninja": 516, "wno": 516, "denable_cpplint": 516, "dcmake_verbose_makefil": 516, "dcmake_compile_warning_as_error": 516, "denable_faster_build": 516, "denable_sanit": 516, "dthread": 516, "denable_intel_gpu": 516, "denable_multi": 516, "denable_auto": 516, "denable_auto_batch": 516, "denable_hetero": 516, "denable_templ": 516, "denable_ov_onnx_frontend": 516, "denable_ov_paddle_frontend": 516, "denable_ov_pytorch_frontend": 516, "denable_ov_tf_frontend": 516, "dcmake_install_prefix": 516, "cc_data": 516, "your_model": [516, 526], "denable_lto": 516, "denable_onednn_for_gpu": 516, "denable_ov_tf_lite_frontend": 516, "denable_profiling_first_infer": 516, "offlin": [517, 547], "retrain": [517, 519, 521], "unstructur": 517, "fastest": [517, 546, 562], "undergo": [518, 519, 520], "criterion": 518, "art": 518, "degrad": [518, 519, 520, 523, 524, 542, 562], "unimport": 519, "hurt": 519, "noisi": 519, "scratch": [519, 570], "qat": 519, "input_info": [519, 520], "pruning_init": 519, "beg": 519, "pruning_target": 519, "num_init_step": 519, "pruning_step": 519, "create_compressed_model": [519, 520], "worth": [519, 520, 543, 569], "compression_ctrl": [519, 520], "requr": 519, "knowledg": [520, 533, 560], "converg": 520, "10e": 520, "4x": 521, "tensroflow": 521, "matur": 521, "calibr": [521, 524], "nncf_ptq_env": 522, "model_typ": 522, "distilbert": 522, "modeltyp": 522, "preset": [522, 554], "quantizationpreset": 522, "fast_bias_correct": 522, "subset_s": 522, "ignored_scop": 522, "layer_1": 522, "layer_2": 522, "layer_3": 522, "ignoredscop": 522, "layer_": 522, "cpu_spr": 522, "targetdevic": 522, "advanced_paramet": 522, "satisfactori": [522, 523], "yolov8": [522, 523], "modelproto": 523, "max_drop": 523, "drop_typ": 523, "anomali": 523, "25gb": 524, "4gb": 524, "exception": 524, "vast": 524, "medium": [524, 539], "int4_sym": 524, "compressweightsmod": 524, "compressed_model": 524, "int4_asym": 524, "compromis": 524, "favor": [524, 554], "sensitivity_metr": 524, "sensitivitymetr": 524, "weight_quantization_error": 524, "hessian_input_activ": 524, "hessian": 524, "mean_activation_vari": 524, "max_activation_vari": 524, "mean_activation_magnitud": 524, "all_lay": 524, "phrase": 524, "load_in_4bit": 524, "huggingfaceh4": 524, "zephyr": 524, "pipe": 524, "sym": 524, "theblok": 524, "facebook": 524, "togethercomput": 524, "redpajama": 524, "incit": 524, "13b": 524, "wikitext": 524, "stabilityai_stablelm": 524, "4e1t": 524, "whowhatbench": 524, "easiest": [525, 559, 562], "kaggl": 525, "hood": [525, 534, 571], "delai": [525, 539, 543, 547, 563, 566], "berttoken": 525, "bertmodel": 525, "me": 525, "encoded_input": 525, "compact": [525, 526, 552], "path_to_your_model": 526, "sacrific": 526, "original_model": 526, "share_weigth": 526, "dealloc": [526, 530], "lifetim": [526, 530], "directory_nam": 526, "diagnost": 526, "team": 526, "your_model_fil": [527, 528, 530, 531], "2gb": 527, "exportedprogram": [529, 532], "necess": 529, "read_imag": 529, "resnet50_weight": 529, "bytesio": 529, "placekitten": 529, "html": [529, 547], "category_nam": 529, "1f": 529, "regard": 529, "recurs": 529, "assumpt": 529, "torchscript": 529, "stai": 529, "exported_model": 529, "path_to_saved_model_dir": 530, "path_to_inference_graph": 530, "path_to_checkpoint_fil": 530, "path_to_meta_graph": 530, "trackabl": 530, "movenet": 530, "singlepos": 530, "constant1": 530, "constant2": 530, "unpredict": 530, "tend": [532, 568], "gigabyt": 532, "callabl": 533, "interoper": [534, 544], "size_t": [535, 571], "implic": 535, "NOT": [535, 541, 555, 560, 571], "cumbersom": 536, "nlp": [536, 543], "beforehand": 536, "ov_dimens": 536, "1x128": 536, "1x200": 536, "set_output_tensor": [536, 550], "gracefulli": 537, "scrambl": 537, "disadvantag": 537, "poor": 537, "afford": 537, "qualifi": 538, "programmat": 538, "620": 539, "1165g7": 539, "succe": 539, "intel_auto": 539, "enable_startup_fallback": 539, "model_prior": [539, 543, 547, 562], "execution_devic": 539, "enable_runtime_fallback": 539, "schedule_polici": 539, "round_robin": 539, "device_prior": 539, "get_available_devic": [539, 548, 553], "ultrasound": 539, "busi": [539, 546, 549, 550, 553, 555, 567], "capac": [539, 542], "allow_auto_batch": [539, 541], "timeout": [539, 541, 564], "auto_batch_timeout": [539, 541], "get_properti": [539, 542, 548], "incap": 539, "perfect": [539, 560], "unlimit": 539, "acquir": 540, "six": 540, "openvino_log_level": 540, "err": 540, "6188": 540, "defaultdeviceid": 540, "uniquenam": 540, "gpu_": 540, "6242": 540, "executable_network": 540, "autoplugin": 540, "6809": 540, "general_error": 540, "pane": 540, "hotspot": 540, "drill": 540, "greatest": 540, "dropdown": 540, "multiplugin": 540, "transpar": [541, 562, 564, 566], "akin": 541, "notion": [541, 543], "auto_batch_devic": 541, "penalti": 541, "unevenli": 541, "contrari": 541, "optimal_batch_s": [541, 543, 567], "presumpt": [541, 556], "penal": 541, "slack": [541, 555, 556, 567], "proof": [541, 556, 562, 566, 567], "num_request": [541, 542, 543, 547, 556], "fluent": 541, "auto_batch": 541, "zeroth": 541, "forc": 541, "br": 541, "strict": [541, 570], "shell": 541, "18m": 541, "bfloat16": 542, "armv8": 542, "white": 542, "inference_precis": [542, 543, 547, 568], "avx512_bf16": 542, "execution_mod": [542, 543, 568], "executionmod": 542, "n_stream": [542, 543], "therebi": 542, "fil": [542, 547], "scheduling_core_typ": 542, "enable_hyper_thread": 542, "intel_cpu": 542, "denormals_optim": 542, "sparse_weights_decompression_r": 542, "hybird": 542, "hyperthread": 542, "pcore": 542, "ecor": 542, "17549e": 542, "compli": 542, "ieee": 542, "unaccept": 542, "ftz": 542, "daz": 542, "mxcsr": 542, "ddr": [542, 545], "perf": 542, "exec": 542, "particl": 542, "brgemm_avx512_amx_sparse_i8": 542, "matmul_1800": 542, "050000": 542, "sapphir": 542, "unavail": 543, "max_batch_s": 543, "mainli": [543, 568], "domin": 543, "wors": 543, "unfus": 543, "aggress": [543, 565, 566], "realloc": 543, "perman": 543, "model_cach": [543, 572], "enqueu": 543, "intel_gpu": [543, 544, 548], "memory_typ": 543, "set_memory_typ": 543, "climage2dtensor": [543, 544], "cl_cach": 543, "compilation_num_thread": [543, 547, 565], "host_task_prior": 543, "queue_prior": 543, "queue_throttl": 543, "enable_loop_unrol": 543, "disable_winograd_convolut": 543, "gop": 543, "device_total_mem_s": [543, 547], "uarch_vers": 543, "execution_units_count": 543, "memory_statist": 543, "inaccuraci": 543, "winograd": 543, "devstr1": 543, "gpu_disable_winograd_convolut": 543, "alongsid": 543, "starv": 543, "spin": 543, "poll": [543, 546, 555], "directx": [544, 547], "vaapi": 544, "hpp": [544, 548, 571], "cl_context": 544, "cl_queue": 544, "id3d11devic": 544, "vadisplai": 544, "create_tensor": 544, "create_tensor_nv12": 544, "clcontext": 544, "overload": [544, 553], "usm": 544, "cl_mem": 544, "image2d": 544, "biplanar": 544, "d3dcontext": 544, "vacontext": 544, "id3d11buff": 544, "id3d11texture2d": 544, "vasurfaceid": 544, "grei": 544, "cl_command_queu": 544, "submiss": 544, "create_context": 544, "get_param": 544, "anymap": 544, "descriptor": 544, "remote_properti": 544, "heaviest": 545, "multi_device_prior": 545, "inabl": 545, "importantli": [545, 546, 569], "suboptim": 545, "transmit": 545, "unsubstanti": 545, "openvino_hetero_visu": 545, "graphviz": 545, "hetero_affinity_": 545, "hetero_subgraphs_": 545, "xdot": [545, 551], "hetero_subgraph": 545, "subgraph1": 545, "3808": 545, "subgraph2": 545, "out_prob": 545, "ref": 545, "4212": 545, "microsecond": 545, "squeezenet1": 545, "path_to_pictur": 545, "knob": 546, "worker": 546, "3720": 547, "794734": 547, "transact": 547, "ever": 547, "feil": 547, "shader": 547, "recompil": [547, 565], "intel_npu": 547, "device_alloc_mem_s": 547, "driver_vers": 547, "propertymut": 548, "8700": 548, "20ghz": 548, "is_mut": 548, "changeabl": 548, "immut": 548, "set_input_tensor": [549, 550], "leak": [549, 565], "wait_for": [550, 553], "set_callback": [550, 553, 555], "weak": 550, "weal_ptr": 550, "cyclic": 550, "abort": 550, "get_input_tensor": 550, "organ": 550, "rewritten": [550, 572], "sink": [551, 570], "destruct": 551, "anymor": [551, 564, 567], "ov_model_input": 551, "ov_model_output": 551, "tensor_nam": 551, "get_nam": [551, 569], "get_any_nam": 551, "original_fw_in_tensor_nam": 551, "original_fw_out_tensor_nam": 551, "get_element_typ": 551, "compos": [551, 561, 562], "opsetx": 551, "denable_openvino_debug": 551, "visualizetre": 551, "ov_visualize_tree_output_shap": 551, "ov_visualize_tree_output_typ": 551, "ov_visualize_tree_min_max_denorm": 551, "ov_visualize_tree_runtime_info": 551, "ov_visualize_tree_io": 551, "ov_visualize_tree_members_nam": 551, "conduct": [552, 556], "prematur": 552, "asyncinferqueu": 552, "share_input": 552, "share_output": 552, "caution": 552, "codebas": 552, "ovdict": 552, "pure": 552, "shared_memori": 553, "to_dict": 553, "spawn": 553, "wait_al": 553, "mutat": 553, "invalid": [553, 571], "userdata": 553, "is_readi": 553, "get_idle_request_id": 553, "create_infer_request": 553, "infer_new_request": 553, "get_runtime_model": 553, "get_profiling_info": 553, "query_st": [553, 569], "golden": 554, "idiom": [554, 564], "multitud": 554, "incorpor": 555, "captur": [555, 572], "somewhat": [555, 564], "slowest": 555, "emot": 555, "notifi": 555, "heavi": 555, "versu": 556, "sacrif": 556, "era": 556, "planar": 557, "intuit": 557, "convert_layout": [557, 560], "inconveni": 558, "set_batch": 558, "1280": 559, "insensit": 559, "set_element_typ": 560, "convert_element_typ": 560, "convert_color": 560, "nv12_two_plan": 560, "i420_three_plan": 560, "colorformat": 560, "postprocessstep": 560, "outputmodelinfo": 560, "convertimagedtyp": 561, "grayscal": 561, "totensor": 561, "centercrop": 561, "concurr": [562, 566], "rise": 562, "expertis": 562, "burden": [562, 569], "unload": 562, "reload": 562, "loadcompil": 562, "mmap": [562, 565], "enable_mmap": [562, 565], "uptim": 562, "carri": 563, "detriment": 564, "finer": 564, "fat": 564, "outermost": [564, 566], "thumb": 564, "grace": 564, "coupl": [564, 565], "moment": 565, "sanit": 565, "valgrind": 565, "indirect": 565, "caught": 565, "peak": [565, 567], "vmhwm": 565, "stress_test": 565, "memleaks_test": 565, "vmrss": 565, "pressur": 565, "malloc_trim": 565, "signifficantli": 565, "glibc": 565, "tunabl": 565, "malloc": 565, "trim_threshold": 565, "arena_max": 565, "jemalloc": 565, "linearli": 566, "starvat": 566, "requisit": 566, "crunch": 566, "compet": 566, "pace": 567, "inflat": 567, "mux": 567, "vacant": 567, "expedit": 567, "massiv": 567, "bubbl": 567, "difficult": 567, "tail": 567, "toler": 567, "wast": 567, "fluctuat": 567, "suffic": 567, "flight": 567, "couldn": 568, "x\u1d49": 568, "xmx": 568, "thank": 569, "lowlat": 569, "forecast": 569, "fulfil": 569, "spec": 569, "drawback": 569, "variablest": 569, "set_stat": 569, "get_stat": 569, "tensor_name_1": 570, "tensor_name_4": 570, "tensor_name_3": 570, "tensor_name_6": 570, "sequence_dimens": 570, "variable_": 570, "somewher": 570, "reshape_layer_nam": 570, "peephol": 570, "inputforget": 570, "nonetheless": 570, "sinkvector": 570, "add_sink": 570, "delete_sink": 570, "str_": 571, "bytes_": 571, "sophist": 571, "held": 571, "underneath": 571, "std_data": 571, "byte_data": 571, "str_data": 571, "iostream": 571, "cout": 571, "bytes_data": 571, "new_cont": 571, "acquisit": 572, "torchdynamo": 572, "dev20230713": 572, "python_env_root": 572, "_dynamo": 572, "eval_fram": 572, "check_if_dynamo_support": 572, "win32": 572, "runtimeerror": 572, "version_info": 572, "realist": 572, "creativ": 572, "hook": 572, "cpython": 572, "pep": 572, "523": 572, "bytecod": 572, "aotautograd": 572, "primtorch": 572, "elementari": 572, "torchinductor": 572, "inlin": 572, "inductor": 572}, "objects": {"": [[17, 0, 0, "-", "openvino"]], "openvino.properties.intel_gpu": [[26, 0, 0, "-", "hint"]], "openvino.runtime.op": [[31, 0, 0, "-", "util"]], "openvino.runtime": [[37, 0, 0, "-", "opset14"], [46, 0, 0, "-", "passes"]]}, "objtypes": {"0": "py:module"}, "objnames": {"0": ["py", "module", "Python module"]}, "titleterms": {"about": [0, 127, 516], "openvino": [0, 3, 4, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 75, 91, 96, 98, 100, 106, 111, 125, 127, 128, 129, 131, 132, 133, 135, 211, 216, 221, 222, 223, 224, 226, 469, 470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 496, 498, 499, 500, 501, 513, 516, 532, 534, 539, 546, 547, 549, 550, 551, 552, 553, 555, 558, 567, 569, 570], "featur": [0, 6, 74, 471, 493, 542, 543, 547], "architectur": [0, 111, 516, 572], "ecosystem": [0, 125], "commun": 0, "case": [0, 83, 135, 558], "studi": 0, "addit": [1, 14, 49, 75, 82, 84, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 224, 470, 471, 472, 473, 477, 478, 479, 481, 486, 487, 495, 496, 498, 499, 500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 517, 518, 521, 524, 525, 527, 528, 532, 535, 539, 541, 542, 543, 546, 547, 549, 551, 554, 556, 557, 558, 568, 571, 572], "resourc": [1, 49, 75, 82, 84, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 224, 470, 471, 473, 477, 478, 479, 481, 486, 487, 495, 496, 498, 499, 500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 517, 518, 521, 524, 525, 527, 528, 532, 535, 539, 541, 542, 543, 546, 547, 549, 551, 554, 557, 558, 568, 571, 572], "glossari": 2, "acronym": 2, "abbrevi": 2, "term": [2, 14], "see": [2, 129, 220, 221, 222, 223, 227, 523, 544, 559], "also": [2, 129, 220, 221, 222, 223, 227, 523, 544, 559], "legal": [3, 13, 15], "inform": [3, 12, 13, 14, 15, 502, 516], "logo": 3, "usag": [3, 49, 500, 502, 516, 545, 550, 565], "guidelin": 3, "intel": [3, 15, 473, 474, 476, 477, 478, 483, 486, 487, 498, 542], "global": [3, 548], "human": 3, "right": 3, "principl": 3, "telemetri": 4, "enabl": [4, 122, 482, 498, 516, 563], "disabl": [4, 539], "report": 4, "chang": [4, 13, 82, 118, 535], "consent": 4, "decis": 4, "data": [4, 83, 130, 527, 529, 536, 542, 543, 557], "collect": [4, 83, 516], "detail": [4, 106, 126, 128, 133, 560, 564, 567], "compat": 5, "support": [5, 6, 7, 8, 13, 14, 77, 83, 85, 98, 110, 112, 113, 115, 116, 500, 527, 528, 529, 530, 531, 542, 543, 547, 560, 572], "infer": [6, 8, 13, 83, 113, 118, 127, 135, 210, 219, 225, 482, 497, 498, 499, 504, 534, 538, 542, 543, 546, 549, 550, 552, 553, 554, 556, 568, 569], "devic": [6, 8, 13, 21, 218, 471, 482, 502, 507, 515, 516, 538, 539, 540, 541, 542, 543, 545, 546, 547, 548, 558, 566, 567], "api": [6, 13, 16, 47, 77, 78, 81, 106, 113, 115, 133, 214, 218, 220, 519, 520, 530, 537, 543, 544, 552, 553, 555, 556, 557, 559, 560, 569, 570], "coverag": 6, "oper": [7, 8, 15, 83, 118, 122, 123, 124, 129, 130, 131, 132, 135, 171, 226, 227, 242, 243, 418, 551, 560, 570], "framework": [7, 13, 75, 77, 83, 129], "frontend": [7, 18, 114, 132, 515], "perform": [9, 10, 12, 502, 539, 540, 541, 543, 545, 546, 554, 556], "benchmark": [9, 104, 502, 503, 511, 512, 539, 546], "get": [10, 75, 471, 487, 504, 544, 548, 559], "number": [10, 83, 502, 546, 556, 567], "model": [11, 13, 59, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 123, 127, 135, 208, 209, 212, 220, 223, 470, 471, 497, 498, 499, 504, 510, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 527, 528, 529, 530, 531, 532, 536, 537, 539, 542, 543, 547, 548, 549, 550, 551, 553, 557, 558, 559, 563, 569, 570], "accuraci": [11, 523], "int8": [11, 225], "bf16": 11, "fp32": 11, "fp16": [11, 79], "flex": 11, "170": 11, "onli": [11, 83, 542, 543, 549], "xeon": 11, "r": [11, 87, 89, 91], "8490h": 11, "f": 12, "A": [12, 567], "q": 12, "releas": [13, 14, 549, 553], "note": [13, 83, 543, 555], "2024": [13, 475, 493], "1": [13, 75, 83, 115, 127, 135, 143, 148, 219, 220, 471, 476, 477, 478, 479, 487, 490, 491, 499, 500, 516, 519, 520, 530, 549], "24": 13, "april": 13, "what": [13, 75, 83, 476, 477, 478, 479, 480, 482, 486, 487, 488, 490, 491], "": [13, 75, 83, 476, 477, 478, 479, 480, 482, 486, 487, 488, 490, 491, 557], "new": [13, 75, 77], "runtim": [13, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 127, 208, 220, 476, 477, 478, 479, 480, 481, 482, 484, 485, 487, 488, 489, 490, 491, 498, 539, 549, 551, 552], "common": [13, 135, 220], "auto": [13, 524, 539, 540], "mode": [13, 515, 538, 542, 545, 546, 550, 553, 568], "cpu": [13, 15, 504, 542, 564], "plugin": [13, 133, 135, 211, 213, 214, 215, 216, 539, 540, 544], "gpu": [13, 15, 130, 473, 482, 519, 520, 543, 544], "npu": [13, 474, 547], "python": [13, 47, 75, 80, 83, 113, 115, 119, 126, 487, 495, 500, 503, 525, 528, 530, 552, 553], "c": [13, 75, 500, 515, 549], "node": [13, 49, 83, 122, 130, 220, 486], "j": [13, 49, 486], "tensorflow": [13, 77, 83, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 115, 116, 530, 531], "pytorch": [13, 77, 90, 91, 92, 93, 94, 95, 96, 114, 529, 572], "onnx": [13, 77, 87, 88, 89, 90, 91, 92, 93, 94, 112, 114, 527, 529], "server": [13, 127], "neural": [13, 15, 105, 226], "network": [13, 83, 127, 226], "compress": [13, 79, 225, 471, 518, 524], "token": [13, 83, 499, 500], "other": [13, 83, 504, 541], "known": 13, "issu": 13, "jupyt": [13, 471, 496], "notebook": [13, 471, 496], "previou": 13, "deprec": 13, "And": 13, "discontinu": [13, 74], "remov": [13, 496], "futur": 13, "polici": 14, "regular": 14, "long": 14, "nightli": 14, "system": [15, 479], "requir": [15, 83, 127, 135, 471, 479, 515], "process": [15, 83, 106, 549, 555, 560], "unit": 15, "develop": [15, 75, 127, 211], "environ": [15, 75, 477, 478, 479, 487, 496, 522], "refer": [16, 127, 133, 214], "preprocess": [19, 82, 542, 543, 557, 558, 560, 561], "properti": [20, 21, 22, 23, 24, 25, 26, 27, 28, 48, 52, 59, 60, 68, 215, 542, 543, 547, 548], "hint": [22, 26, 502, 539, 542, 556], "intel_auto": 23, "intel_cpu": 24, "intel_gpu": [25, 26], "log": [27, 279, 502, 540], "stream": [28, 542, 543, 567], "op": [30, 31, 83], "util": 31, "opset1": [32, 228], "opset10": [33, 229], "opset11": [34, 230], "opset12": [35, 231], "opset13": [36, 232], "opset14": [37, 233], "opset2": [38, 234], "opset3": [39, 235], "opset4": [40, 236], "opset5": [41, 237], "opset6": [42, 238], "opset7": [43, 239], "opset8": [44, 240], "opset9": [45, 241], "pass": [46, 220, 221, 222, 223], "addon": 48, "bind": 49, "build": [49, 127, 211, 504, 516, 549, 551], "from": [49, 77, 81, 83, 97, 113, 115, 127, 129, 132, 477, 478, 479, 481, 482, 483, 486, 487, 490, 491, 496, 518, 519, 520, 530, 539, 544, 553, 556, 559], "sourc": [49, 75, 130], "enumer": [50, 51, 538], "element": [50, 83, 553, 571], "resizealgorithm": 51, "interfac": [52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 115], "compiledmodel": [52, 212, 548, 552, 553], "method": [52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 518, 519, 520, 535, 544], "core": [53, 129, 477, 478, 479, 548, 549], "coreconstructor": 54, "constructor": [54, 64, 66, 69, 131, 212, 213, 217, 219], "inferrequest": [55, 219], "inputinfo": 56, "inputmodelinfo": 57, "inputtensorinfo": 58, "output": [60, 81, 83, 132, 220, 499, 500, 503, 505, 506, 507, 508, 509, 510, 511, 512, 529, 536, 550, 552, 553, 559, 560], "outputinfo": 61, "outputtensorinfo": 62, "partialshap": 63, "partialshapeconstructor": 64, "prepostprocessor": [65, 557], "prepostprocessorconstructor": 66, "preprocessstep": 67, "tensor": [68, 83, 130, 135, 218, 529, 544, 550, 553, 571], "tensorconstructor": 69, "type": [70, 71, 72, 83, 220, 514, 529, 542, 543, 553], "alia": [70, 71, 72], "dimens": [70, 83, 536, 537], "supportedtypedarrai": 71, "elementtypestr": 72, "document": 73, "legaci": [74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124], "compon": [74, 126, 127, 128, 477, 478, 479, 515], "instal": [75, 83, 127, 471, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 496, 500, 518], "tool": [75, 135, 502], "For": [75, 83, 242, 472], "an": [75, 83, 87, 88, 89, 90, 91, 92, 93, 94, 101, 108, 109, 112, 127, 477, 478, 479, 522, 527, 541, 549], "exist": [75, 83], "deep": [75, 109], "learn": [75, 471, 494], "step": [75, 127, 135, 143, 148, 163, 200, 476, 477, 478, 479, 487, 490, 491, 549, 557, 558], "set": [75, 83, 84, 127, 226, 227, 476, 487, 490, 491, 516, 522, 533, 548, 549, 551, 553, 556, 563], "up": [75, 127, 476, 487, 490, 491, 522], "virtual": [75, 487, 496], "2": [75, 83, 88, 115, 127, 135, 148, 219, 220, 471, 476, 477, 478, 479, 487, 490, 491, 493, 499, 500, 516, 519, 520, 530, 549], "activ": [75, 487], "3": [75, 127, 135, 148, 163, 219, 220, 471, 487, 499, 500, 519, 520, 549], "updat": [75, 83, 135, 487], "pip": [75, 487], "highest": [75, 487], "version": [75, 83, 226, 487, 490, 491], "4": [75, 127, 135, 148, 200, 219, 487, 499, 500, 519, 520, 549], "packag": [75, 127, 211, 476, 481, 482, 487, 490, 491, 516], "5": [75, 127, 148, 487, 519, 520, 549], "test": [75, 216, 541, 556], "next": [75, 476, 477, 478, 479, 480, 482, 486, 487, 488, 490, 491], "start": [75, 83, 122, 127, 471, 487, 504, 518, 549], "zoo": [76, 106], "transit": 77, "convers": [77, 78, 81, 83, 86, 106, 108, 115, 118, 526, 532, 560], "paramet": [77, 78, 81, 83, 84, 115, 356, 522, 524, 526, 529], "comparison": 77, "input_shap": [77, 83, 84], "batch": [77, 83, 539, 541, 543, 564, 567], "mean_valu": 77, "scale_valu": [77, 83], "reverse_input_channel": 77, "source_layout": 77, "target_layout": 77, "layout": [77, 82, 118, 557, 559, 560], "transform": [77, 122, 135, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 220, 447, 448, 449, 499, 570], "cut": [77, 81, 83], "off": [77, 81], "part": [77, 81, 83, 100], "protobuf": [77, 83], "format": [77, 83, 85, 96, 111, 113, 114, 115, 130, 224, 499, 529, 530, 557], "tf": 77, "graph": [77, 83, 120, 122, 221], "graphdef": 77, "savedmodel": [77, 115, 530], "mo": [77, 83], "v": [77, 226], "ovc": [77, 525], "exampl": [78, 108, 109, 115, 126, 130, 242, 384, 471, 498, 502, 504, 505, 506, 508, 509, 510, 511, 512, 515, 518, 519, 520, 522, 523, 524, 539, 544, 549, 550, 557, 558, 561, 563, 569], "convert": [80, 83, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 132, 466, 498, 499, 500, 504, 525, 527, 528, 529, 530, 531, 532, 560, 561], "repres": 80, "object": [80, 106, 549, 557], "purpos": 81, "default": 81, "behavior": 81, "without": [81, 83], "input": [81, 82, 83, 84, 106, 132, 135, 220, 449, 499, 500, 502, 506, 529, 533, 535, 544, 549, 550, 552, 553, 555, 559, 560], "end": [81, 83, 122], "begin": [81, 493], "multipl": [81, 83, 132, 516, 537], "port": [81, 83, 120, 220], "embed": 82, "comput": [82, 83, 208, 515], "specifi": [82, 83, 84], "mean": [82, 83, 108, 560], "scale": [82, 83, 108, 560], "valu": [82, 83, 108, 449], "revers": [82, 385], "channel": [82, 83], "optim": [83, 118, 119, 121, 123, 135, 498, 516, 517, 519, 520, 541, 542, 546, 554, 555, 556, 557, 562, 565, 566, 570], "frequent": [83, 113, 115], "ask": [83, 113, 115], "question": [83, 113, 115], "q1": 83, "doe": 83, "messag": 83, "error": [83, 117], "current": 83, "caff": [83, 119], "proto": 83, "contain": 83, "field": [83, 210, 212, 213, 217, 218, 219], "q2": 83, "how": [83, 117, 127, 130, 216, 220, 226, 503, 505, 506, 507, 508, 509, 510, 511, 512, 516, 522, 539, 541, 546, 551, 556, 572], "do": 83, "i": [83, 487, 537], "creat": [83, 96, 103, 127, 129, 213, 222, 519, 520, 539, 546, 549, 550, 570, 571], "bare": 83, "caffemodel": 83, "have": 83, "prototxt": 83, "q3": 83, "unabl": 83, "id": 83, "q7": 83, "invalid": 83, "file": [83, 96, 100, 103, 122, 130, 477, 478, 479, 527, 528], "neither": 83, "layer": [83, 112, 113, 115, 116, 119, 130, 334, 502, 527, 528, 530, 531], "nor": 83, "top": [83, 539, 546], "level": [83, 544, 548, 556, 564], "q8": 83, "old": 83, "style": 83, "via": [83, 480, 488, 543, 548, 570, 572], "input_dim": 83, "ar": 83, "pleas": 83, "q9": 83, "topologi": [83, 545], "q11": 83, "q12": 83, "happen": 83, "while": 83, "construct": 83, "net": 83, "fallback": [83, 545], "function": [83, 523, 553], "q13": 83, "cannot": 83, "shape": [83, 84, 106, 117, 418, 533, 535, 536, 537, 542, 543, 551], "due": 83, "except": 83, "q14": 83, "becaus": 83, "avail": [83, 227, 538, 539, 548], "regist": [83, 129, 222], "us": [83, 103, 113, 115, 122, 127, 135, 211, 220, 470, 476, 490, 491, 504, 520, 530, 539, 540, 545, 546, 550, 556, 558, 563, 570, 572], "q15": 83, "name": [83, 122, 132, 220, 529, 542, 543, 559], "can": 83, "deduc": 83, "given": 83, "option": [83, 502, 514, 519, 520, 556, 563, 567, 572], "choos": [83, 567], "one": [83, 127], "mxnet": 83, "q16": 83, "provid": 83, "q19": 83, "both": 83, "defin": [83, 122, 127, 130, 545, 559], "either": 83, "factor": 83, "per": [83, 135, 502], "q20": 83, "find": 83, "input_proto": 83, "store": [83, 127], "input_model": 83, "pre": [83, 88, 93, 104, 537, 555, 560], "train": [83, 88, 93, 104, 128, 518, 519, 520, 521, 522, 523], "weight": [83, 171, 225, 524, 542], "q22": 83, "fail": 83, "directori": [83, 127], "permiss": 83, "deni": 83, "q23": 83, "discov": 83, "q24": 83, "wa": 83, "translat": 83, "ie": 83, "stop": 83, "q25": 83, "edg": 83, "undefin": [83, 536], "check": [83, 490, 491, 539], "correct": 83, "q26": 83, "q27": 83, "need": 83, "more": [83, 502], "anoth": 83, "place": [83, 493], "q28": 83, "placehold": 83, "q29": 83, "index": 83, "out": [83, 536], "q30": 83, "ha": 83, "than": 83, "were": 83, "try": 83, "notat": 83, "where": 83, "integ": 83, "q31": 83, "0": [83, 475], "name_of_the_nod": 83, "omit": 83, "all": [83, 127, 496, 502], "replac": [83, 106, 220], "Or": 83, "q32": 83, "No": [83, 471], "q33": 83, "The": [83, 535, 545, 555], "amount": 83, "equal": [83, 299, 559], "q34": 83, "alreadi": 83, "been": 83, "q35": 83, "unsupport": 83, "match": [83, 222], "kind": 83, "point": [83, 122, 542], "scope": 83, "q36": 83, "write": [83, 119, 220, 542, 543], "event": 83, "tensorboard": 83, "q37": 83, "There": 83, "implement": [83, 130, 218, 222, 564], "thi": 83, "extens": [83, 118, 121, 122, 128, 129, 132, 542, 543], "q38": 83, "propag": 83, "q39": 83, "q40": 83, "Not": [83, 537], "fulli": 83, "q41": 83, "proce": 83, "q42": 83, "modul": 83, "found": 83, "higher": 83, "q43": 83, "read": [83, 226, 515, 542, 543], "incorrect": 83, "miss": 83, "q44": 83, "after": [83, 167, 171], "corrupt": 83, "q45": 83, "custom": [83, 106, 115, 130, 131, 132, 135, 530, 560], "customlayersmap": 83, "xml": 83, "q46": 83, "configur": [83, 122, 130, 471, 472, 473, 474, 477, 478, 479, 492, 502, 519, 520, 536, 539, 541, 545, 546, 548], "q47": 83, "extractor": [83, 119, 124], "insensit": 83, "duplic": 83, "q48": 83, "expect": 83, "extract": [83, 97, 118], "iter": [83, 502], "q49": 83, "its": 83, "cast": 83, "float": [83, 542], "q50": 83, "q51": 83, "q52": 83, "q53": 83, "follow": 83, "load": [83, 118, 127, 129, 470, 498, 524, 558], "q54": 83, "q55": 83, "attempt": 83, "second": 83, "time": [83, 518], "class": [83, 131, 210, 212, 213, 215, 217, 218, 219], "q56": 83, "them": 83, "q57": 83, "pars": 83, "q58": 83, "q59": 83, "q60": 83, "q61": 83, "you": 83, "should": 83, "each": 83, "q62": 83, "q63": 83, "q64": 83, "q65": 83, "q66": 83, "instanc": [83, 213], "q67": 83, "must": 83, "singl": [83, 132, 496], "dictionari": 83, "q68": 83, "q69": 83, "q70": 83, "q71": 83, "One": [83, 104], "attribut": [83, 118, 132, 136, 137, 138, 139, 140, 141, 142], "q72": 83, "valid": [83, 523], "q73": 83, "broken": 83, "q74": 83, "reachabl": 83, "q75": 83, "sub": [83, 130], "q76": 83, "clip": 83, "infin": 83, "blob": 83, "q77": 83, "zero": 83, "q78": 83, "pattern": [83, 122, 222], "q79": 83, "q80": 83, "warn": 83, "might": 83, "slow": 83, "q81": 83, "argument": 83, "nd_prefix_nam": 83, "pretrained_model_nam": 83, "input_symbol": 83, "ani": 83, "q82": 83, "q83": 83, "q84": 83, "json": 83, "q85": 83, "param": 83, "nd": 83, "q86": 83, "q87": 83, "call": [83, 552], "register_caffe_python_extractor": 83, "q88": 83, "calcul": [83, 418], "memori": [83, 113, 115, 118, 530, 543, 544, 552, 553, 565], "q89": 83, "appear": 83, "kaldi": 83, "magic": 83, "nnet": 83, "tag": 83, "q90": 83, "count": 83, "line": [83, 115], "list": [83, 539, 553], "q91": 83, "abl": [83, 117], "q92": 83, "q93": 83, "lower": 83, "q94": 83, "parallelcompon": 83, "q97": 83, "cycl": 83, "q100": 83, "interp": 83, "mai": 83, "wrong": 83, "q101": 83, "q102": 83, "_contrib_box_nm": 83, "q103": 83, "modeloptim": 83, "q105": 83, "ir": [83, 88, 90, 91, 92, 93, 94, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 224, 226, 498, 499, 500, 532, 558], "prepar": [83, 109, 127, 500, 522, 523, 525, 536], "execut": [83, 135, 222, 515, 542, 543, 545, 546, 566, 568], "path": 83, "tutori": [86, 126, 128, 471, 495], "faster": [87, 563], "cnn": [87, 89], "gpt": 88, "download": [88, 90, 91, 92, 93, 94, 98, 100, 104, 110, 477, 479, 504], "base": [88, 110], "mask": 89, "bert": [90, 98, 503], "ner": 90, "cascad": [91, 550], "rcnn": 91, "101": 91, "f3net": 92, "clone": [92, 127], "repositori": [92, 476, 487, 490, 491], "quartznet": 93, "rcan": 94, "rnn": 95, "t": 95, "yolact": 96, "patch": [96, 103], "attent": 97, "ocr": 97, "aocr": 97, "librari": [97, 108, 129, 133, 515], "pretrain": [98, 100, 110], "reshap": [98, 117, 441, 508, 535], "crnn": 99, "deepspeech": 100, "freez": [100, 115, 530], "pb": 100, "main": [100, 135, 163], "efficientdet": 101, "interpret": [101, 208], "result": [101, 135, 359, 516, 549, 553], "facenet": 102, "gnmt": 103, "run": [103, 127, 496, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 523, 534, 550, 553, 569], "languag": [104, 497, 515], "billion": 104, "word": 104, "collabor": 105, "filter": [105, 518, 519], "detect": 106, "toolkit": [106, 476, 477, 478, 483, 486, 487], "sampl": [106, 471, 501, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 539, 545, 546], "open": 106, "demo": 106, "feed": 106, "imag": [106, 108, 127, 483, 509, 560], "fix": [106, 117], "resiz": [106, 560], "keep": 106, "aspect": 106, "ratio": 106, "retinanet": 107, "slim": 108, "classif": [108, 505, 506, 509], "incept": 108, "v1": 108, "wide": 109, "famili": 109, "xlnet": 110, "larg": [110, 497], "frozen": [110, 115, 530], "yolo": 111, "yolov4": 111, "yolov3": 111, "overview": [111, 125, 127, 133, 135, 220, 226, 559, 563], "dump": [111, 559], "yolov1": 111, "yolov2": 111, "paddlepaddl": [113, 528], "faq": [113, 115], "export": [114, 519, 520, 524, 529], "non": [115, 117, 529, 530], "kera": [115, 530], "h5": [115, 530], "command": 115, "cli": [115, 525], "specif": [115, 122, 135, 208, 218, 226, 243, 542, 567], "summari": [115, 127, 530, 543], "lite": [116, 531], "troubleshoot": [117, 492, 496], "To": 117, "avoid": 117, "collis": 117, "represent": [118, 209, 225, 226, 500, 551, 569, 571], "pipelin": [118, 135, 471, 499], "front": [118, 122], "phase": [118, 122], "partial": [118, 559], "middl": [118, 122], "nhwc": 118, "nchw": 118, "back": [118, 122], "intermedi": [118, 225, 500], "emit": 118, "extend": [119, 216, 553], "travers": 120, "modif": 120, "connect": 120, "gener": [122, 499, 500, 555], "datumaro": 126, "workflow": [126, 128, 513, 518], "hand": 126, "secur": [127, 469, 470], "add": [127, 266], "prerequisit": [127, 135, 143, 496, 498, 499], "host": 127, "machin": 127, "guest": 127, "vm": 127, "combin": [127, 545, 556], "role": 127, "independ": 127, "softwar": 127, "vendor": 127, "user": [127, 557], "isv": 127, "instruct": [127, 516], "artefact": 127, "kei": [127, 493], "certif": 127, "access": [127, 571], "control": [127, 523, 568], "master": 127, "licens": 127, "tcb": 127, "6": [127, 148, 519, 520, 549], "publish": 127, "7": [127, 148, 519, 520, 549], "receiv": 127, "request": [127, 210, 219, 546, 549, 550, 553, 556], "setup": [127, 504], "ca": 127, "sign": [127, 287], "nginx": 127, "mechan": 129, "definit": [129, 130], "semant": 129, "map": [129, 132], "customlay": 130, "structur": [130, 224, 549], "kernel": [130, 496], "buffer": 130, "compileropt": 130, "worksiz": 130, "built": 130, "In": 130, "debug": [130, 220, 540, 551], "tip": 130, "validate_and_infer_typ": 131, "clone_with_new_input": 131, "visit_attribut": 131, "evalu": 131, "has_evalu": 131, "opextens": 132, "standard": 132, "openvino_framework_map": 132, "macro": 132, "conversionextens": 132, "guid": [133, 492, 496, 497, 517, 542], "advanc": [134, 471, 502, 552, 559, 563, 566, 567], "topic": 134, "low": [135, 171, 209, 225, 544, 556, 564], "precis": [135, 140, 171, 209, 225, 542, 560, 568], "introduct": [135, 136, 225, 518, 519, 520, 522, 523, 527, 557], "quantiz": [135, 171, 208, 209, 471, 518, 519, 520, 521, 522, 523, 542], "approach": 135, "fakequant": [135, 171, 208, 420], "dequant": [135, 171], "markup": [135, 148], "decomposit": 135, "handl": [135, 536, 544, 545], "cleanup": [135, 200], "analysi": 135, "mix": [135, 384], "restrict": [135, 208], "typic": 135, "avgpoolprecisionpreserv": 137, "intervalsalign": 138, "precisionpreserv": 139, "quantizationalign": 141, "quantizationgranular": 142, "convertsubtractconst": 144, "linopsequencefus": 145, "pullreshapethroughdequant": 146, "pulltransposethroughdequant": 147, "markupcanbequant": [148, 155], "markupprecis": [148, 157], "markuppertensorquant": [148, 156], "markupavgpoolprecisionpreserv": [148, 153], "propagateprecis": [148, 158], "alignquantizationinterv": [148, 149], "alignquantizationparamet": [148, 150], "createattribut": 151, "createprecisionsdependentattribut": 152, "markupbia": 154, "propagatesharedvalu": 159, "propagatethroughprecisionpreserv": 160, "propagatetoinput": 161, "updatesharedprecisionpreserv": 162, "clamptransform": 164, "prelutransform": 165, "relutransform": 166, "addtransform": 167, "subgraph": [167, 171], "befor": [167, 171], "multiplytransform": [168, 169], "subtracttransform": 170, "convolutiontransform": 171, "limit": [171, 541, 542, 543, 544, 547], "origin": 171, "convolutionbackpropdatatransform": 172, "groupconvolutiontransform": 173, "interpolatetransform": 174, "matmultransform": 175, "concattransform": 176, "depthtospacetransform": 177, "gathertransform": 178, "padtransform": 179, "shufflechannelstransform": 180, "splittransform": 181, "stridedslicetransform": 182, "transposetransform": 183, "variadicsplittransform": 184, "mvntransform": 185, "normalizel2transform": 186, "avgpooltransform": 187, "maxpooltransform": 188, "fakequantizetransform": 189, "foldfakequantizetransform": 190, "reducemaxtransform": 191, "reducemeantransform": 192, "reducemintransform": 193, "reducesumtransform": 194, "batchtospacetransform": 195, "reshapetransform": 196, "spacetobatchtransform": 197, "squeezetransform": 198, "unsqueezetransform": 199, "eliminatefakequantizetransform": 201, "fakequantizedecompositiontransform": 202, "foldconverttransform": 203, "fuseconverttransform": 204, "fusemultiplytofakequantizetransform": 205, "fusesubtracttofakequantizetransform": 206, "multiplytogroupconvolutiontransform": 207, "asynchron": [210, 550, 552], "asyncinferrequest": 210, "cancel": [210, 219], "cmake": [211, 549], "compil": [212, 220, 482, 499, 516, 537, 548, 549, 553, 572], "compile_model": [212, 213, 563], "export_model": 212, "create_sync_infer_request": 212, "create_infer_request": 212, "get_properti": [212, 213, 217, 218], "set_properti": [212, 213], "get_runtime_model": 212, "destructor": [213, 219], "transform_model": 213, "query_model": 213, "import_model": 213, "create_context": 213, "get_default_context": 213, "remot": [217, 218, 544, 550], "context": [217, 543, 544], "remotecontext": [217, 544], "get_device_nam": [217, 218], "create_tensor": 217, "public": 218, "type_check": 218, "get_data": 218, "intern": [218, 564], "vectortensorimpl": 218, "get_element_typ": 218, "get_shap": 218, "get_strid": 218, "set_shap": 218, "synchron": [219, 550, 553], "set_tensors_impl": 219, "query_st": 219, "infer_preprocess": 219, "start_pipelin": 219, "wait_pipelin": 219, "infer_postprocess": 219, "get_profiling_info": 219, "work": [220, 498, 503, 505, 506, 507, 508, 509, 510, 511, 512, 518, 539, 541, 546, 548, 550, 551, 553, 556], "elimin": 220, "condit": [220, 516], "essenti": 220, "friendli": 220, "info": 220, "constant": [220, 354], "fold": 220, "mistak": 220, "manag": [220, 476, 481, 482, 490, 491, 496], "rewrit": 221, "matcher": 222, "callback": [222, 553, 555], "matcherpass": 222, "suitabl": 225, "artifici": 226, "opset": 226, "tabl": [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "content": [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], "broadcast": [242, 371, 372], "rule": [242, 418], "elementwis": 242, "descript": 242, "numpi": 242, "pdpd": 242, "bidirect": 242, "clamp": 244, "elu": 245, "exp": 246, "gelu": [247, 248], "hardsigmoid": 249, "hsigmoid": 250, "hswish": 251, "logsoftmax": 252, "mish": 253, "prelu": 254, "relu": 255, "selu": 256, "sigmoid": 257, "softmax": [258, 259], "softplu": 260, "softsign": 261, "swish": 262, "ab": 263, "aco": 264, "acosh": 265, "asin": 267, "asinh": 268, "atan": 269, "atanh": 270, "ceil": 271, "co": 272, "cosh": 273, "cumsum": 274, "divid": 275, "erf": 276, "floor": 277, "floormod": 278, "maximum": 280, "minimum": 281, "mod": 282, "multipli": 283, "neg": [284, 384], "power": 285, "round": 286, "sin": 288, "sinh": 289, "sqrt": 290, "squareddiffer": 291, "subtract": 292, "tan": 293, "tanh": 294, "bitwiseand": 295, "bitwisenot": 296, "bitwiseor": 297, "bitwisexor": 298, "greater": 300, "greaterequ": 301, "isfinit": 302, "isinf": 303, "isnan": 304, "less": 305, "lessequ": 306, "notequ": 307, "bucket": 308, "If": 309, "nonzero": 310, "select": [311, 516, 539, 541], "binaryconvolut": 312, "convolut": [313, 519], "convolutionbackpropdata": 314, "deformableconvolut": [315, 316], "groupconvolut": 317, "groupconvolutionbackpropdata": 318, "deformablepsroipool": 319, "detectionoutput": [320, 321], "experimentaldetectrondetectionoutput": 322, "experimentaldetectrongenerateproposalssingleimag": 323, "experimentaldetectronpriorgridgener": 324, "experimentaldetectronroifeatureextractor": 325, "generatepropos": 326, "priorbox": [327, 328], "priorboxclust": 329, "propos": [330, 331], "psroipool": 332, "regionyolo": 333, "reorgyolo": 334, "roialign": [335, 336], "roialignrot": 337, "roipool": 338, "ey": 339, "multinomi": 340, "randomuniform": 341, "rang": [342, 343], "gridsampl": 344, "i420tobgr": 345, "i420torgb": 346, "interpol": [347, 348, 349], "nv12tobgr": 350, "nv12torgb": 351, "assign": [352, 353, 545], "loop": [355, 570], "readvalu": [357, 358], "tensoriter": [360, 570], "augrucel": 361, "augrusequ": 362, "logicaland": 363, "logicalnot": 364, "logicalor": 365, "logicalxor": 366, "einsum": 367, "invers": [368, 447, 448], "matmul": 369, "batchtospac": 370, "concat": 373, "depthtospac": 374, "extractimagepatch": 375, "gather": [376, 377, 378], "gatherel": 379, "gathernd": [380, 381], "gathertre": 382, "pad": [383, 384, 537], "posit": 384, "reversesequ": 386, "roll": 387, "scatterelementsupd": [388, 389], "scatterndupd": [390, 391], "scatterupd": 392, "shufflechannel": 393, "slice": 394, "spacetobatch": 395, "spacetodepth": 396, "split": 397, "stridedslic": 398, "tile": 399, "transpos": [400, 560], "uniqu": 401, "variadicsplit": 402, "batchnorminfer": [403, 404], "grn": 405, "groupnorm": 406, "lrn": 407, "mvn": [408, 409], "normalizel2": 410, "adaptiveavgpool": 411, "adaptivemaxpool": 412, "avgpool": [413, 414], "maxpool": [415, 416, 417], "pool": 418, "fakeconvert": 419, "reducel1": 421, "reducel2": 422, "reducelogicaland": 423, "reducelogicalor": 424, "reducemax": 425, "reducemean": 426, "reducemin": 427, "reduceprod": 428, "reducesum": 429, "ctcgreedydecod": 430, "ctcgreedydecoderseqlen": 431, "ctcloss": 432, "grucel": 433, "grusequ": 434, "lstmcell": 435, "lstmsequenc": 436, "onehot": 437, "rnncell": 438, "rnnsequenc": 439, "scaleddotproductattent": 440, "shapeof": [442, 443], "squeez": 444, "unsqueez": 445, "dft": 446, "discret": [447, 448, 449], "fourier": [447, 448, 449], "idft": 447, "complex": 448, "real": [448, 449], "irdft": 448, "rdft": 449, "experimentaldetectrontopkroi": 450, "matrixnonmaxsuppress": 451, "multiclassnonmaxsuppress": [452, 453], "nmsrotat": 454, "nonmaxsuppress": [455, 456, 457, 458, 459], "topk": [460, 461, 462], "embeddingbagoffsetssum": 463, "embeddingbagpackedsum": 464, "embeddingsegmentssum": 465, "convertlik": 467, "convertpromotetyp": 468, "encrypt": 470, "deploy": [470, 514, 572], "quick": [471, 518], "basic": [471, 502, 522, 556, 566], "interact": [471, 495], "code": [471, 516, 539, 540, 548, 558], "integr": [471, 549, 557, 558], "With": 471, "your": [471, 548, 549], "applic": [471, 504, 537, 544, 549, 558, 566, 569], "autom": 471, "flexibl": 471, "hardwar": 472, "processor": 473, "graphic": 473, "linux": [473, 476, 477, 482, 484, 490, 491, 540], "window": [473, 479, 489, 516, 572], "subsystem": 473, "wsl": 473, "distribut": [476, 477, 478, 483, 486, 487, 514, 515, 519, 520], "apt": 476, "uninstal": [476, 477, 478, 479, 480, 482, 488, 490, 491], "archiv": [477, 478, 479], "maco": [478, 485], "homebrew": 480, "conan": 481, "conda": 482, "forg": 482, "anaconda": 482, "docker": 483, "npm": 486, "registri": 486, "pypi": [487, 518], "verifi": 487, "vcpkg": 488, "yum": 490, "zypper": 491, "launch": 496, "shut": 496, "down": 496, "deactiv": 496, "reactiv": 496, "delet": 496, "openvino_env": 496, "hug": [498, 499], "face": [498, 499], "optimum": 498, "tune": [498, 519, 520, 522, 524], "lora": 498, "nativ": [499, 544], "full": 499, "text": [499, 500], "import": [499, 519, 520], "decod": 499, "displai": 499, "detoken": 500, "latenc": [502, 539, 552, 556, 562], "throughput": [502, 512, 539, 556, 564, 566, 567], "It": [503, 505, 506, 507, 508, 509, 510, 511, 512, 556], "media": 504, "hello": [505, 506, 507, 508], "nv12": [506, 544, 560], "queri": [507, 546, 548], "ssd": 508, "async": [509, 555, 556], "creation": [510, 544], "sync": 511, "deploi": [514, 519, 520], "local": [514, 515], "granular": 514, "major": 514, "pluggabl": 515, "binari": 516, "size": [516, 541, 567], "stage": 516, "statist": 516, "differ": 516, "isa": 516, "agnost": 516, "poc": 516, "analyz": [516, 540, 545], "dure": 518, "nncf": [518, 519, 520, 522, 523], "prune": [518, 519], "experiment": 518, "recommend": [518, 543], "appli": [519, 520, 522, 536, 570], "fine": [519, 520], "multi": [519, 520, 542, 543, 546, 566], "save": [519, 520, 558], "checkpoint": [519, 520], "8": [519, 520, 549], "restor": [519, 520], "awar": 520, "qat": 520, "post": [521, 522, 523, 560], "flow": 522, "calibr": [522, 523], "dataset": [522, 523], "metric": [523, 524], "gptq": 524, "state": [525, 542, 569, 570], "convert_model": 525, "extern": [527, 542], "torch": [529, 572], "benefit": 532, "set_batch": 535, "dynam": [536, 537, 542, 543, 547, 559], "Of": 536, "box": 536, "bound": [536, 543], "inferenc": 536, "when": 537, "partit": 537, "automat": [539, 541, 543, 545, 564], "candid": 539, "prioriti": 539, "exclud": 539, "cumulative_throughput": 539, "target": [539, 558], "individu": [539, 546, 556], "app": [539, 556], "instrument": 540, "trace": 540, "technologi": 540, "explicit": 541, "underli": 541, "consider": [541, 546, 567], "benchmark_app": [541, 556], "acceler": [542, 543], "cach": [542, 543, 547, 563], "depend": 542, "thread": 542, "denorm": 542, "spars": 542, "decompress": 542, "x86": 542, "64": 542, "convent": 543, "consumpt": 543, "improv": 543, "share": [543, 544, 552, 553], "remotetensor": [543, 544], "checklist": 543, "between": 544, "direct": [544, 552], "video": 544, "surfac": 544, "queue": 544, "heterogen": 545, "hetero": 545, "manual": 545, "affin": 545, "difficult": 545, "On": 546, "umd": 547, "alloc": 549, "link": 549, "project": 549, "script": 549, "roi": 550, "capabl": [551, 560], "hide": 552, "postpon": 552, "return": 552, "exclus": 553, "easier": 553, "ovdict": 553, "asyncinferqueu": 553, "acquir": 553, "u1": 553, "u4": 553, "i4": 553, "gil": 553, "portabl": 554, "prefer": [555, 556], "get_tensor": 555, "idiom": 555, "high": 556, "declar": 557, "Into": 558, "syntax": 559, "short": 559, "predefin": 559, "address": 560, "particular": 560, "normal": 560, "color": 560, "i420": 560, "torchvis": 561, "cache_dir": 563, "config": 563, "make": 563, "even": 563, "modelpath": 563, "further": 564, "wai": 566, "leverag": 566, "orient": 566, "design": 566, "few": 567, "obtain": 570, "makest": 570, "lowlatency2": 570, "string": 571, "automatic1111": 572, "stabl": 572, "diffus": 572, "webui": 572}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"About OpenVINO": [[0, "about-openvino"]], "Features": [[0, "features"]], "Architecture": [[0, "architecture"], [572, "architecture"]], "OpenVINO Ecosystem": [[0, "openvino-ecosystem"]], "Community": [[0, "community"]], "Case Studies": [[0, "case-studies"]], "Additional Resources": [[1, "additional-resources"], [49, "additional-resources"], [75, "additional-resources"], [82, "additional-resources"], [84, "additional-resources"], [112, "additional-resources"], [113, "additional-resources"], [114, "additional-resources"], [115, "additional-resources"], [118, "additional-resources"], [119, "additional-resources"], [120, "additional-resources"], [121, "additional-resources"], [122, "additional-resources"], [123, "additional-resources"], [124, "additional-resources"], [224, "additional-resources"], [470, "additional-resources"], [471, "additional-resources"], [473, "additional-resources"], [477, "additional-resources"], [478, "additional-resources"], [479, "additional-resources"], [481, "additional-resources"], [486, "additional-resources"], [487, "additional-resources"], [495, "additional-resources"], [496, "additional-resources"], [498, "additional-resources"], [499, "additional-resources"], [500, "additional-resources"], [501, "additional-resources"], [502, "additional-resources"], [503, "additional-resources"], [505, "additional-resources"], [506, "additional-resources"], [507, "additional-resources"], [508, "additional-resources"], [509, "additional-resources"], [510, "additional-resources"], [511, "additional-resources"], [512, "additional-resources"], [517, "additional-resources"], [518, "additional-resources"], [521, "additional-resources"], [524, "additional-resources"], [525, "additional-resources"], [527, "additional-resources"], [528, "additional-resources"], [532, "additional-resources"], [535, "additional-resources"], [539, "additional-resources"], [541, "additional-resources"], [542, "additional-resources"], [543, "additional-resources"], [546, "additional-resources"], [547, "additional-resources"], [549, "additional-resources"], [551, "additional-resources"], [554, "additional-resources"], [557, "additional-resources"], [558, "additional-resources"], [568, "additional-resources"], [571, "additional-resources"], [572, "additional-resources"]], "Glossary": [[2, "glossary"]], "Acronyms and Abbreviations": [[2, "acronyms-and-abbreviations"]], "Terms": [[2, "terms"]], "See Also": [[2, "see-also"], [129, "see-also"], [220, "see-also"], [221, "see-also"], [222, "see-also"], [223, "see-also"], [227, "see-also"], [544, "see-also"]], "Legal Information": [[3, "legal-information"], [13, "legal-information"], [15, "legal-information"]], "OpenVINO\u2122 Logo": [[3, "openvino-logo"]], "Logo Usage Guidelines": [[3, "logo-usage-guidelines"]], "Intel Global Human Right Principles": [[3, "intel-global-human-right-principles"]], "OpenVINO\u2122 Telemetry": [[4, "openvino-telemetry"]], "Enable or disable Telemetry reporting": [[4, "enable-or-disable-telemetry-reporting"]], "Changing consent decision": [[4, "changing-consent-decision"]], "Telemetry Data Collection Details": [[4, "telemetry-data-collection-details"]], "Compatibility and Support": [[5, "compatibility-and-support"]], "Inference Device Support": [[6, "inference-device-support"]], "Feature Support and API Coverage": [[6, "feature-support-and-api-coverage"]], "Supported Operations - by Framework Frontend": [[7, "supported-operations-by-framework-frontend"]], "Supported Operations - by Inference Devices": [[8, "supported-operations-by-inference-devices"]], "Performance Benchmarks": [[9, "performance-benchmarks"]], "Getting Performance Numbers": [[10, "getting-performance-numbers"]], "Model Accuracy": [[11, "model-accuracy"]], "Model Accuracy for INT8": [[11, "id1"]], "Model Accuracy for BF16, FP32 and FP16 (FP16: Flex-170 only. BF16: Xeon(R) 8490H only)": [[11, "id2"]], "Performance Information F.A.Q.": [[12, "performance-information-f-a-q"]], "OpenVINO Release Notes": [[13, "openvino-release-notes"]], "2024.1 - 24 April 2024": [[13, "april-2024"]], "What\u2019s new": [[13, "what-s-new"]], "OpenVINO\u2122 Runtime": [[13, "openvino-runtime"]], "Common": [[13, "common"]], "AUTO Inference Mode": [[13, "auto-inference-mode"]], "CPU Device Plugin": [[13, "cpu-device-plugin"]], "GPU Device Plugin": [[13, "gpu-device-plugin"]], "NPU Device Plugin": [[13, "npu-device-plugin"]], "OpenVINO Python API": [[13, "openvino-python-api"], [47, "openvino-python-api"]], "OpenVINO C API": [[13, "openvino-c-api"]], "OpenVINO Node.js API": [[13, "openvino-node-js-api"]], "TensorFlow Framework Support": [[13, "tensorflow-framework-support"]], "PyTorch Framework Support": [[13, "pytorch-framework-support"]], "ONNX Framework Support": [[13, "onnx-framework-support"]], "OpenVINO Model Server": [[13, "openvino-model-server"]], "Neural Network Compression Framework": [[13, "neural-network-compression-framework"]], "OpenVINO Tokenizers": [[13, "openvino-tokenizers"], [500, "openvino-tokenizers"]], "Other Changes and Known Issues": [[13, "other-changes-and-known-issues"]], "Jupyter Notebooks": [[13, "jupyter-notebooks"]], "Known Issues": [[13, "known-issues"]], "Previous 2024 releases": [[13, "previous-2024-releases"]], "Deprecation And Support": [[13, "deprecation-and-support"]], "Discontinued in 2024": [[13, "discontinued-in-2024"]], "Deprecated and to be removed in the future": [[13, "deprecated-and-to-be-removed-in-the-future"]], "Release Policy": [[14, "release-policy"]], "Regular releases": [[14, "regular-releases"]], "Long-Term Support releases": [[14, "long-term-support-releases"]], "Nightly releases": [[14, "nightly-releases"]], "Additional Information": [[14, "additional-information"]], "System Requirements": [[15, "system-requirements"], [479, "system-requirements"]], "CPU": [[15, "cpu"]], "GPU": [[15, "gpu"]], "Intel\u00ae Neural Processing Unit": [[15, "intel-neural-processing-unit"]], "Operating systems and developer environment": [[15, "operating-systems-and-developer-environment"]], "API Reference": [[16, "api-reference"]], "openvino": [[17, "module-openvino"]], "openvino.frontend": [[18, "openvino-frontend"]], "openvino.preprocess": [[19, "openvino-preprocess"]], "openvino.properties": [[20, "openvino-properties"]], "openvino.properties.device": [[21, "openvino-properties-device"]], "openvino.properties.hint": [[22, "openvino-properties-hint"]], "openvino.properties.intel_auto": [[23, "openvino-properties-intel-auto"]], "openvino.properties.intel_cpu": [[24, "openvino-properties-intel-cpu"]], "openvino.properties.intel_gpu": [[25, "openvino-properties-intel-gpu"]], "openvino.properties.intel_gpu.hint": [[26, "module-openvino.properties.intel_gpu.hint"]], "openvino.properties.log": [[27, "openvino-properties-log"]], "openvino.properties.streams": [[28, "openvino-properties-streams"]], "openvino.runtime": [[29, "openvino-runtime"]], "openvino.runtime.op": [[30, "openvino-runtime-op"]], "openvino.runtime.op.util": [[31, "module-openvino.runtime.op.util"]], "openvino.runtime.opset1": [[32, "openvino-runtime-opset1"]], "openvino.runtime.opset10": [[33, "openvino-runtime-opset10"]], "openvino.runtime.opset11": [[34, "openvino-runtime-opset11"]], "openvino.runtime.opset12": [[35, "openvino-runtime-opset12"]], "openvino.runtime.opset13": [[36, "openvino-runtime-opset13"]], "openvino.runtime.opset14": [[37, "module-openvino.runtime.opset14"]], "openvino.runtime.opset2": [[38, "openvino-runtime-opset2"]], "openvino.runtime.opset3": [[39, "openvino-runtime-opset3"]], "openvino.runtime.opset4": [[40, "openvino-runtime-opset4"]], "openvino.runtime.opset5": [[41, "openvino-runtime-opset5"]], "openvino.runtime.opset6": [[42, "openvino-runtime-opset6"]], "openvino.runtime.opset7": [[43, "openvino-runtime-opset7"]], "openvino.runtime.opset8": [[44, "openvino-runtime-opset8"]], "openvino.runtime.opset9": [[45, "openvino-runtime-opset9"]], "openvino.runtime.passes": [[46, "module-openvino.runtime.passes"]], "Property addon": [[48, "property-addon"]], "Properties": [[48, "properties"], [52, "properties"], [59, "properties"], [60, "properties"], [68, "properties"]], "OpenVINO\u2122 Node.js Bindings": [[49, "openvino-node-js-bindings"]], "Usage": [[49, "usage"]], "Build From Sources": [[49, "build-from-sources"]], "Enumeration element": [[50, "enumeration-element"]], "Enumeration resizeAlgorithm": [[51, "enumeration-resizealgorithm"]], "Interface CompiledModel": [[52, "interface-compiledmodel"]], "Methods": [[52, "methods"], [53, "methods"], [55, "methods"], [56, "methods"], [57, "methods"], [58, "methods"], [59, "methods"], [60, "methods"], [61, "methods"], [62, "methods"], [63, "methods"], [65, "methods"], [67, "methods"], [68, "methods"]], "Interface Core": [[53, "interface-core"]], "Interface CoreConstructor": [[54, "interface-coreconstructor"]], "Constructors": [[54, "constructors"], [64, "constructors"], [66, "constructors"], [69, "constructors"]], "InferRequest": [[55, "inferrequest"]], "Interface InputInfo": [[56, "interface-inputinfo"]], "Interface InputModelInfo": [[57, "interface-inputmodelinfo"]], "Interface InputTensorInfo": [[58, "interface-inputtensorinfo"]], "Interface Model": [[59, "interface-model"]], "Interface Output": [[60, "interface-output"]], "Interface OutputInfo": [[61, "interface-outputinfo"]], "Interface OutputTensorInfo": [[62, "interface-outputtensorinfo"]], "Interface PartialShape": [[63, "interface-partialshape"]], "Interface PartialShapeConstructor": [[64, "interface-partialshapeconstructor"]], "Interface PrePostProcessor": [[65, "interface-prepostprocessor"]], "Interface PrePostProcessorConstructor": [[66, "interface-prepostprocessorconstructor"]], "Interface PreProcessSteps": [[67, "interface-preprocesssteps"]], "Interface Tensor": [[68, "interface-tensor"]], "Interface TensorConstructor": [[69, "interface-tensorconstructor"]], "Type alias Dimension": [[70, "type-alias-dimension"]], "Type alias SupportedTypedArray": [[71, "type-alias-supportedtypedarray"]], "Type alias elementTypeString": [[72, "type-alias-elementtypestring"]], "Documentation": [[73, "documentation"]], "Legacy Features and Components": [[74, "legacy-features-and-components"]], "Discontinued:": [[74, "discontinued"]], "Install OpenVINO\u2122 Development Tools": [[75, "install-openvino-development-tools"]], "For Python Developers": [[75, "for-python-developers"]], "For C/C++ Developers": [[75, "for-c-c-developers"]], "Installing OpenVINO\u2122 Development Tools": [[75, "installing-openvino-development-tools"]], "Installation into an Existing Environment with the Source Deep Learning Framework": [[75, "installation-into-an-existing-environment-with-the-source-deep-learning-framework"]], "Installation in a New Environment": [[75, "installation-in-a-new-environment"]], "Step 1. Set Up Python Virtual Environment": [[75, "step-1-set-up-python-virtual-environment"], [487, "step-1-set-up-python-virtual-environment"]], "Step 2. Activate Virtual Environment": [[75, "step-2-activate-virtual-environment"], [487, "step-2-activate-virtual-environment"]], "Step 3. Set Up and Update PIP to the Highest Version": [[75, "step-3-set-up-and-update-pip-to-the-highest-version"], [487, "step-3-set-up-and-update-pip-to-the-highest-version"]], "Step 4. Install the Package": [[75, "step-4-install-the-package"], [487, "step-4-install-the-package"]], "Step 5. Test the Installation": [[75, "step-5-test-the-installation"]], "What\u2019s Next?": [[75, "what-s-next"], [476, "what-s-next"], [477, "what-s-next"], [478, "what-s-next"], [479, "what-s-next"], [480, "what-s-next"], [482, "what-s-next"], [486, "what-s-next"], [487, "what-s-next"], [488, "what-s-next"], [490, "what-s-next"], [491, "what-s-next"]], "Get started with Python": [[75, "get-started-with-python"], [487, "get-started-with-python"]], "Get started with C++": [[75, "get-started-with-c"]], "Learn OpenVINO Development Tools": [[75, "learn-openvino-development-tools"]], "Model Zoo": [[76, "model-zoo"]], "Transition from Legacy Conversion API": [[77, "transition-from-legacy-conversion-api"]], "Parameters Comparison": [[77, "parameters-comparison"]], "Transition from Legacy API to New API": [[77, "transition-from-legacy-api-to-new-api"]], "input_shape": [[77, "input-shape"]], "batch": [[77, "batch"]], "mean_values": [[77, "mean-values"]], "scale_values": [[77, "scale-values"]], "reverse_input_channels": [[77, "reverse-input-channels"]], "source_layout": [[77, "source-layout"]], "target_layout": [[77, "target-layout"]], "layout": [[77, "layout"]], "transform": [[77, "transform"]], "Cutting Off Parts of a Model": [[77, "cutting-off-parts-of-a-model"]], "PyTorch": [[77, "pytorch"]], "TensorFlow protobuf format / tf.Graph / tf.GraphDef": [[77, "tensorflow-protobuf-format-tf-graph-tf-graphdef"]], "TensorFlow SavedModel format": [[77, "tensorflow-savedmodel-format"]], "ONNX": [[77, "onnx"]], "Supported Frameworks in MO vs OVC": [[77, "supported-frameworks-in-mo-vs-ovc"]], "Legacy Conversion API": [[78, "legacy-conversion-api"]], "Examples of model conversion parameters": [[78, "examples-of-model-conversion-parameters"]], "[LEGACY] Compressing a Model to FP16": [[79, "legacy-compressing-a-model-to-fp16"]], "[LEGACY] Convert Models Represented as Python Objects": [[80, "legacy-convert-models-represented-as-python-objects"]], "[LEGACY] Cutting Off Parts of a Model": [[81, "legacy-cutting-off-parts-of-a-model"]], "Purpose of Model Cutting": [[81, "purpose-of-model-cutting"]], "Model conversion API parameters": [[81, "model-conversion-api-parameters"]], "Default Behavior without input and output": [[81, "default-behavior-without-input-and-output"]], "Model Cutting": [[81, "model-cutting"]], "Cutting at the End": [[81, "cutting-at-the-end"]], "Cutting from the Beginning": [[81, "cutting-from-the-beginning"]], "Inputs with Multiple Input Ports": [[81, "inputs-with-multiple-input-ports"]], "[LEGACY] Embedding Preprocessing Computation": [[82, "legacy-embedding-preprocessing-computation"]], "Specifying Layout": [[82, "specifying-layout"]], "Changing Model Layout": [[82, "changing-model-layout"]], "Specifying Mean and Scale Values": [[82, "specifying-mean-and-scale-values"]], "Reversing Input Channels": [[82, "reversing-input-channels"]], "[LEGACY] Model Optimizer Frequently Asked Questions": [[83, "legacy-model-optimizer-frequently-asked-questions"]], "Q1. What does the message \u201c[ ERROR ]: Current caffe.proto does not contain field\u201d mean?": [[83, "q1-what-does-the-message-error-current-caffe-proto-does-not-contain-field-mean"]], "Q2. How do I create a bare caffemodel, if I have only prototxt?": [[83, "q2-how-do-i-create-a-bare-caffemodel-if-i-have-only-prototxt"]], "Q3. What does the message \u201c[ ERROR ]: Unable to create ports for node with id\u201d mean?": [[83, "q3-what-does-the-message-error-unable-to-create-ports-for-node-with-id-mean"]], "Q7. What does the message \u201cInvalid proto file: there is neither \u2018layer\u2019 nor \u2018layers\u2019 top-level messages\u201d mean?": [[83, "q7-what-does-the-message-invalid-proto-file-there-is-neither-layer-nor-layers-top-level-messages-mean"]], "Q8. What does the message \u201cOld-style inputs (via \u2018input_dims\u2019) are not supported. Please specify inputs via \u2018input_shape\u2019\u201d mean?": [[83, "q8-what-does-the-message-old-style-inputs-via-input-dims-are-not-supported-please-specify-inputs-via-input-shape-mean"]], "Q9. What does the message \u201cMean file for topologies with multiple inputs is not supported\u201d mean?": [[83, "q9-what-does-the-message-mean-file-for-topologies-with-multiple-inputs-is-not-supported-mean"]], "Q11. What does the message \u201cInvalid prototxt file: value error\u201d mean?": [[83, "q11-what-does-the-message-invalid-prototxt-file-value-error-mean"]], "Q12. What does the message \u201cError happened while constructing caffe.Net in the Caffe fallback function\u201d mean?": [[83, "q12-what-does-the-message-error-happened-while-constructing-caffe-net-in-the-caffe-fallback-function-mean"]], "Q13. What does the message \u201cCannot infer shapes due to exception in Caffe\u201d mean?": [[83, "q13-what-does-the-message-cannot-infer-shapes-due-to-exception-in-caffe-mean"]], "Q14. What does the message \u201cCannot infer shape for node {} because there is no Caffe available. Please register python infer function for op or use Caffe for shape inference\u201d mean?": [[83, "q14-what-does-the-message-cannot-infer-shape-for-node-because-there-is-no-caffe-available-please-register-python-infer-function-for-op-or-use-caffe-for-shape-inference-mean"]], "Q15. What does the message \u201cFramework name can not be deduced from the given options. Use \u2013framework to choose one of Caffe, TensorFlow, MXNet\u201d mean?": [[83, "q15-what-does-the-message-framework-name-can-not-be-deduced-from-the-given-options-use-framework-to-choose-one-of-caffe-tensorflow-mxnet-mean"]], "Q16. What does the message \u201cInput shape is required to convert MXNet model. Please provide it with \u2013input_shape\u201d mean?": [[83, "q16-what-does-the-message-input-shape-is-required-to-convert-mxnet-model-please-provide-it-with-input-shape-mean"]], "Q19. What does the message \u201cBoth \u2013scale and \u2013scale_values are defined. Specify either scale factor or scale values per input channels\u201d mean?": [[83, "q19-what-does-the-message-both-scale-and-scale-values-are-defined-specify-either-scale-factor-or-scale-values-per-input-channels-mean"]], "Q20. What does the message \u201cCannot find prototxt file: for Caffe please specify \u2013input_proto - a protobuf file that stores topology and \u2013input_model that stores pre-trained weights\u201d mean?": [[83, "q20-what-does-the-message-cannot-find-prototxt-file-for-caffe-please-specify-input-proto-a-protobuf-file-that-stores-topology-and-input-model-that-stores-pre-trained-weights-mean"]], "Q22. What does the message \u201cFailed to create directory .. . Permission denied!\u201d mean?": [[83, "q22-what-does-the-message-failed-to-create-directory-permission-denied-mean"]], "Q23. What does the message \u201cDiscovered data node without inputs and value\u201d mean?": [[83, "q23-what-does-the-message-discovered-data-node-without-inputs-and-value-mean"]], "Q24. What does the message \u201cPart of the nodes was not translated to IE. Stopped\u201d mean?": [[83, "q24-what-does-the-message-part-of-the-nodes-was-not-translated-to-ie-stopped-mean"]], "Q25. What does the message \u201cWhile creating an edge from .. to .. : node name is undefined in the graph. Check correctness of the input model\u201d mean?": [[83, "q25-what-does-the-message-while-creating-an-edge-from-to-node-name-is-undefined-in-the-graph-check-correctness-of-the-input-model-mean"]], "Q26. What does the message \u201cNode does not exist in the graph\u201d mean?": [[83, "q26-what-does-the-message-node-does-not-exist-in-the-graph-mean"]], "Q27. What does the message \u201c\u2013input parameter was provided. Other inputs are needed for output computation. Provide more inputs or choose another place to cut the net\u201d mean?": [[83, "q27-what-does-the-message-input-parameter-was-provided-other-inputs-are-needed-for-output-computation-provide-more-inputs-or-choose-another-place-to-cut-the-net-mean"]], "Q28. What does the message \u201cPlaceholder node does not have an input port, but input port was provided\u201d mean?": [[83, "q28-what-does-the-message-placeholder-node-does-not-have-an-input-port-but-input-port-was-provided-mean"]], "Q29. What does the message \u201cPort index is out of number of available input ports for node\u201d mean?": [[83, "q29-what-does-the-message-port-index-is-out-of-number-of-available-input-ports-for-node-mean"]], "Q30. What does the message \u201cNode has more than 1 input and input shapes were provided. Try not to provide input shapes or specify input port with PORT:NODE notation, where PORT is an integer\u201d mean?": [[83, "q30-what-does-the-message-node-has-more-than-1-input-and-input-shapes-were-provided-try-not-to-provide-input-shapes-or-specify-input-port-with-port-node-notation-where-port-is-an-integer-mean"]], "Q31. What does the message \u201cInput port > 0 in \u2013input is not supported if \u2013input_shape is not provided. Node: NAME_OF_THE_NODE. Omit port index and all input ports will be replaced by placeholders. Or provide \u2013input_shape\u201d mean?": [[83, "q31-what-does-the-message-input-port-0-in-input-is-not-supported-if-input-shape-is-not-provided-node-name-of-the-node-omit-port-index-and-all-input-ports-will-be-replaced-by-placeholders-or-provide-input-shape-mean"]], "Q32. What does the message \u201cNo or multiple placeholders in the model, but only one shape is provided, cannot set it\u201d mean?": [[83, "q32-what-does-the-message-no-or-multiple-placeholders-in-the-model-but-only-one-shape-is-provided-cannot-set-it-mean"]], "Q33. What does the message \u201cThe amount of input nodes for port is not equal to 1\u201d mean?": [[83, "q33-what-does-the-message-the-amount-of-input-nodes-for-port-is-not-equal-to-1-mean"]], "Q34. What does the message \u201cOutput node for port has already been specified\u201d mean?": [[83, "q34-what-does-the-message-output-node-for-port-has-already-been-specified-mean"]], "Q35. What does the message \u201cUnsupported match kind\u2026. Match kinds \u201cpoints\u201d or \u201cscope\u201d are supported only\u201d mean?": [[83, "q35-what-does-the-message-unsupported-match-kind-match-kinds-points-or-scope-are-supported-only-mean"]], "Q36. What does the message \u201cCannot write an event file for the TensorBoard to directory\u201d mean?": [[83, "q36-what-does-the-message-cannot-write-an-event-file-for-the-tensorboard-to-directory-mean"]], "Q37. What does the message \u201cThere is no registered \u2018infer\u2019 function for node  with op = .. . Please implement this function in the extensions\u201d mean?": [[83, "q37-what-does-the-message-there-is-no-registered-infer-function-for-node-with-op-please-implement-this-function-in-the-extensions-mean"]], "Q38. What does the message \u201cStopped shape/value propagation at node\u201d mean?": [[83, "q38-what-does-the-message-stopped-shape-value-propagation-at-node-mean"]], "Q39. What does the message \u201cThe input with shape .. does not have the batch dimension\u201d mean?": [[83, "q39-what-does-the-message-the-input-with-shape-does-not-have-the-batch-dimension-mean"]], "Q40. What does the message \u201cNot all output shapes were inferred or fully defined for node\u201d mean?": [[83, "q40-what-does-the-message-not-all-output-shapes-were-inferred-or-fully-defined-for-node-mean"]], "Q41. What does the message \u201cShape for tensor is not defined. Can not proceed\u201d mean?": [[83, "q41-what-does-the-message-shape-for-tensor-is-not-defined-can-not-proceed-mean"]], "Q42. What does the message \u201cModule TensorFlow was not found. Please install TensorFlow 1.2 or higher\u201d mean?": [[83, "q42-what-does-the-message-module-tensorflow-was-not-found-please-install-tensorflow-1-2-or-higher-mean"]], "Q43. What does the message \u201cCannot read the model file: it is incorrect TensorFlow model file or missing\u201d mean?": [[83, "q43-what-does-the-message-cannot-read-the-model-file-it-is-incorrect-tensorflow-model-file-or-missing-mean"]], "Q44. What does the message \u201cCannot pre-process TensorFlow graph after reading from model file. File is corrupt or has unsupported format\u201d mean?": [[83, "q44-what-does-the-message-cannot-pre-process-tensorflow-graph-after-reading-from-model-file-file-is-corrupt-or-has-unsupported-format-mean"]], "Q45. What does the message \u201cFound custom layer. Model Optimizer does not support this layer. Please, register it in CustomLayersMapping.xml or implement extension\u201d mean?": [[83, "q45-what-does-the-message-found-custom-layer-model-optimizer-does-not-support-this-layer-please-register-it-in-customlayersmapping-xml-or-implement-extension-mean"]], "Q46. What does the message \u201cCustom replacement configuration file does not exist\u201d mean?": [[83, "q46-what-does-the-message-custom-replacement-configuration-file-does-not-exist-mean"]], "Q47. What does the message \u201cExtractors collection have case insensitive duplicates\u201d mean?": [[83, "q47-what-does-the-message-extractors-collection-have-case-insensitive-duplicates-mean"]], "Q48. What does the message \u201cInput model name is not in an expected format, cannot extract iteration number\u201d mean?": [[83, "q48-what-does-the-message-input-model-name-is-not-in-an-expected-format-cannot-extract-iteration-number-mean"]], "Q49. What does the message \u201cCannot convert type of placeholder because not all of its outputs are \u2018Cast\u2019 to float operations\u201d mean?": [[83, "q49-what-does-the-message-cannot-convert-type-of-placeholder-because-not-all-of-its-outputs-are-cast-to-float-operations-mean"]], "Q50. What does the message \u201cData type is unsupported\u201d mean?": [[83, "q50-what-does-the-message-data-type-is-unsupported-mean"]], "Q51. What does the message \u201cNo node with name \u2026\u201d mean?": [[83, "q51-what-does-the-message-no-node-with-name-mean"]], "Q52. What does the message \u201cModule MXNet was not found. Please install MXNet 1.0.0\u201d mean?": [[83, "q52-what-does-the-message-module-mxnet-was-not-found-please-install-mxnet-1-0-0-mean"]], "Q53. What does the message \u201cThe following error happened while loading MXNet model ..\u201d mean?": [[83, "q53-what-does-the-message-the-following-error-happened-while-loading-mxnet-model-mean"]], "Q54. What does the message \u201cThe following error happened while processing input shapes: ..\u201d mean?": [[83, "q54-what-does-the-message-the-following-error-happened-while-processing-input-shapes-mean"]], "Q55. What does the message \u201cAttempt to register of custom name for the second time as class. Note that custom names are case-insensitive\u201d mean?": [[83, "q55-what-does-the-message-attempt-to-register-of-custom-name-for-the-second-time-as-class-note-that-custom-names-are-case-insensitive-mean"]], "Q56. What does the message \u201cBoth \u2013input_shape and \u2013batch were provided. Please, provide only one of them\u201d mean?": [[83, "q56-what-does-the-message-both-input-shape-and-batch-were-provided-please-provide-only-one-of-them-mean"]], "Q57. What does the message \u201cInput shape .. cannot be parsed\u201d mean?": [[83, "q57-what-does-the-message-input-shape-cannot-be-parsed-mean"]], "Q58. What does the message \u201cPlease provide input layer names for input layer shapes\u201d mean?": [[83, "q58-what-does-the-message-please-provide-input-layer-names-for-input-layer-shapes-mean"]], "Q59. What does the message \u201cValues cannot be parsed\u201d mean?": [[83, "q59-what-does-the-message-values-cannot-be-parsed-mean"]], "Q60. What does the message \u201c.. channels are expected for given values\u201d mean?": [[83, "q60-what-does-the-message-channels-are-expected-for-given-values-mean"]], "Q61. What does the message \u201cYou should specify input for each mean value\u201d mean?": [[83, "q61-what-does-the-message-you-should-specify-input-for-each-mean-value-mean"]], "Q62. What does the message \u201cYou should specify input for each scale value\u201d mean?": [[83, "q62-what-does-the-message-you-should-specify-input-for-each-scale-value-mean"]], "Q63. What does the message \u201cNumber of inputs and mean values does not match\u201d mean?": [[83, "q63-what-does-the-message-number-of-inputs-and-mean-values-does-not-match-mean"]], "Q64. What does the message \u201cNumber of inputs and scale values does not match\u201d mean?": [[83, "q64-what-does-the-message-number-of-inputs-and-scale-values-does-not-match-mean"]], "Q65. What does the message \u201cNo class registered for match kind \u2026 Supported match kinds are .. \u201c mean?": [[83, "q65-what-does-the-message-no-class-registered-for-match-kind-supported-match-kinds-are-mean"]], "Q66. What does the message \u201cNo instance(s) is(are) defined for the custom replacement\u201d mean?": [[83, "q66-what-does-the-message-no-instance-s-is-are-defined-for-the-custom-replacement-mean"]], "Q67. What does the message \u201cThe instance must be a single dictionary for the custom replacement with id ..\u201d mean?": [[83, "q67-what-does-the-message-the-instance-must-be-a-single-dictionary-for-the-custom-replacement-with-id-mean"]], "Q68. What does the message \u201cNo instances are defined for replacement with id .. \u201c mean?": [[83, "q68-what-does-the-message-no-instances-are-defined-for-replacement-with-id-mean"]], "Q69. What does the message \u201cCustom replacements configuration file .. does not exist\u201d mean?": [[83, "q69-what-does-the-message-custom-replacements-configuration-file-does-not-exist-mean"]], "Q70. What does the message \u201cFailed to parse custom replacements configuration file ..\u201d mean?": [[83, "q70-what-does-the-message-failed-to-parse-custom-replacements-configuration-file-mean"]], "Q71. What does the message \u201cOne of the custom replacements in the configuration file .. does not contain attribute \u2018id\u2019\u201d mean?": [[83, "q71-what-does-the-message-one-of-the-custom-replacements-in-the-configuration-file-does-not-contain-attribute-id-mean"]], "Q72. What does the message \u201cFile .. validation failed\u201d mean?": [[83, "q72-what-does-the-message-file-validation-failed-mean"]], "Q73. What does the message \u201cCannot update the file .. because it is broken\u201d mean?": [[83, "q73-what-does-the-message-cannot-update-the-file-because-it-is-broken-mean"]], "Q74. What does the message \u201cEnd node .. is not reachable from start nodes: ..\u201d mean?": [[83, "q74-what-does-the-message-end-node-is-not-reachable-from-start-nodes-mean"]], "Q75. What does the message \u201cSub-graph contains network input node ..\u201d mean?": [[83, "q75-what-does-the-message-sub-graph-contains-network-input-node-mean"]], "Q76. What does the message \u201c\u2026 elements of \u2026 were clipped to infinity while converting a blob for node [\u2026] to \u2026\u201d mean?": [[83, "q76-what-does-the-message-elements-of-were-clipped-to-infinity-while-converting-a-blob-for-node-to-mean"]], "Q77. What does the message \u201c\u2026 elements of \u2026 were clipped to zero while converting a blob for node [\u2026] to \u2026\u201d mean?": [[83, "q77-what-does-the-message-elements-of-were-clipped-to-zero-while-converting-a-blob-for-node-to-mean"]], "Q78. What does the message \u201cThe amount of nodes matched pattern \u2026 is not equal to 1\u201d mean?": [[83, "q78-what-does-the-message-the-amount-of-nodes-matched-pattern-is-not-equal-to-1-mean"]], "Q79. What does the message \u201cThe topology contains no \u201cinput\u201d layers\u201d mean?": [[83, "q79-what-does-the-message-the-topology-contains-no-input-layers-mean"]], "Q80. What does the message \u201cWarning: please expect that Model Optimizer conversion might be slow\u201d mean?": [[83, "q80-what-does-the-message-warning-please-expect-that-model-optimizer-conversion-might-be-slow-mean"]], "Q81. What does the message \u201cArguments \u2013nd_prefix_name, \u2013pretrained_model_name and \u2013input_symbol should be provided. Please provide all or do not use any.\u201d mean?": [[83, "q81-what-does-the-message-arguments-nd-prefix-name-pretrained-model-name-and-input-symbol-should-be-provided-please-provide-all-or-do-not-use-any-mean"]], "Q82. What does the message \u201cYou should specify input for mean/scale values\u201d mean?": [[83, "q82-what-does-the-message-you-should-specify-input-for-mean-scale-values-mean"]], "Q83. What does the message \u201cInput with name \u2026 not found!\u201d mean?": [[83, "q83-what-does-the-message-input-with-name-not-found-mean"]], "Q84. What does the message \u201cSpecified input json \u2026 does not exist\u201d mean?": [[83, "q84-what-does-the-message-specified-input-json-does-not-exist-mean"]], "Q85. What does the message \u201cUnsupported Input model file type \u2026 Model Optimizer support only .params and .nd files format\u201d mean?": [[83, "q85-what-does-the-message-unsupported-input-model-file-type-model-optimizer-support-only-params-and-nd-files-format-mean"]], "Q86. What does the message \u201cOperation \u2026 not supported. Please register it as custom op\u201d mean?": [[83, "q86-what-does-the-message-operation-not-supported-please-register-it-as-custom-op-mean"]], "Q87. What does the message \u201cCan not register Op \u2026 Please, call function \u2018register_caffe_python_extractor\u2019 with parameter \u2018name\u2019\u201d mean?": [[83, "q87-what-does-the-message-can-not-register-op-please-call-function-register-caffe-python-extractor-with-parameter-name-mean"]], "Q88. What does the message \u201cModel Optimizer is unable to calculate output shape of Memory node ..\u201d mean?": [[83, "q88-what-does-the-message-model-optimizer-is-unable-to-calculate-output-shape-of-memory-node-mean"]], "Q89. What do the messages \u201cFile \u2026  does not appear to be a Kaldi file (magic number does not match)\u201d, \u201cKaldi model should start with <Nnet> tag\u201d mean?": [[83, "q89-what-do-the-messages-file-does-not-appear-to-be-a-kaldi-file-magic-number-does-not-match-kaldi-model-should-start-with-nnet-tag-mean"]], "Q90. What do the messages \u201cExpect counts file to be one-line file.\u201d or \u201cExpect counts file to contain list of integers\u201d mean?": [[83, "q90-what-do-the-messages-expect-counts-file-to-be-one-line-file-or-expect-counts-file-to-contain-list-of-integers-mean"]], "Q91. What does the message \u201cModel Optimizer is not able to read Kaldi model ..\u201d mean?": [[83, "q91-what-does-the-message-model-optimizer-is-not-able-to-read-kaldi-model-mean"]], "Q92. What does the message \u201cModel Optimizer is not able to read counts file  ..\u201d mean?": [[83, "q92-what-does-the-message-model-optimizer-is-not-able-to-read-counts-file-mean"]], "Q93. What does the message \u201cFor legacy MXNet models Model Optimizer does not support conversion of old MXNet models (trained with 1.0.0 version of MXNet and lower) with custom layers.\u201d mean?": [[83, "q93-what-does-the-message-for-legacy-mxnet-models-model-optimizer-does-not-support-conversion-of-old-mxnet-models-trained-with-1-0-0-version-of-mxnet-and-lower-with-custom-layers-mean"]], "Q94. What does the message \u201cExpected token </ParallelComponent>, has ...\u201d mean?": [[83, "q94-what-does-the-message-expected-token-parallelcomponent-has-mean"]], "Q97. What does the message \u201cGraph contains a cycle. Can not proceed ..\u201d mean?": [[83, "q97-what-does-the-message-graph-contains-a-cycle-can-not-proceed-mean"]], "Q100. What does the message \u201cInterp layer shape inference function may be wrong, please, try to update layer shape inference function in the file (extensions/ops/interp.op at the line \u2026).\u201d mean?": [[83, "q100-what-does-the-message-interp-layer-shape-inference-function-may-be-wrong-please-try-to-update-layer-shape-inference-function-in-the-file-extensions-ops-interp-op-at-the-line-mean"]], "Q101. What does the message \u201cMean/scale values should \u2026\u201d mean?": [[83, "q101-what-does-the-message-mean-scale-values-should-mean"]], "Q102. What does the message \u201cOperation _contrib_box_nms is not supported \u2026\u201d mean?": [[83, "q102-what-does-the-message-operation-contrib-box-nms-is-not-supported-mean"]], "Q103. What does the message \u201cModelOptimizer is not able to parse *.caffemodel\u201d mean?": [[83, "q103-what-does-the-message-modeloptimizer-is-not-able-to-parse-caffemodel-mean"]], "Q105. What does the message \u201cThe IR preparation was executed by the legacy MO path. \u2026\u201d mean?": [[83, "q105-what-does-the-message-the-ir-preparation-was-executed-by-the-legacy-mo-path-mean"]], "[LEGACY] Setting Input Shapes": [[84, "legacy-setting-input-shapes"]], "Specifying input_shape parameter": [[84, "specifying-input-shape-parameter"]], "[LEGACY] Supported Model Formats": [[85, "legacy-supported-model-formats"]], "[LEGACY] Model Conversion Tutorials": [[86, "legacy-model-conversion-tutorials"]], "Converting an ONNX Faster R-CNN Model": [[87, "converting-an-onnx-faster-r-cnn-model"]], "Converting an ONNX GPT-2 Model": [[88, "converting-an-onnx-gpt-2-model"]], "Downloading the Pre-Trained Base GPT-2 Model": [[88, "downloading-the-pre-trained-base-gpt-2-model"]], "Converting an ONNX GPT-2 Model to IR": [[88, "converting-an-onnx-gpt-2-model-to-ir"]], "Converting an ONNX Mask R-CNN Model": [[89, "converting-an-onnx-mask-r-cnn-model"]], "Converting a PyTorch BERT-NER Model": [[90, "converting-a-pytorch-bert-ner-model"]], "Downloading and Converting the Model to ONNX": [[90, "downloading-and-converting-the-model-to-onnx"], [92, "downloading-and-converting-the-model-to-onnx"], [94, "downloading-and-converting-the-model-to-onnx"]], "Converting an ONNX BERT-NER model to IR": [[90, "converting-an-onnx-bert-ner-model-to-ir"]], "Converting a PyTorch Cascade RCNN R-101 Model": [[91, "converting-a-pytorch-cascade-rcnn-r-101-model"]], "Downloading and Converting Model to ONNX": [[91, "downloading-and-converting-model-to-onnx"]], "Converting an ONNX Cascade RCNN R-101 Model to OpenVINO IR": [[91, "converting-an-onnx-cascade-rcnn-r-101-model-to-openvino-ir"]], "Converting a PyTorch F3Net Model": [[92, "converting-a-pytorch-f3net-model"]], "Cloning the F3Net Repository": [[92, "cloning-the-f3net-repository"]], "Converting an ONNX F3Net Model to IR": [[92, "converting-an-onnx-f3net-model-to-ir"]], "Converting a PyTorch QuartzNet Model": [[93, "converting-a-pytorch-quartznet-model"]], "Downloading the Pre-trained QuartzNet Model": [[93, "downloading-the-pre-trained-quartznet-model"]], "Converting an ONNX QuartzNet model to IR": [[93, "converting-an-onnx-quartznet-model-to-ir"]], "Converting a PyTorch RCAN Model": [[94, "converting-a-pytorch-rcan-model"]], "Converting an ONNX RCAN Model to IR": [[94, "converting-an-onnx-rcan-model-to-ir"]], "Converting a PyTorch RNN-T Model": [[95, "converting-a-pytorch-rnn-t-model"]], "Converting a PyTorch YOLACT Model": [[96, "converting-a-pytorch-yolact-model"]], "Creating a Patch File": [[96, "creating-a-patch-file"], [103, "creating-a-patch-file"]], "Converting a YOLACT Model to the OpenVINO IR format": [[96, "converting-a-yolact-model-to-the-openvino-ir-format"]], "Converting a TensorFlow Attention OCR Model": [[97, "converting-a-tensorflow-attention-ocr-model"]], "Extracting a Model from aocr Library": [[97, "extracting-a-model-from-aocr-library"]], "Converting the TensorFlow AOCR Model to IR": [[97, "converting-the-tensorflow-aocr-model-to-ir"]], "Converting a TensorFlow BERT Model": [[98, "converting-a-tensorflow-bert-model"]], "Supported Models": [[98, "supported-models"], [110, "supported-models"]], "Downloading the Pretrained BERT Model": [[98, "downloading-the-pretrained-bert-model"]], "Converting a TensorFlow BERT Model to IR": [[98, "converting-a-tensorflow-bert-model-to-ir"]], "Converting a Reshapable TensorFlow BERT Model to OpenVINO IR": [[98, "converting-a-reshapable-tensorflow-bert-model-to-openvino-ir"]], "Converting a TensorFlow CRNN Model": [[99, "converting-a-tensorflow-crnn-model"]], "Converting a TensorFlow DeepSpeech Model": [[100, "converting-a-tensorflow-deepspeech-model"]], "Downloading the Pretrained DeepSpeech Model": [[100, "downloading-the-pretrained-deepspeech-model"]], "Freezing the Model into a *.pb File": [[100, "freezing-the-model-into-a-pb-file"]], "Converting the Main Part of DeepSpeech Model into OpenVINO IR": [[100, "converting-the-main-part-of-deepspeech-model-into-openvino-ir"]], "Converting TensorFlow EfficientDet Models": [[101, "converting-tensorflow-efficientdet-models"]], "Converting EfficientDet Model to the IR": [[101, "converting-efficientdet-model-to-the-ir"]], "Converting an EfficientDet TensorFlow Model to the IR": [[101, "converting-an-efficientdet-tensorflow-model-to-the-ir"]], "Interpreting Results of the TensorFlow Model and the IR": [[101, "interpreting-results-of-the-tensorflow-model-and-the-ir"]], "Converting TensorFlow FaceNet Models": [[102, "converting-tensorflow-facenet-models"]], "Converting a TensorFlow FaceNet Model to the IR": [[102, "converting-a-tensorflow-facenet-model-to-the-ir"]], "Converting a TensorFlow GNMT Model": [[103, "converting-a-tensorflow-gnmt-model"]], "Converting a GNMT Model to the IR": [[103, "converting-a-gnmt-model-to-the-ir"]], "Using a GNMT Model": [[103, "using-a-gnmt-model"]], "Running GNMT IR": [[103, "running-gnmt-ir"]], "Converting a TensorFlow Language Model on One Billion Word Benchmark": [[104, "converting-a-tensorflow-language-model-on-one-billion-word-benchmark"]], "Downloading a Pre-trained Language Model on One Billion Word Benchmark": [[104, "downloading-a-pre-trained-language-model-on-one-billion-word-benchmark"]], "Converting a TensorFlow Language Model on One Billion Word Benchmark to IR": [[104, "converting-a-tensorflow-language-model-on-one-billion-word-benchmark-to-ir"]], "Converting a TensorFlow Neural Collaborative Filtering Model": [[105, "converting-a-tensorflow-neural-collaborative-filtering-model"]], "Converting TensorFlow Object Detection API Models": [[106, "converting-tensorflow-object-detection-api-models"]], "Converting a Model": [[106, "converting-a-model"]], "OpenVINO\u2122 Toolkit Samples and Open Model Zoo Demos": [[106, "openvino-toolkit-samples-and-open-model-zoo-demos"]], "Feeding Input Images to the Samples": [[106, "feeding-input-images-to-the-samples"]], "Custom Input Shape": [[106, "custom-input-shape"]], "Fixed Shape Resizer Replacement": [[106, "fixed-shape-resizer-replacement"]], "Keeping Aspect Ratio Resizer Replacement": [[106, "keeping-aspect-ratio-resizer-replacement"]], "Model Conversion Process in Detail": [[106, "model-conversion-process-in-detail"]], "Converting a TensorFlow RetinaNet Model": [[107, "converting-a-tensorflow-retinanet-model"]], "Converting TensorFlow Slim Image Classification Model Library Models": [[108, "converting-tensorflow-slim-image-classification-model-library-models"]], "Example of an Inception V1 Model Conversion": [[108, "example-of-an-inception-v1-model-conversion"]], "Mean and Scale Values for TensorFlow-Slim Models": [[108, "mean-and-scale-values-for-tensorflow-slim-models"]], "Converting TensorFlow Wide and Deep Family Models": [[109, "converting-tensorflow-wide-and-deep-family-models"]], "Preparing an Example of Wide and Deep Model": [[109, "preparing-an-example-of-wide-and-deep-model"]], "Converting the Wide and Deep Model to IR": [[109, "converting-the-wide-and-deep-model-to-ir"]], "Converting a TensorFlow XLNet Model": [[110, "converting-a-tensorflow-xlnet-model"]], "Downloading the Pretrained Base XLNet Model": [[110, "downloading-the-pretrained-base-xlnet-model"]], "Downloading the Pretrained Large XLNet Model": [[110, "downloading-the-pretrained-large-xlnet-model"]], "Converting a frozen TensorFlow XLNet Model to IR": [[110, "converting-a-frozen-tensorflow-xlnet-model-to-ir"]], "Converting TensorFlow YOLO Models": [[111, "converting-tensorflow-yolo-models"]], "Converting a YOLOv4 Model to IR": [[111, "converting-a-yolov4-model-to-ir"]], "Converting YOLOv3 Model to the OpenVINO format": [[111, "converting-yolov3-model-to-the-openvino-format"]], "Overview of YOLOv3 Model Architecture": [[111, "overview-of-yolov3-model-architecture"]], "Dumping a YOLOv3 TensorFlow Model": [[111, "dumping-a-yolov3-tensorflow-model"]], "Converting a YOLOv3 TensorFlow Model to the OpenVINO format": [[111, "converting-a-yolov3-tensorflow-model-to-the-openvino-format"]], "Converting YOLOv1 and YOLOv2 Models to the IR": [[111, "converting-yolov1-and-yolov2-models-to-the-ir"]], "[LEGACY] Converting an ONNX Model": [[112, "legacy-converting-an-onnx-model"]], "Converting an ONNX Model": [[112, "converting-an-onnx-model"], [527, "converting-an-onnx-model"], [527, "id1"]], "Supported ONNX Layers": [[112, "supported-onnx-layers"], [527, "supported-onnx-layers"]], "[LEGACY] Converting a PaddlePaddle Model": [[113, "legacy-converting-a-paddlepaddle-model"]], "Converting PaddlePaddle Model Inference Format": [[113, "converting-paddlepaddle-model-inference-format"]], "Converting PaddlePaddle Model From Memory Using Python API": [[113, "converting-paddlepaddle-model-from-memory-using-python-api"]], "Supported PaddlePaddle Layers": [[113, "supported-paddlepaddle-layers"], [528, "supported-paddlepaddle-layers"]], "Frequently Asked Questions (FAQ)": [[113, "frequently-asked-questions-faq"], [115, "frequently-asked-questions-faq"]], "[LEGACY] Converting a PyTorch Model": [[114, "legacy-converting-a-pytorch-model"]], "Converting a PyTorch model with PyTorch Frontend": [[114, "converting-a-pytorch-model-with-pytorch-frontend"]], "Exporting a PyTorch Model to ONNX Format": [[114, "exporting-a-pytorch-model-to-onnx-format"], [529, "exporting-a-pytorch-model-to-onnx-format"]], "[LEGACY] Converting a TensorFlow Model": [[115, "legacy-converting-a-tensorflow-model"]], "Converting TensorFlow 1 Models": [[115, "converting-tensorflow-1-models"], [530, "converting-tensorflow-1-models"]], "Converting Frozen Model Format": [[115, "converting-frozen-model-format"], [530, "converting-frozen-model-format"]], "Converting Non-Frozen Model Formats": [[115, "converting-non-frozen-model-formats"], [530, "converting-non-frozen-model-formats"]], "Freezing Custom Models in Python": [[115, "freezing-custom-models-in-python"], [530, "freezing-custom-models-in-python"]], "Converting TensorFlow 2 Models": [[115, "converting-tensorflow-2-models"], [530, "converting-tensorflow-2-models"]], "SavedModel Format": [[115, "savedmodel-format"], [530, "savedmodel-format"]], "Keras H5": [[115, "keras-h5"]], "Command-Line Interface (CLI) Examples Using TensorFlow-Specific Parameters": [[115, "command-line-interface-cli-examples-using-tensorflow-specific-parameters"]], "Conversion of TensorFlow models from memory using Python API": [[115, "conversion-of-tensorflow-models-from-memory-using-python-api"]], "Supported TensorFlow and TensorFlow 2 Keras Layers": [[115, "supported-tensorflow-and-tensorflow-2-keras-layers"], [530, "supported-tensorflow-and-tensorflow-2-keras-layers"]], "Summary": [[115, "summary"], [127, "summary"], [530, "summary"]], "[LEGACY] Converting a TensorFlow Lite Model": [[116, "legacy-converting-a-tensorflow-lite-model"]], "Supported TensorFlow Lite Layers": [[116, "supported-tensorflow-lite-layers"], [531, "supported-tensorflow-lite-layers"]], "Supported TensorFlow Lite Models": [[116, "supported-tensorflow-lite-models"], [531, "supported-tensorflow-lite-models"]], "[LEGACY] Troubleshooting Reshape Errors": [[117, "legacy-troubleshooting-reshape-errors"]], "How To Avoid Shape Collision": [[117, "how-to-avoid-shape-collision"]], "How To Fix Non-Reshape-able Model": [[117, "how-to-fix-non-reshape-able-model"]], "Legacy Model Optimizer Extensibility": [[118, "legacy-model-optimizer-extensibility"]], "Model Representation in Memory": [[118, "model-representation-in-memory"]], "Model Conversion Pipeline": [[118, "model-conversion-pipeline"]], "Model Loading": [[118, "model-loading"]], "Operations Attributes Extracting": [[118, "operations-attributes-extracting"]], "Front Phase": [[118, "front-phase"]], "Partial Inference": [[118, "partial-inference"]], "Middle Phase": [[118, "middle-phase"]], "NHWC to NCHW Layout Change": [[118, "nhwc-to-nchw-layout-change"]], "Back Phase": [[118, "back-phase"]], "Intermediate Representation Emitting": [[118, "intermediate-representation-emitting"]], "[LEGACY] Extending Model Optimizer with Caffe Python Layers": [[119, "legacy-extending-model-optimizer-with-caffe-python-layers"]], "Writing Extractor for Caffe Python Layer": [[119, "writing-extractor-for-caffe-python-layer"]], "[LEGACY] Graph Traversal and Modification": [[120, "legacy-graph-traversal-and-modification"]], "Ports": [[120, "ports"]], "Connections": [[120, "connections"]], "[LEGACY] Model Optimizer Extensions": [[121, "legacy-model-optimizer-extensions"]], "[LEGACY] Graph Transformation Extensions": [[122, "legacy-graph-transformation-extensions"]], "Front Phase Transformations": [[122, "front-phase-transformations"]], "Pattern-Defined Front Phase Transformations": [[122, "pattern-defined-front-phase-transformations"]], "Specific Operation Front Phase Transformations": [[122, "specific-operation-front-phase-transformations"]], "Generic Front Phase Transformations": [[122, "generic-front-phase-transformations"]], "Node Name Pattern Front Phase Transformations": [[122, "node-name-pattern-front-phase-transformations"]], "Front Phase Transformations Using Start and End Points": [[122, "front-phase-transformations-using-start-and-end-points"]], "Generic Front Phase Transformations Enabled with Transformations Configuration File": [[122, "generic-front-phase-transformations-enabled-with-transformations-configuration-file"]], "Middle Phase Transformations": [[122, "middle-phase-transformations"]], "Pattern-Defined Middle Phase Transformations": [[122, "pattern-defined-middle-phase-transformations"]], "Generic Middle Phase Transformations": [[122, "generic-middle-phase-transformations"]], "Back Phase Transformations": [[122, "back-phase-transformations"]], "Pattern-Defined Back Phase Transformations": [[122, "pattern-defined-back-phase-transformations"]], "Generic Back Phase Transformations": [[122, "generic-back-phase-transformations"]], "[LEGACY] Model Optimizer Operation": [[123, "legacy-model-optimizer-operation"]], "[LEGACY] Operation Extractor": [[124, "legacy-operation-extractor"]], "OpenVINO\u2122 Ecosystem Overview": [[125, "openvino-ecosystem-overview"]], "Datumaro": [[126, "datumaro"]], "Detailed Workflow": [[126, "detailed-workflow"], [128, "detailed-workflow"]], "Datumaro Components": [[126, "datumaro-components"]], "Tutorials": [[126, "tutorials"], [128, "tutorials"]], "Python Hands-on Examples": [[126, "python-hands-on-examples"]], "OpenVINO\u2122 Security Add-on": [[127, "openvino-security-add-on"]], "Overview": [[127, "overview"]], "About the Installation": [[127, "about-the-installation"]], "Prerequisites": [[127, "prerequisites"], [498, "prerequisites"], [499, "prerequisites"]], "How to Prepare a Host Machine": [[127, "how-to-prepare-a-host-machine"]], "Step 1: Set up Packages on the Host Machine": [[127, "step-1-set-up-packages-on-the-host-machine"]], "Step 2: Set up Networking on the Host Machine": [[127, "step-2-set-up-networking-on-the-host-machine"]], "Step 3: Clone the OpenVINO\u2122 Security Add-on": [[127, "step-3-clone-the-openvino-security-add-on"]], "Step 4: Set Up one Guest VM for the combined roles of Model Developer and Independent Software Vendor": [[127, "step-4-set-up-one-guest-vm-for-the-combined-roles-of-model-developer-and-independent-software-vendor"]], "Step 5: Set Up one Guest VM for the User role": [[127, "step-5-set-up-one-guest-vm-for-the-user-role"]], "How to Build and Install the OpenVINO\u2122 Security Add-on Software": [[127, "how-to-build-and-install-the-openvino-security-add-on-software"]], "Step 1: Build the OpenVINO\u2122 Model Server image": [[127, "step-1-build-the-openvino-model-server-image"]], "Step 2: Build the software required for all roles": [[127, "step-2-build-the-software-required-for-all-roles"]], "Step 3: Install the host software": [[127, "step-3-install-the-host-software"]], "Step 4: Install the OpenVINO\u2122 Security Add-on Model Developer / ISV Components": [[127, "step-4-install-the-openvino-security-add-on-model-developer-isv-components"]], "Step 5: Install the OpenVINO\u2122 Security Add-on Model Hosting Component": [[127, "step-5-install-the-openvino-security-add-on-model-hosting-component"]], "How to Use the OpenVINO\u2122 Security Add-on": [[127, "how-to-use-the-openvino-security-add-on"]], "Model Developer Instructions": [[127, "model-developer-instructions"]], "Step 1: Set up the artefacts directory": [[127, "step-1-set-up-the-artefacts-directory"]], "Step 2: Create a key store and add a certificate to it": [[127, "step-2-create-a-key-store-and-add-a-certificate-to-it"]], "Step 3: Create the model": [[127, "step-3-create-the-model"]], "Step 4: Define access control for  the model and create a master license for it": [[127, "step-4-define-access-control-for-the-model-and-create-a-master-license-for-it"]], "Step 5: Create a Runtime Reference TCB": [[127, "step-5-create-a-runtime-reference-tcb"]], "Step 6: Publish the access controlled Model and Runtime Reference TCB": [[127, "step-6-publish-the-access-controlled-model-and-runtime-reference-tcb"]], "Step 7: Receive a User Request": [[127, "step-7-receive-a-user-request"]], "Model User Instructions": [[127, "model-user-instructions"]], "Step 1: Setup up the artefacts directory": [[127, "step-1-setup-up-the-artefacts-directory"]], "Step 2: Add a CA-Signed Certificate to a Key Store": [[127, "step-2-add-a-ca-signed-certificate-to-a-key-store"]], "Step 3: Request an access controlled Model from the Model Developer": [[127, "step-3-request-an-access-controlled-model-from-the-model-developer"]], "Step 4: Receive and load the access controlled model into the OpenVINO\u2122 Model Server": [[127, "step-4-receive-and-load-the-access-controlled-model-into-the-openvino-model-server"]], "Step 5: Start the NGINX Model Server": [[127, "step-5-start-the-nginx-model-server"]], "Step 6: Prepare to run Inference": [[127, "step-6-prepare-to-run-inference"]], "Step 7: Run Inference": [[127, "step-7-run-inference"]], "References": [[127, "references"]], "OpenVINO\u2122 Training Extensions": [[128, "openvino-training-extensions"]], "OpenVINO Training Extensions Components": [[128, "openvino-training-extensions-components"]], "OpenVINO Extensibility Mechanism": [[129, "openvino-extensibility-mechanism"]], "Definition of Operation Semantics": [[129, "definition-of-operation-semantics"]], "Mapping from Framework Operation": [[129, "mapping-from-framework-operation"]], "Registering Extensions": [[129, "registering-extensions"]], "Load Extensions to Core": [[129, "load-extensions-to-core"]], "Create a Library with Extensions": [[129, "create-a-library-with-extensions"]], "How to Implement Custom GPU Operations": [[130, "how-to-implement-custom-gpu-operations"]], "Configuration File Format": [[130, "configuration-file-format"]], "CustomLayer Node and Sub-Node Structure": [[130, "customlayer-node-and-sub-node-structure"]], "Kernel Node and Sub-Node Structure": [[130, "kernel-node-and-sub-node-structure"]], "Source Node and Sub-Node Structure": [[130, "source-node-and-sub-node-structure"]], "Define Node and Sub-Node Structure": [[130, "define-node-and-sub-node-structure"]], "Buffers Node and Sub-Node Structure": [[130, "buffers-node-and-sub-node-structure"]], "Data Node and Sub-Node Structure": [[130, "data-node-and-sub-node-structure"]], "Tensor Node and Sub-Node Structure": [[130, "tensor-node-and-sub-node-structure"]], "CompilerOptions Node and Sub-Node Structure": [[130, "compileroptions-node-and-sub-node-structure"]], "WorkSizes Node and Sub-Node Structure": [[130, "worksizes-node-and-sub-node-structure"]], "Example Configuration File": [[130, "example-configuration-file"]], "Built-In Definitions for Custom Layers": [[130, "built-in-definitions-for-custom-layers"]], "Example Kernel": [[130, "example-kernel"]], "Debugging Tips": [[130, "id2"]], "Custom OpenVINO Operations": [[131, "custom-openvino-operations"]], "Operation Class": [[131, "operation-class"]], "Operation Constructors": [[131, "operation-constructors"]], "validate_and_infer_types()": [[131, "validate-and-infer-types"]], "clone_with_new_inputs()": [[131, "clone-with-new-inputs"]], "visit_attributes()": [[131, "visit-attributes"]], "evaluate() and has_evaluate()": [[131, "evaluate-and-has-evaluate"]], "Frontend Extensions": [[132, "frontend-extensions"]], "Single Operation Mapping with OpExtension": [[132, "single-operation-mapping-with-opextension"]], "Converting to Standard OpenVINO Operation": [[132, "converting-to-standard-openvino-operation"]], "Attribute Mapping": [[132, "attribute-mapping"]], "Named attributes mapping": [[132, "named-attributes-mapping"]], "Attribute mapping with named inputs and outputs": [[132, "attribute-mapping-with-named-inputs-and-outputs"]], "Mapping attributes from operation inputs": [[132, "mapping-attributes-from-operation-inputs"]], "Mapping custom operations to frontends with OPENVINO_FRAMEWORK_MAP macro": [[132, "mapping-custom-operations-to-frontends-with-openvino-framework-map-macro"]], "Mapping to Multiple Operations with ConversionExtension": [[132, "mapping-to-multiple-operations-with-conversionextension"]], "Overview of OpenVINO Plugin Library": [[133, "overview-of-openvino-plugin-library"]], "OpenVINO Plugin Library": [[133, "openvino-plugin-library"]], "Detailed Guides": [[133, "detailed-guides"]], "API References": [[133, "api-references"]], "Advanced Topics": [[134, "advanced-topics"]], "OpenVINO\u2122 Low Precision Transformations": [[135, "openvino-low-precision-transformations"]], "Introduction": [[135, "introduction"], [136, "introduction"], [225, "introduction"], [518, "introduction"], [519, "introduction"], [520, "introduction"], [522, "introduction"], [523, "introduction"], [557, "introduction"]], "Input model requirements": [[135, "input-model-requirements"]], "Low precision tools": [[135, "low-precision-tools"]], "Quantization approaches": [[135, "quantization-approaches"]], "FakeQuantize operation": [[135, "fakequantize-operation"]], "Quantize and dequantization operations": [[135, "quantize-and-dequantization-operations"]], "Low precision transformations pipeline": [[135, "low-precision-transformations-pipeline"]], "Step 1. Prerequisites": [[135, "step-1-prerequisites"]], "Step 2. Markup": [[135, "step-2-markup"]], "Step 3. Main transformations, FakeQuantize decomposition and dequantization operations handling": [[135, "step-3-main-transformations-fakequantize-decomposition-and-dequantization-operations-handling"]], "Decomposition transformations": [[135, "decomposition-transformations"]], "Dequantization operations handling transformations": [[135, "dequantization-operations-handling-transformations"]], "Step 4: Cleanup of the result model": [[135, "step-4-cleanup-of-the-result-model"]], "Low precision transformations in plugin transformation pipeline": [[135, "low-precision-transformations-in-plugin-transformation-pipeline"]], "Step 1. Common optimizations": [[135, "step-1-common-optimizations"]], "Step 2. Low precision transformations execution": [[135, "step-2-low-precision-transformations-execution"]], "Step 3. Plugin-specific transformations": [[135, "step-3-plugin-specific-transformations"]], "Result model overview": [[135, "result-model-overview"]], "Inference": [[135, "inference"]], "Results analysis": [[135, "results-analysis"]], "Mixed precision": [[135, "mixed-precision"]], "Customization": [[135, "customization"]], "Operation precision restrictions": [[135, "operation-precision-restrictions"]], "Operation per tensor quantization restrictions": [[135, "operation-per-tensor-quantization-restrictions"]], "Update precisions": [[135, "update-precisions"]], "Typical customization use cases": [[135, "typical-customization-use-cases"]], "Attributes": [[136, "attributes"]], "AvgPoolPrecisionPreserved Attribute": [[137, "avgpoolprecisionpreserved-attribute"]], "IntervalsAlignment Attribute": [[138, "intervalsalignment-attribute"]], "PrecisionPreserved Attribute": [[139, "precisionpreserved-attribute"]], "Precisions Attribute": [[140, "precisions-attribute"]], "QuantizationAlignment Attribute": [[141, "quantizationalignment-attribute"]], "QuantizationGranularity Attribute": [[142, "quantizationgranularity-attribute"]], "Step 1. Prerequisites Transformations": [[143, "step-1-prerequisites-transformations"]], "ConvertSubtractConstant transformation": [[144, "convertsubtractconstant-transformation"]], "LinOpSequenceFusion transformation": [[145, "linopsequencefusion-transformation"]], "PullReshapeThroughDequantization transformation": [[146, "pullreshapethroughdequantization-transformation"]], "PullTransposeThroughDequantization transformation": [[147, "pulltransposethroughdequantization-transformation"]], "Step 2. Markup Transformations": [[148, "step-2-markup-transformations"]], "1. MarkupCanBeQuantized": [[148, "markupcanbequantized"]], "2. MarkupPrecisions": [[148, "markupprecisions"]], "3. MarkupPerTensorQuantization": [[148, "markuppertensorquantization"]], "4. MarkupAvgPoolPrecisionPreserved": [[148, "markupavgpoolprecisionpreserved"]], "5. PropagatePrecisions": [[148, "propagateprecisions"]], "6. AlignQuantizationIntervals": [[148, "alignquantizationintervals"]], "7. AlignQuantizationParameters": [[148, "alignquantizationparameters"]], "AlignQuantizationIntervals transformation": [[149, "alignquantizationintervals-transformation"]], "AlignQuantizationParameters transformation": [[150, "alignquantizationparameters-transformation"]], "CreateAttribute transformation": [[151, "createattribute-transformation"]], "CreatePrecisionsDependentAttribute transformation": [[152, "createprecisionsdependentattribute-transformation"]], "MarkupAvgPoolPrecisionPreserved transformation": [[153, "markupavgpoolprecisionpreserved-transformation"]], "MarkupBias transformation": [[154, "markupbias-transformation"]], "MarkupCanBeQuantized transformation": [[155, "markupcanbequantized-transformation"]], "MarkupPerTensorQuantization transformation": [[156, "markuppertensorquantization-transformation"]], "MarkupPrecisions transformation": [[157, "markupprecisions-transformation"]], "PropagatePrecisions transformation": [[158, "propagateprecisions-transformation"]], "PropagateSharedValue transformation": [[159, "propagatesharedvalue-transformation"]], "PropagateThroughPrecisionPreserved transformation": [[160, "propagatethroughprecisionpreserved-transformation"]], "PropagateToInput transformation": [[161, "propagatetoinput-transformation"]], "UpdateSharedPrecisionPreserved transformation": [[162, "updatesharedprecisionpreserved-transformation"]], "Step 3. Main Transformations": [[163, "step-3-main-transformations"]], "ClampTransformation transformation": [[164, "clamptransformation-transformation"]], "PReluTransformation transformation": [[165, "prelutransformation-transformation"]], "ReluTransformation transformation": [[166, "relutransformation-transformation"]], "AddTransformation transformation": [[167, "addtransformation-transformation"]], "Subgraph before transformation": [[167, "subgraph-before-transformation"], [171, "subgraph-before-transformation"]], "Subgraph after transformation": [[167, "subgraph-after-transformation"], [171, "subgraph-after-transformation"]], "MultiplyTransformation transformation": [[168, "multiplytransformation-transformation"], [169, "multiplytransformation-transformation"]], "SubtractTransformation transformation": [[170, "subtracttransformation-transformation"]], "ConvolutionTransformation transformation": [[171, "convolutiontransformation-transformation"]], "Limitations": [[171, "limitations"], [541, "limitations"], [542, "limitations"], [543, "limitations"], [544, "limitations"], [547, "limitations"]], "Quantized weights in low precision with dequantization operations": [[171, "quantized-weights-in-low-precision-with-dequantization-operations"]], "Weights in original precision with FakeQuantize operation": [[171, "weights-in-original-precision-with-fakequantize-operation"]], "ConvolutionBackpropDataTransformation transformation": [[172, "convolutionbackpropdatatransformation-transformation"]], "GroupConvolutionTransformation transformation": [[173, "groupconvolutiontransformation-transformation"]], "InterpolateTransformation transformation": [[174, "interpolatetransformation-transformation"]], "MatMulTransformation transformation": [[175, "matmultransformation-transformation"]], "ConcatTransformation transformation": [[176, "concattransformation-transformation"]], "DepthToSpaceTransformation transformation": [[177, "depthtospacetransformation-transformation"]], "GatherTransformation transformation": [[178, "gathertransformation-transformation"]], "PadTransformation transformation": [[179, "padtransformation-transformation"]], "ShuffleChannelsTransformation transformation": [[180, "shufflechannelstransformation-transformation"]], "SplitTransformation transformation": [[181, "splittransformation-transformation"]], "StridedSliceTransformation transformation": [[182, "stridedslicetransformation-transformation"]], "TransposeTransformation transformation": [[183, "transposetransformation-transformation"]], "VariadicSplitTransformation transformation": [[184, "variadicsplittransformation-transformation"]], "MVNTransformation transformation": [[185, "mvntransformation-transformation"]], "NormalizeL2Transformation transformation": [[186, "normalizel2transformation-transformation"]], "AvgPoolTransformation transformation": [[187, "avgpooltransformation-transformation"]], "MaxPoolTransformation transformation": [[188, "maxpooltransformation-transformation"]], "FakeQuantizeTransformation transformation": [[189, "fakequantizetransformation-transformation"]], "FoldFakeQuantizeTransformation transformation": [[190, "foldfakequantizetransformation-transformation"]], "ReduceMaxTransformation transformation": [[191, "reducemaxtransformation-transformation"]], "ReduceMeanTransformation transformation": [[192, "reducemeantransformation-transformation"]], "ReduceMinTransformation transformation": [[193, "reducemintransformation-transformation"]], "ReduceSumTransformation transformation": [[194, "reducesumtransformation-transformation"]], "BatchToSpaceTransformation transformation": [[195, "batchtospacetransformation-transformation"]], "ReshapeTransformation transformation": [[196, "reshapetransformation-transformation"]], "SpaceToBatchTransformation transformation": [[197, "spacetobatchtransformation-transformation"]], "SqueezeTransformation transformation": [[198, "squeezetransformation-transformation"]], "UnsqueezeTransformation transformation": [[199, "unsqueezetransformation-transformation"]], "Step 4. Cleanup Transformations": [[200, "step-4-cleanup-transformations"]], "EliminateFakeQuantizeTransformation transformation": [[201, "eliminatefakequantizetransformation-transformation"]], "FakeQuantizeDecompositionTransformation transformation": [[202, "fakequantizedecompositiontransformation-transformation"]], "FoldConvertTransformation transformation": [[203, "foldconverttransformation-transformation"]], "FuseConvertTransformation transformation": [[204, "fuseconverttransformation-transformation"]], "FuseMultiplyToFakeQuantizeTransformation transformation": [[205, "fusemultiplytofakequantizetransformation-transformation"]], "FuseSubtractToFakeQuantizeTransformation transformation": [[206, "fusesubtracttofakequantizetransformation-transformation"]], "MultiplyToGroupConvolutionTransformation transformation": [[207, "multiplytogroupconvolutiontransformation-transformation"]], "Quantized models compute and restrictions": [[208, "quantized-models-compute-and-restrictions"]], "Interpreting FakeQuantize at runtime": [[208, "interpreting-fakequantize-at-runtime"]], "Quantization specifics and restrictions": [[208, "quantization-specifics-and-restrictions"]], "Representation of low-precision models": [[209, "representation-of-low-precision-models"]], "Representation of quantized models": [[209, "representation-of-quantized-models"]], "Asynchronous Inference Request": [[210, "asynchronous-inference-request"]], "AsyncInferRequest Class": [[210, "asyncinferrequest-class"]], "Class Fields": [[210, "class-fields"], [212, "class-fields"], [213, "class-fields"], [217, "class-fields"], [218, "class-fields"], [219, "class-fields"]], "AsyncInferRequest()": [[210, "asyncinferrequest"]], "~AsyncInferRequest()": [[210, "id1"]], "cancel()": [[210, "cancel"], [219, "cancel"]], "Build Plugin Using CMake": [[211, "build-plugin-using-cmake"]], "OpenVINO Developer Package": [[211, "openvino-developer-package"]], "Build Plugin using OpenVINO Developer Package": [[211, "build-plugin-using-openvino-developer-package"]], "Compiled Model": [[212, "compiled-model"]], "CompiledModel Class": [[212, "compiledmodel-class"]], "CompiledModel Constructor": [[212, "compiledmodel-constructor"]], "compile_model()": [[212, "compile-model"], [213, "compile-model"]], "export_model()": [[212, "export-model"]], "create_sync_infer_request()": [[212, "create-sync-infer-request"]], "create_infer_request()": [[212, "create-infer-request"]], "get_property()": [[212, "get-property"], [213, "get-property"], [217, "get-property"]], "set_property()": [[212, "set-property"], [213, "set-property"]], "get_runtime_model()": [[212, "get-runtime-model"]], "Plugin": [[213, "plugin"]], "Plugin Class": [[213, "plugin-class"]], "Plugin Constructor": [[213, "plugin-constructor"]], "Plugin Destructor": [[213, "plugin-destructor"]], "transform_model()": [[213, "transform-model"]], "query_model()": [[213, "query-model"]], "import_model()": [[213, "import-model"]], "create_context()": [[213, "create-context"]], "get_default_context()": [[213, "get-default-context"]], "Create Instance of Plugin Class": [[213, "create-instance-of-plugin-class"]], "Plugin API Reference": [[214, "plugin-api-reference"]], "Plugin Properties": [[215, "plugin-properties"]], "Property Class": [[215, "property-class"]], "Plugin Testing": [[216, "plugin-testing"]], "How to Extend OpenVINO Plugin Tests": [[216, "how-to-extend-openvino-plugin-tests"]], "Remote Context": [[217, "remote-context"]], "RemoteContext Class": [[217, "remotecontext-class"]], "RemoteContext Constructor": [[217, "remotecontext-constructor"]], "get_device_name()": [[217, "get-device-name"], [218, "get-device-name"]], "create_tensor()": [[217, "create-tensor"]], "Remote Tensor": [[218, "remote-tensor"]], "Device Specific Remote Tensor Public API": [[218, "device-specific-remote-tensor-public-api"]], "type_check()": [[218, "type-check"]], "get_data()": [[218, "get-data"]], "Device-Specific Internal tensor implementation": [[218, "device-specific-internal-tensor-implementation"]], "VectorTensorImpl()": [[218, "vectortensorimpl"]], "get_element_type()": [[218, "get-element-type"]], "get_shape()": [[218, "get-shape"]], "get_strides()": [[218, "get-strides"]], "set_shape()": [[218, "set-shape"]], "get_properties()": [[218, "get-properties"]], "Synchronous Inference Request": [[219, "synchronous-inference-request"]], "InferRequest Class": [[219, "inferrequest-class"]], "InferRequest Constructor": [[219, "inferrequest-constructor"]], "~InferRequest Destructor": [[219, "inferrequest-destructor"]], "set_tensors_impl()": [[219, "set-tensors-impl"]], "query_state()": [[219, "query-state"]], "infer()": [[219, "infer"]], "1. infer_preprocess()": [[219, "infer-preprocess"]], "2. start_pipeline()": [[219, "start-pipeline"]], "3. wait_pipeline()": [[219, "wait-pipeline"]], "4. infer_postprocess()": [[219, "infer-postprocess"]], "get_profiling_info()": [[219, "get-profiling-info"]], "Overview of Transformations API": [[220, "overview-of-transformations-api"]], "Working with Model": [[220, "working-with-model"]], "Working with node input and output ports": [[220, "working-with-node-input-and-output-ports"]], "Node replacement": [[220, "node-replacement"]], "Node elimination": [[220, "node-elimination"]], "Transformations types": [[220, "transformations-types"]], "Transformation conditional compilation": [[220, "transformation-conditional-compilation"]], "Transformation writing essentials": [[220, "transformation-writing-essentials"]], "1. Friendly Names": [[220, "friendly-names"]], "2. Runtime Info": [[220, "runtime-info"]], "3. Constant Folding": [[220, "constant-folding"]], "Common mistakes in transformations": [[220, "common-mistakes-in-transformations"]], "Using pass manager": [[220, "using-pass-manager"]], "How to debug transformations": [[220, "how-to-debug-transformations"]], "OpenVINO Graph Rewrite Pass": [[221, "openvino-graph-rewrite-pass"]], "OpenVINO Matcher Pass": [[222, "openvino-matcher-pass"]], "Create a pattern": [[222, "create-a-pattern"]], "Implement callback": [[222, "implement-callback"]], "Register pattern and Matcher": [[222, "register-pattern-and-matcher"]], "Execute MatcherPass": [[222, "execute-matcherpass"]], "Pattern Matching": [[222, "pattern-matching"]], "OpenVINO Model Pass": [[223, "openvino-model-pass"]], "OpenVINO IR format": [[224, "openvino-ir-format"]], "IR Structure": [[224, "ir-structure"]], "Intermediate Representation Suitable for INT8 Inference": [[225, "intermediate-representation-suitable-for-int8-inference"]], "Compressed Low Precision Weights": [[225, "compressed-low-precision-weights"]], "Operation Sets in OpenVINO": [[226, "operation-sets-in-openvino"]], "Overview of Artificial Neural Networks Representation": [[226, "overview-of-artificial-neural-networks-representation"]], "Operation Sets": [[226, "operation-sets"]], "How to Read Opset Specification": [[226, "how-to-read-opset-specification"]], "IR Versions vs Operation Set Versions": [[226, "ir-versions-vs-operation-set-versions"]], "Available Operation Sets": [[227, "available-operation-sets"]], "opset1": [[228, "opset1"]], "Table of Contents": [[228, "table-of-contents"], [229, "table-of-contents"], [230, "table-of-contents"], [231, "table-of-contents"], [232, "table-of-contents"], [233, "table-of-contents"], [234, "table-of-contents"], [235, "table-of-contents"], [236, "table-of-contents"], [237, "table-of-contents"], [238, "table-of-contents"], [239, "table-of-contents"], [240, "table-of-contents"], [241, "table-of-contents"]], "opset10": [[229, "opset10"]], "opset11": [[230, "opset11"]], "opset12": [[231, "opset12"]], "opset13": [[232, "opset13"]], "opset14": [[233, "opset14"]], "opset2": [[234, "opset2"]], "opset3": [[235, "opset3"]], "opset4": [[236, "opset4"]], "opset5": [[237, "opset5"]], "opset6": [[238, "opset6"]], "opset7": [[239, "opset7"]], "opset8": [[240, "opset8"]], "opset9": [[241, "opset9"]], "Broadcast Rules For Elementwise Operations": [[242, "broadcast-rules-for-elementwise-operations"]], "Description": [[242, "description"], [242, "id1"]], "Rules": [[242, "rules"], [242, "id2"]], "Numpy examples": [[242, "numpy-examples"]], "PDPD examples": [[242, "pdpd-examples"]], "Bidirectional Broadcast Rules": [[242, "bidirectional-broadcast-rules"]], "Bidirectional examples": [[242, "bidirectional-examples"]], "Operation Specifications": [[243, "operation-specifications"]], "Clamp": [[244, "clamp"]], "Elu": [[245, "elu"]], "Exp": [[246, "exp"]], "GELU": [[247, "gelu"], [248, "gelu"]], "HardSigmoid": [[249, "hardsigmoid"]], "HSigmoid": [[250, "hsigmoid"]], "HSwish": [[251, "hswish"]], "LogSoftMax": [[252, "logsoftmax"]], "Mish": [[253, "mish"]], "PReLU": [[254, "prelu"]], "ReLU": [[255, "relu"]], "Selu": [[256, "selu"]], "Sigmoid": [[257, "sigmoid"]], "SoftMax": [[258, "softmax"], [259, "softmax"]], "SoftPlus": [[260, "softplus"]], "SoftSign": [[261, "softsign"]], "Swish": [[262, "swish"]], "Abs": [[263, "abs"]], "Acos": [[264, "acos"]], "Acosh": [[265, "acosh"]], "Add": [[266, "add"]], "Asin": [[267, "asin"]], "Asinh": [[268, "asinh"]], "Atan": [[269, "atan"]], "Atanh": [[270, "atanh"]], "Ceiling": [[271, "ceiling"]], "Cos": [[272, "cos"]], "Cosh": [[273, "cosh"]], "CumSum": [[274, "cumsum"]], "Divide": [[275, "divide"]], "Erf": [[276, "erf"]], "Floor": [[277, "floor"]], "FloorMod": [[278, "floormod"]], "Log": [[279, "log"]], "Maximum": [[280, "maximum"]], "Minimum": [[281, "minimum"]], "Mod": [[282, "mod"]], "Multiply": [[283, "multiply"]], "Negative": [[284, "negative"]], "Power": [[285, "power"]], "Round": [[286, "round"]], "Sign": [[287, "sign"]], "Sin": [[288, "sin"]], "Sinh": [[289, "sinh"]], "Sqrt": [[290, "sqrt"]], "SquaredDifference": [[291, "squareddifference"]], "Subtract": [[292, "subtract"]], "Tan": [[293, "tan"]], "Tanh": [[294, "tanh"]], "BitwiseAnd": [[295, "bitwiseand"]], "BitwiseNot": [[296, "bitwisenot"]], "BitwiseOr": [[297, "bitwiseor"]], "BitwiseXor": [[298, "bitwisexor"]], "Equal": [[299, "equal"]], "Greater": [[300, "greater"]], "GreaterEqual": [[301, "greaterequal"]], "IsFinite": [[302, "isfinite"]], "IsInf": [[303, "isinf"]], "IsNaN": [[304, "isnan"]], "Less": [[305, "less"]], "LessEqual": [[306, "lessequal"]], "NotEqual": [[307, "notequal"]], "Bucketize": [[308, "bucketize"]], "If": [[309, "if"]], "NonZero": [[310, "nonzero"]], "Select": [[311, "select"]], "BinaryConvolution": [[312, "binaryconvolution"]], "Convolution": [[313, "convolution"]], "ConvolutionBackpropData": [[314, "convolutionbackpropdata"]], "DeformableConvolution": [[315, "deformableconvolution"], [316, "deformableconvolution"]], "GroupConvolution": [[317, "groupconvolution"]], "GroupConvolutionBackpropData": [[318, "groupconvolutionbackpropdata"]], "DeformablePSROIPooling": [[319, "deformablepsroipooling"]], "DetectionOutput": [[320, "detectionoutput"], [321, "detectionoutput"]], "ExperimentalDetectronDetectionOutput": [[322, "experimentaldetectrondetectionoutput"]], "ExperimentalDetectronGenerateProposalsSingleImage": [[323, "experimentaldetectrongenerateproposalssingleimage"]], "ExperimentalDetectronPriorGridGenerator": [[324, "experimentaldetectronpriorgridgenerator"]], "ExperimentalDetectronROIFeatureExtractor": [[325, "experimentaldetectronroifeatureextractor"]], "GenerateProposals": [[326, "generateproposals"]], "PriorBox": [[327, "priorbox"], [328, "priorbox"]], "PriorBoxClustered": [[329, "priorboxclustered"]], "Proposal": [[330, "proposal"], [331, "proposal"]], "PSROIPooling": [[332, "psroipooling"]], "RegionYolo": [[333, "regionyolo"]], "ReorgYolo Layer": [[334, "reorgyolo-layer"]], "ROIAlign": [[335, "roialign"], [336, "roialign"]], "ROIAlignRotated": [[337, "roialignrotated"]], "ROIPooling": [[338, "roipooling"]], "Eye": [[339, "eye"]], "Multinomial": [[340, "multinomial"]], "RandomUniform": [[341, "randomuniform"]], "Range": [[342, "range"], [343, "range"]], "GridSample": [[344, "gridsample"]], "I420toBGR": [[345, "i420tobgr"]], "I420toRGB": [[346, "i420torgb"]], "Interpolate": [[347, "interpolate"], [348, "interpolate"], [349, "interpolate"]], "NV12toBGR": [[350, "nv12tobgr"]], "NV12toRGB": [[351, "nv12torgb"]], "Assign": [[352, "assign"], [353, "assign"]], "Constant": [[354, "constant"]], "Loop": [[355, "loop"]], "Parameter": [[356, "parameter"]], "ReadValue": [[357, "readvalue"], [358, "readvalue"]], "Result": [[359, "result"]], "TensorIterator": [[360, "tensoriterator"]], "AUGRUCell": [[361, "augrucell"]], "AUGRUSequence": [[362, "augrusequence"]], "LogicalAnd": [[363, "logicaland"]], "LogicalNot": [[364, "logicalnot"]], "LogicalOr": [[365, "logicalor"]], "LogicalXor": [[366, "logicalxor"]], "Einsum": [[367, "einsum"]], "Inverse": [[368, "inverse"]], "MatMul": [[369, "matmul"]], "BatchToSpace": [[370, "batchtospace"]], "Broadcast": [[371, "broadcast"], [372, "broadcast"]], "Concat": [[373, "concat"]], "DepthToSpace": [[374, "depthtospace"]], "ExtractImagePatches": [[375, "extractimagepatches"]], "Gather": [[376, "gather"], [377, "gather"], [378, "gather"]], "GatherElements": [[379, "gatherelements"]], "GatherND": [[380, "gathernd"], [381, "gathernd"]], "GatherTree": [[382, "gathertree"]], "Pad": [[383, "pad"], [384, "pad"]], "Positive pads example:": [[384, "positive-pads-example"]], "Negative pads example:": [[384, "negative-pads-example"]], "Mixed pads example:": [[384, "mixed-pads-example"]], "Reverse": [[385, "reverse"]], "ReverseSequence": [[386, "reversesequence"]], "Roll": [[387, "roll"]], "ScatterElementsUpdate": [[388, "scatterelementsupdate"], [389, "scatterelementsupdate"]], "ScatterNDUpdate": [[390, "scatterndupdate"], [391, "scatterndupdate"]], "ScatterUpdate": [[392, "scatterupdate"]], "ShuffleChannels": [[393, "shufflechannels"]], "Slice": [[394, "slice"]], "SpaceToBatch": [[395, "spacetobatch"]], "SpaceToDepth": [[396, "spacetodepth"]], "Split": [[397, "split"]], "StridedSlice": [[398, "stridedslice"]], "Tile": [[399, "tile"]], "Transpose": [[400, "transpose"]], "Unique": [[401, "unique"]], "VariadicSplit": [[402, "variadicsplit"]], "BatchNormInference": [[403, "batchnorminference"], [404, "batchnorminference"]], "GRN": [[405, "grn"]], "GroupNormalization": [[406, "groupnormalization"]], "LRN": [[407, "lrn"]], "MVN": [[408, "mvn"], [409, "mvn"]], "NormalizeL2": [[410, "normalizel2"]], "AdaptiveAvgPool": [[411, "adaptiveavgpool"]], "AdaptiveMaxPool": [[412, "adaptivemaxpool"]], "AvgPool": [[413, "avgpool"], [414, "avgpool"]], "MaxPool": [[415, "maxpool"], [416, "maxpool"], [417, "maxpool"]], "Shape calculation rules for Pooling Operators": [[418, "shape-calculation-rules-for-pooling-operators"]], "FakeConvert": [[419, "fakeconvert"]], "FakeQuantize": [[420, "fakequantize"]], "ReduceL1": [[421, "reducel1"]], "ReduceL2": [[422, "reducel2"]], "ReduceLogicalAnd": [[423, "reducelogicaland"]], "ReduceLogicalOr": [[424, "reducelogicalor"]], "ReduceMax": [[425, "reducemax"]], "ReduceMean": [[426, "reducemean"]], "ReduceMin": [[427, "reducemin"]], "ReduceProd": [[428, "reduceprod"]], "ReduceSum": [[429, "reducesum"]], "CTCGreedyDecoder": [[430, "ctcgreedydecoder"]], "CTCGreedyDecoderSeqLen": [[431, "ctcgreedydecoderseqlen"]], "CTCLoss": [[432, "ctcloss"]], "GRUCell": [[433, "grucell"]], "GRUSequence": [[434, "grusequence"]], "LSTMCell": [[435, "lstmcell"]], "LSTMSequence": [[436, "lstmsequence"]], "OneHot": [[437, "onehot"]], "RNNCell": [[438, "rnncell"]], "RNNSequence": [[439, "rnnsequence"]], "ScaledDotProductAttention": [[440, "scaleddotproductattention"]], "Reshape": [[441, "reshape"]], "ShapeOf": [[442, "shapeof"], [443, "shapeof"]], "Squeeze": [[444, "squeeze"]], "Unsqueeze": [[445, "unsqueeze"]], "DFT": [[446, "dft"]], "Inverse Discrete Fourier Transformation (IDFT)": [[447, "inverse-discrete-fourier-transformation-idft"]], "Inverse Discrete complex-to-real Fourier Transformation (IRDFT)": [[448, "inverse-discrete-complex-to-real-fourier-transformation-irdft"]], "Discrete Fourier Transformation for real-valued input (RDFT)": [[449, "discrete-fourier-transformation-for-real-valued-input-rdft"]], "ExperimentalDetectronTopKROIs": [[450, "experimentaldetectrontopkrois"]], "MatrixNonMaxSuppression": [[451, "matrixnonmaxsuppression"]], "MulticlassNonMaxSuppression": [[452, "multiclassnonmaxsuppression"], [453, "multiclassnonmaxsuppression"]], "NMSRotated": [[454, "nmsrotated"]], "NonMaxSuppression": [[455, "nonmaxsuppression"], [456, "nonmaxsuppression"], [457, "nonmaxsuppression"], [458, "nonmaxsuppression"], [459, "nonmaxsuppression"]], "TopK": [[460, "topk"], [461, "topk"], [462, "topk"]], "EmbeddingBagOffsetsSum": [[463, "embeddingbagoffsetssum"]], "EmbeddingBagPackedSum": [[464, "embeddingbagpackedsum"]], "EmbeddingSegmentsSum": [[465, "embeddingsegmentssum"]], "Convert": [[466, "convert"]], "ConvertLike": [[467, "convertlike"]], "ConvertPromoteTypes": [[468, "convertpromotetypes"]], "OpenVINO Security": [[469, "openvino-security"]], "Using Encrypted Models with OpenVINO": [[470, "using-encrypted-models-with-openvino"]], "Secure Model Deployment": [[470, "secure-model-deployment"]], "Loading Encrypted Models": [[470, "loading-encrypted-models"]], "GET STARTED": [[471, "get-started"]], "1. Quick Start Example (No Installation Required)": [[471, "quick-start-example-no-installation-required"]], "2. Install OpenVINO": [[471, "install-openvino"]], "3. Learn OpenVINO": [[471, "learn-openvino"]], "OpenVINO Basics": [[471, "openvino-basics"]], "Interactive Tutorials - Jupyter Notebooks": [[471, "interactive-tutorials-jupyter-notebooks"]], "OpenVINO Code Samples": [[471, "openvino-code-samples"]], "Integrate OpenVINO With Your Application": [[471, "integrate-openvino-with-your-application"]], "OpenVINO Advanced Features": [[471, "openvino-advanced-features"]], "Model Compression and Quantization": [[471, "model-compression-and-quantization"]], "Automated Device Configuration": [[471, "automated-device-configuration"]], "Flexible Model and Pipeline Configuration": [[471, "flexible-model-and-pipeline-configuration"]], "Additional Configurations For Hardware": [[472, "additional-configurations-for-hardware"]], "Configurations for Intel\u00ae Processor Graphics (GPU) with OpenVINO\u2122": [[473, "configurations-for-intel-processor-graphics-gpu-with-openvino"]], "Linux": [[473, "linux"]], "Windows": [[473, "windows"]], "Windows Subsystem for Linux (WSL)": [[473, "windows-subsystem-for-linux-wsl"]], "Configurations for Intel\u00ae NPU with OpenVINO\u2122": [[474, "configurations-for-intel-npu-with-openvino"]], "Install OpenVINO\u2122 2024.0": [[475, "install-openvino-2024-0"]], "Install Intel\u00ae Distribution of OpenVINO\u2122 Toolkit for Linux Using APT Repository": [[476, "install-intel-distribution-of-openvino-toolkit-for-linux-using-apt-repository"]], "Installing OpenVINO Runtime": [[476, "installing-openvino-runtime"], [477, "installing-openvino-runtime"], [478, "installing-openvino-runtime"], [479, "installing-openvino-runtime"], [480, "installing-openvino-runtime"], [487, "installing-openvino-runtime"], [488, "installing-openvino-runtime"]], "Step 1: Set Up the OpenVINO Toolkit APT Repository": [[476, "step-1-set-up-the-openvino-toolkit-apt-repository"]], "Step 2: Install OpenVINO Runtime Using the APT Package Manager": [[476, "step-2-install-openvino-runtime-using-the-apt-package-manager"]], "Uninstalling OpenVINO Runtime": [[476, "uninstalling-openvino-runtime"], [479, "uninstalling-openvino-runtime"], [490, "uninstalling-openvino-runtime"], [491, "uninstalling-openvino-runtime"]], "Install OpenVINO\u2122 Runtime on Linux from an Archive File": [[477, "install-openvino-runtime-on-linux-from-an-archive-file"]], "Step 1: Download and Install the OpenVINO Core Components": [[477, "step-1-download-and-install-the-openvino-core-components"]], "Step 2: Configure the Environment": [[477, "step-2-configure-the-environment"], [478, "step-2-configure-the-environment"], [479, "step-2-configure-the-environment"]], "Uninstalling the Intel\u00ae Distribution of OpenVINO\u2122 Toolkit": [[477, "uninstalling-the-intel-distribution-of-openvino-toolkit"]], "Install OpenVINO\u2122 Runtime on macOS from an Archive File": [[478, "install-openvino-runtime-on-macos-from-an-archive-file"]], "Step 1: Install OpenVINO Core Components": [[478, "step-1-install-openvino-core-components"]], "Uninstalling Intel\u00ae Distribution of OpenVINO\u2122 Toolkit": [[478, "uninstalling-intel-distribution-of-openvino-toolkit"]], "Install OpenVINO\u2122 Runtime on Windows from an Archive File": [[479, "install-openvino-runtime-on-windows-from-an-archive-file"]], "Step 1: Download and Install OpenVINO Core Components": [[479, "step-1-download-and-install-openvino-core-components"]], "Install OpenVINO\u2122 Runtime via Homebrew": [[480, "install-openvino-runtime-via-homebrew"]], "Uninstalling OpenVINO": [[480, "uninstalling-openvino"], [488, "uninstalling-openvino"]], "Install OpenVINO\u2122 Runtime from Conan Package Manager": [[481, "install-openvino-runtime-from-conan-package-manager"]], "Installing OpenVINO Runtime with Conan Package Manager": [[481, "installing-openvino-runtime-with-conan-package-manager"]], "Install OpenVINO\u2122 Runtime from Conda Forge": [[482, "install-openvino-runtime-from-conda-forge"]], "Installing OpenVINO Runtime with Anaconda Package Manager": [[482, "installing-openvino-runtime-with-anaconda-package-manager"]], "Compiling with OpenVINO Runtime from Conda-Forge on Linux": [[482, "compiling-with-openvino-runtime-from-conda-forge-on-linux"]], "Enabling GPU device for inference": [[482, "enabling-gpu-device-for-inference"]], "Uninstalling OpenVINO\u2122 Runtime": [[482, "uninstalling-openvino-runtime"]], "Install Intel\u00ae Distribution of OpenVINO\u2122 toolkit from a Docker Image": [[483, "install-intel-distribution-of-openvino-toolkit-from-a-docker-image"]], "Install OpenVINO\u2122 Runtime on Linux": [[484, "install-openvino-runtime-on-linux"]], "Install OpenVINO\u2122 Runtime for macOS": [[485, "install-openvino-runtime-for-macos"]], "Install Intel\u00ae Distribution of OpenVINO\u2122 Toolkit from npm Registry": [[486, "install-intel-distribution-of-openvino-toolkit-from-npm-registry"]], "Installing OpenVINO Node.js": [[486, "installing-openvino-node-js"]], "Install Intel\u00ae Distribution of OpenVINO\u2122 Toolkit from PyPI Repository": [[487, "install-intel-distribution-of-openvino-toolkit-from-pypi-repository"]], "Step 5. Verify that the Package Is Installed": [[487, "step-5-verify-that-the-package-is-installed"]], "Install OpenVINO\u2122 Runtime via vcpkg": [[488, "install-openvino-runtime-via-vcpkg"]], "Install OpenVINO\u2122 Runtime on Windows": [[489, "install-openvino-runtime-on-windows"]], "Install OpenVINO\u2122 Runtime on Linux From YUM Repository": [[490, "install-openvino-runtime-on-linux-from-yum-repository"]], "Install OpenVINO Runtime": [[490, "install-openvino-runtime"], [490, "id1"], [491, "install-openvino-runtime"], [491, "id1"]], "Step 1: Set Up the Repository": [[490, "step-1-set-up-the-repository"], [491, "step-1-set-up-the-repository"]], "Step 2: Install OpenVINO Runtime Using the YUM Package Manager": [[490, "step-2-install-openvino-runtime-using-the-yum-package-manager"]], "Check for Installed Packages and Version": [[490, "check-for-installed-packages-and-version"], [491, "check-for-installed-packages-and-version"]], "Install OpenVINO\u2122 Runtime on Linux From ZYPPER Repository": [[491, "install-openvino-runtime-on-linux-from-zypper-repository"]], "Step 2: Install OpenVINO Runtime Using the ZYPPER Package Manager": [[491, "step-2-install-openvino-runtime-using-the-zypper-package-manager"]], "Troubleshooting Guide for OpenVINO\u2122 Installation & Configuration": [[492, "troubleshooting-guide-for-openvino-installation-configuration"]], "OpenVINO 2024.2": [[493, "openvino-2024-2"]], "Places to Begin": [[493, "places-to-begin"]], "Key Features": [[493, "key-features"]], "Learn OpenVINO": [[494, "learn-openvino"]], "Interactive Tutorials (Python)": [[495, "interactive-tutorials-python"]], "Installation of OpenVINO\u2122 Notebooks": [[496, "installation-of-openvino-notebooks"]], "Installation Guide": [[496, "installation-guide"]], "Installing prerequisites": [[496, "installing-prerequisites"]], "Installing notebooks": [[496, "installing-notebooks"]], "Run the Notebooks": [[496, "run-the-notebooks"]], "Launch a Single Notebook": [[496, "launch-a-single-notebook"]], "Launch All Notebooks": [[496, "launch-all-notebooks"]], "Manage the Notebooks": [[496, "manage-the-notebooks"]], "Shut Down Jupyter Kernel": [[496, "shut-down-jupyter-kernel"]], "Deactivate Virtual Environment": [[496, "deactivate-virtual-environment"]], "Reactivate Virtual Environment": [[496, "reactivate-virtual-environment"]], "Delete Virtual Environment": [[496, "delete-virtual-environment"]], "Remove openvino_env Kernel from Jupyter": [[496, "remove-openvino-env-kernel-from-jupyter"]], "Troubleshooting": [[496, "troubleshooting"]], "Large Language Model Inference Guide": [[497, "large-language-model-inference-guide"]], "Inference with Hugging Face and Optimum Intel": [[498, "inference-with-hugging-face-and-optimum-intel"]], "Loading a Hugging Face Model to Optimum Intel": [[498, "loading-a-hugging-face-model-to-optimum-intel"]], "Converting a Hugging Face Model to OpenVINO IR": [[498, "converting-a-hugging-face-model-to-openvino-ir"]], "Inference Example": [[498, "inference-example"]], "Enabling OpenVINO Runtime Optimizations": [[498, "enabling-openvino-runtime-optimizations"]], "Working with Models Tuned with LoRA": [[498, "working-with-models-tuned-with-lora"]], "Inference with Native OpenVINO": [[499, "inference-with-native-openvino"]], "Convert Hugging Face tokenizer and model to OpenVINO IR format": [[499, "convert-hugging-face-tokenizer-and-model-to-openvino-ir-format"]], "Full OpenVINO Text Generation Pipeline": [[499, "full-openvino-text-generation-pipeline"]], "1.      Import and Compile Models": [[499, "import-and-compile-models"]], "2.      Tokenize and Transform Input": [[499, "tokenize-and-transform-input"]], "3.      Generate Tokens": [[499, "generate-tokens"]], "4.      Decode and Display Output": [[499, "decode-and-display-output"]], "Supported Tokenizers": [[500, "supported-tokenizers"]], "Python Installation": [[500, "python-installation"]], "C++ Installation": [[500, "c-installation"]], "Tokenizers Usage": [[500, "tokenizers-usage"]], "1. Convert a Tokenizer to OpenVINO Intermediate Representation (IR)": [[500, "convert-a-tokenizer-to-openvino-intermediate-representation-ir"]], "2. Tokenize and Prepare Inputs": [[500, "tokenize-and-prepare-inputs"]], "3. Generate Text": [[500, "generate-text"]], "4. Detokenize Output": [[500, "detokenize-output"]], "OpenVINO\u2122 Samples": [[501, "openvino-samples"]], "Benchmark Tool": [[502, "benchmark-tool"]], "Basic Usage": [[502, "basic-usage"]], "Configuration Options": [[502, "configuration-options"]], "Performance hints: latency and throughput": [[502, "performance-hints-latency-and-throughput"]], "Latency": [[502, "latency"]], "Throughput": [[502, "throughput"]], "Device": [[502, "device"]], "Number of iterations": [[502, "number-of-iterations"]], "Inputs": [[502, "inputs"]], "Examples": [[502, "examples"], [504, "examples"], [515, "examples"], [519, "examples"], [520, "examples"], [544, "examples"]], "Advanced Usage": [[502, "advanced-usage"]], "Per-layer performance and logging": [[502, "per-layer-performance-and-logging"]], "All configuration options": [[502, "all-configuration-options"]], "More information on inputs": [[502, "more-information-on-inputs"]], "Examples of Running the Tool": [[502, "examples-of-running-the-tool"]], "Bert Benchmark Python Sample": [[503, "bert-benchmark-python-sample"]], "How It Works": [[503, "how-it-works"], [505, "how-it-works"], [506, "how-it-works"], [507, "how-it-works"], [508, "how-it-works"], [509, "how-it-works"], [510, "how-it-works"], [511, "how-it-works"], [512, "how-it-works"]], "Running": [[503, "running"], [505, "running"], [506, "running"], [507, "running"], [508, "running"], [509, "running"], [510, "running"], [511, "running"], [512, "running"]], "Sample Output": [[503, "sample-output"], [505, "sample-output"], [506, "sample-output"], [507, "sample-output"], [508, "sample-output"], [509, "sample-output"], [510, "sample-output"], [511, "sample-output"], [512, "sample-output"]], "Get Started with Samples": [[504, "get-started-with-samples"]], "Build the Sample Applications": [[504, "build-the-sample-applications"]], "Sample Application Setup": [[504, "sample-application-setup"]], "Download the Models": [[504, "download-the-models"]], "Convert the Model": [[504, "convert-the-model"]], "Download a Media to use": [[504, "download-a-media-to-use"]], "Run Inference on a Sample": [[504, "run-inference-on-a-sample"]], "Running Inference on CPU": [[504, "running-inference-on-cpu"]], "Other Samples": [[504, "other-samples"]], "Hello Classification Sample": [[505, "hello-classification-sample"]], "Example": [[505, "example"], [506, "example"], [508, "example"], [509, "example"], [510, "example"], [511, "example"], [512, "example"], [557, "example"], [561, "example"]], "Hello NV12 Input Classification Sample": [[506, "hello-nv12-input-classification-sample"]], "Hello Query Device Sample": [[507, "hello-query-device-sample"]], "Hello Reshape SSD Sample": [[508, "hello-reshape-ssd-sample"]], "Image Classification Async Sample": [[509, "image-classification-async-sample"]], "Model Creation Sample": [[510, "model-creation-sample"]], "Sync Benchmark Sample": [[511, "sync-benchmark-sample"]], "Throughput Benchmark Sample": [[512, "throughput-benchmark-sample"]], "OpenVINO Workflow": [[513, "openvino-workflow"]], "Deploy Locally": [[514, "deploy-locally"]], "Local Deployment Options": [[514, "local-deployment-options"]], "Granularity of Major Distribution Types": [[514, "granularity-of-major-distribution-types"]], "Libraries for Local Distribution": [[515, "libraries-for-local-distribution"]], "Library Requirements for C++ and C Languages": [[515, "library-requirements-for-c-and-c-languages"]], "Libraries for Pluggable Components": [[515, "libraries-for-pluggable-components"]], "Libraries for Compute Devices": [[515, "libraries-for-compute-devices"]], "Libraries for Execution Modes": [[515, "libraries-for-execution-modes"]], "Frontend Libraries for Reading Models": [[515, "frontend-libraries-for-reading-models"]], "OpenVINO Conditional Compilation for Optimal Binary Size": [[516, "openvino-conditional-compilation-for-optimal-binary-size"]], "Conditional Compilation for Multiple Models": [[516, "conditional-compilation-for-multiple-models"]], "Stage 1: collecting statistics information about code usage": [[516, "stage-1-collecting-statistics-information-about-code-usage"]], "Stage 2: build resulting OpenVINO package": [[516, "stage-2-build-resulting-openvino-package"], [516, "id1"]], "Conditional Compilation for Different Instruction Set Architectures(ISAs)": [[516, "conditional-compilation-for-different-instruction-set-architectures-isas"]], "Device-agnostic Conditional Compilation (POC)": [[516, "device-agnostic-conditional-compilation-poc"]], "How to Enable Conditional Compilation on Windows": [[516, "how-to-enable-conditional-compilation-on-windows"]], "Stage 1: Selective build analyzed stage": [[516, "stage-1-selective-build-analyzed-stage"]], "Model Optimization Guide": [[517, "model-optimization-guide"]], "Compressing Models During Training": [[518, "compressing-models-during-training"]], "NNCF Quick Start Examples": [[518, "nncf-quick-start-examples"]], "Installation": [[518, "installation"]], "Install from PyPI": [[518, "install-from-pypi"]], "Working with NNCF": [[518, "working-with-nncf"]], "Training-Time Compression Methods": [[518, "training-time-compression-methods"]], "Quantization": [[518, "quantization"]], "Filter pruning": [[518, "filter-pruning"]], "Experimental methods": [[518, "experimental-methods"]], "Recommended Workflow": [[518, "recommended-workflow"]], "Filter Pruning of Convolutional Models": [[519, "filter-pruning-of-convolutional-models"]], "Applying Filter Pruning with fine-tuning": [[519, "applying-filter-pruning-with-fine-tuning"]], "1. Import NNCF API": [[519, "import-nncf-api"], [520, "import-nncf-api"]], "2. Create NNCF configuration": [[519, "create-nncf-configuration"], [520, "create-nncf-configuration"]], "3. Apply optimization methods": [[519, "apply-optimization-methods"], [520, "apply-optimization-methods"]], "4. Fine-tune the model": [[519, "fine-tune-the-model"], [520, "fine-tune-the-model"]], "5. Multi-GPU distributed training": [[519, "multi-gpu-distributed-training"], [520, "multi-gpu-distributed-training"]], "6. Export quantized model": [[519, "export-quantized-model"], [520, "export-quantized-model"]], "7. (Optional) Save checkpoint": [[519, "optional-save-checkpoint"], [520, "optional-save-checkpoint"]], "8. (Optional) Restore from checkpoint": [[519, "optional-restore-from-checkpoint"], [520, "optional-restore-from-checkpoint"]], "Deploying pruned model": [[519, "deploying-pruned-model"]], "Quantization-aware Training (QAT)": [[520, "quantization-aware-training-qat"]], "Using NNCF QAT": [[520, "using-nncf-qat"]], "Deploying quantized model": [[520, "deploying-quantized-model"]], "Quantizing Models Post-training": [[521, "quantizing-models-post-training"]], "Basic Quantization Flow": [[522, "basic-quantization-flow"]], "Set up an Environment": [[522, "set-up-an-environment"]], "Prepare a Calibration Dataset": [[522, "prepare-a-calibration-dataset"]], "Quantize a Model": [[522, "quantize-a-model"]], "Tune quantization parameters": [[522, "tune-quantization-parameters"]], "Examples of how to apply NNCF post-training quantization:": [[522, "examples-of-how-to-apply-nncf-post-training-quantization"]], "Quantizing with Accuracy Control": [[523, "quantizing-with-accuracy-control"]], "Prepare model": [[523, "prepare-model"]], "Prepare calibration and validation datasets": [[523, "prepare-calibration-and-validation-datasets"]], "Prepare validation function": [[523, "prepare-validation-function"]], "Run quantization with accuracy control": [[523, "run-quantization-with-accuracy-control"]], "Examples of NNCF post-training quantization with control of accuracy metric:": [[523, "examples-of-nncf-post-training-quantization-with-control-of-accuracy-metric"]], "See also": [[523, "see-also"], [559, "see-also"]], "Weight Compression": [[524, "weight-compression"]], "Compress Model Weights": [[524, "compress-model-weights"]], "Exporting and Loading Compressed Models": [[524, "exporting-and-loading-compressed-models"]], "GPTQ Models": [[524, "gptq-models"]], "Compression Metrics Examples": [[524, "compression-metrics-examples"]], "Auto-tuning of Weight Compression Parameters": [[524, "auto-tuning-of-weight-compression-parameters"]], "Model Preparation": [[525, "model-preparation"]], "Model States": [[525, "model-states"]], "Convert a Model with Python: convert_model": [[525, "convert-a-model-with-python-convert-model"]], "Convert a Model in CLI: ovc": [[525, "convert-a-model-in-cli-ovc"]], "Conversion Parameters": [[526, "conversion-parameters"]], "Introduction to ONNX": [[527, "introduction-to-onnx"]], "External Data Files": [[527, "external-data-files"]], "Converting a PaddlePaddle Model": [[528, "converting-a-paddlepaddle-model"]], "Converting PaddlePaddle Model Files": [[528, "converting-paddlepaddle-model-files"]], "Converting PaddlePaddle Python Model": [[528, "converting-paddlepaddle-python-model"]], "Converting a PyTorch Model": [[529, "converting-a-pytorch-model"]], "Supported Input Parameter Types": [[529, "supported-input-parameter-types"]], "Non-tensor Data Types": [[529, "non-tensor-data-types"]], "Input and output names of the model": [[529, "input-and-output-names-of-the-model"]], "Support for torch.export": [[529, "support-for-torch-export"]], "Converting a TensorFlow Model": [[530, "converting-a-tensorflow-model"]], "Keras H5 Format": [[530, "keras-h5-format"]], "Converting TensorFlow Models from Memory Using Python API": [[530, "converting-tensorflow-models-from-memory-using-python-api"]], "Converting a TensorFlow Lite Model": [[531, "converting-a-tensorflow-lite-model"]], "Convert to OpenVINO IR": [[532, "convert-to-openvino-ir"]], "Convert Models": [[532, "convert-models"]], "IR Conversion Benefits": [[532, "ir-conversion-benefits"]], "Setting Input Shapes": [[533, "setting-input-shapes"]], "Running Inference with OpenVINO\u2122": [[534, "running-inference-with-openvino"]], "Changing Input Shapes": [[535, "changing-input-shapes"]], "The reshape method": [[535, "the-reshape-method"]], "The set_batch method": [[535, "the-set-batch-method"]], "Dynamic Shapes": [[536, "dynamic-shapes"], [542, "dynamic-shapes"], [543, "dynamic-shapes"]], "Applying Dynamic Shapes": [[536, "applying-dynamic-shapes"]], "Handling Dynamic Shapes": [[536, "handling-dynamic-shapes"]], "Configuring the Model": [[536, "configuring-the-model"]], "Undefined Dimensions \u201cOut Of the Box\u201d": [[536, "undefined-dimensions-out-of-the-box"]], "Dimension Bounds": [[536, "dimension-bounds"]], "Preparing and Inferencing Dynamic Data": [[536, "preparing-and-inferencing-dynamic-data"]], "Dynamic Shapes in Outputs": [[536, "dynamic-shapes-in-outputs"]], "When Dynamic Shapes API is Not Applicable": [[537, "when-dynamic-shapes-api-is-not-applicable"]], "Padding": [[537, "padding"]], "Multiple Pre-compiled Models": [[537, "multiple-pre-compiled-models"]], "Dimension Partitioning": [[537, "dimension-partitioning"]], "Inference Devices and Modes": [[538, "inference-devices-and-modes"]], "Enumerating Available Devices": [[538, "enumerating-available-devices"]], "Automatic Device Selection": [[539, "automatic-device-selection"]], "How AUTO Works": [[539, "how-auto-works"]], "Using AUTO": [[539, "using-auto"]], "Device Candidates and Priority": [[539, "device-candidates-and-priority"]], "Checking Available Devices": [[539, "checking-available-devices"]], "Excluding Devices from Device Candidate List": [[539, "excluding-devices-from-device-candidate-list"]], "Performance Hints for AUTO": [[539, "performance-hints-for-auto"]], "LATENCY": [[539, "latency"]], "THROUGHPUT": [[539, "throughput"]], "CUMULATIVE_THROUGHPUT": [[539, "id1"]], "Code Examples": [[539, "code-examples"]], "Disabling Auto-Batching for THROUGHPUT and CUMULATIVE_THROUGHPUT": [[539, "disabling-auto-batching-for-throughput-and-cumulative-throughput"]], "Configuring Model Priority": [[539, "configuring-model-priority"]], "Checking Target Runtime Devices": [[539, "checking-target-runtime-devices"]], "Configuring Individual Devices and Creating the Auto-Device plugin on Top": [[539, "configuring-individual-devices-and-creating-the-auto-device-plugin-on-top"]], "Using AUTO with OpenVINO Samples and Benchmark app": [[539, "using-auto-with-openvino-samples-and-benchmark-app"]], "Debugging Auto-Device Plugin": [[540, "debugging-auto-device-plugin"]], "Using Debug Log": [[540, "using-debug-log"]], "Instrumentation and Tracing Technology": [[540, "instrumentation-and-tracing-technology"]], "Analyze Code Performance on Linux": [[540, "analyze-code-performance-on-linux"]], "Automatic Batching": [[541, "automatic-batching"], [543, "automatic-batching"]], "How Automatic Batching Works": [[541, "how-automatic-batching-works"]], "Configuring Automatic Batching": [[541, "configuring-automatic-batching"]], "Automatic Batch Size Selection": [[541, "automatic-batch-size-selection"]], "Optimizing Performance by Limiting Batch Size": [[541, "optimizing-performance-by-limiting-batch-size"]], "Automatic Batching as an explicit device": [[541, "automatic-batching-as-an-explicit-device"]], "Automatic Batching as underlying device configured to other devices": [[541, "automatic-batching-as-underlying-device-configured-to-other-devices"]], "Other Performance Considerations": [[541, "other-performance-considerations"]], "Testing Performance with Benchmark_app": [[541, "testing-performance-with-benchmark-app"]], "CPU Device": [[542, "cpu-device"]], "Device Name": [[542, "device-name"]], "Supported Inference Data Types": [[542, "supported-inference-data-types"], [543, "supported-inference-data-types"]], "Quantized Data Types Specifics": [[542, "quantized-data-types-specifics"]], "Floating Point Data Types Specifics": [[542, "floating-point-data-types-specifics"]], "Inference Precision Hint": [[542, "inference-precision-hint"]], "Execution Mode Hint": [[542, "execution-mode-hint"]], "Supported Features": [[542, "supported-features"], [543, "supported-features"]], "Multi-device Execution": [[542, "multi-device-execution"], [543, "multi-device-execution"]], "Multi-stream Execution": [[542, "multi-stream-execution"], [543, "multi-stream-execution"]], "Preprocessing Acceleration": [[542, "preprocessing-acceleration"], [543, "preprocessing-acceleration"]], "Model Caching": [[542, "model-caching"], [543, "model-caching"], [547, "model-caching"]], "Extensibility": [[542, "extensibility"], [543, "extensibility"]], "Stateful Models": [[542, "stateful-models"]], "Supported Properties": [[542, "supported-properties"], [543, "supported-properties"]], "Read-write Properties": [[542, "read-write-properties"]], "Read-only properties": [[542, "read-only-properties"]], "External Dependencies": [[542, "external-dependencies"]], "Optimization guide": [[542, "optimization-guide"]], "Multi-Threading Optimization": [[542, "multi-threading-optimization"]], "Denormals Optimization": [[542, "denormals-optimization"]], "Sparse weights decompression (Intel\u00ae x86-64)": [[542, "sparse-weights-decompression-intel-x86-64"]], "GPU Device": [[543, "gpu-device"]], "Device Naming Convention": [[543, "device-naming-convention"]], "Bounded dynamic batch": [[543, "bounded-dynamic-batch"]], "Notes for performance and memory consumption in dynamic shapes": [[543, "notes-for-performance-and-memory-consumption-in-dynamic-shapes"]], "Recommendations for performance improvement": [[543, "recommendations-for-performance-improvement"]], "GPU Context and Memory Sharing via RemoteTensor API": [[543, "gpu-context-and-memory-sharing-via-remotetensor-api"]], "Read-write properties": [[543, "read-write-properties"]], "Read-only Properties": [[543, "read-only-properties"]], "GPU Performance Checklist: Summary": [[543, "gpu-performance-checklist-summary"]], "Remote Tensor API of GPU Plugin": [[544, "remote-tensor-api-of-gpu-plugin"]], "Context Sharing Between Application and GPU Plugin": [[544, "context-sharing-between-application-and-gpu-plugin"]], "Creation of RemoteContext from Native Handle": [[544, "creation-of-remotecontext-from-native-handle"]], "Getting RemoteContext from the Plugin": [[544, "getting-remotecontext-from-the-plugin"]], "Memory Sharing Between Application and GPU Plugin": [[544, "memory-sharing-between-application-and-gpu-plugin"]], "Direct NV12 Video Surface Input": [[544, "direct-nv12-video-surface-input"]], "Context & Queue Sharing": [[544, "context-queue-sharing"]], "Low-Level Methods for RemoteContext and RemoteTensor Creation": [[544, "low-level-methods-for-remotecontext-and-remotetensor-creation"]], "Heterogeneous execution": [[545, "heterogeneous-execution"]], "Defining and Configuring the Hetero Device": [[545, "defining-and-configuring-the-hetero-device"]], "Manual and Automatic modes for assigning affinities": [[545, "manual-and-automatic-modes-for-assigning-affinities"]], "The Manual Mode": [[545, "the-manual-mode"]], "The Automatic Mode": [[545, "the-automatic-mode"]], "Using Manual and Automatic Modes in Combination": [[545, "using-manual-and-automatic-modes-in-combination"]], "Configure fallback devices": [[545, "configure-fallback-devices"]], "Handling of Difficult Topologies": [[545, "handling-of-difficult-topologies"]], "Analyzing Performance of Heterogeneous Execution": [[545, "analyzing-performance-of-heterogeneous-execution"]], "Sample Usage": [[545, "sample-usage"]], "Multi-device execution": [[546, "multi-device-execution"]], "How MULTI Works": [[546, "how-multi-works"]], "Using the Multi-Device Mode": [[546, "using-the-multi-device-mode"]], "Configuring Individual Devices and Creating the Multi-Device On Top": [[546, "configuring-individual-devices-and-creating-the-multi-device-on-top"]], "Querying the Optimal Number of Inference Requests": [[546, "querying-the-optimal-number-of-inference-requests"]], "Using the Multi-Device with OpenVINO Samples and Benchmarking Performance": [[546, "using-the-multi-device-with-openvino-samples-and-benchmarking-performance"]], "Performance Considerations for the Multi-Device Execution": [[546, "performance-considerations-for-the-multi-device-execution"]], "NPU Device": [[547, "npu-device"]], "UMD Dynamic Model Caching": [[547, "umd-dynamic-model-caching"]], "OpenVINO Model Caching": [[547, "openvino-model-caching"]], "Supported Features and properties": [[547, "supported-features-and-properties"]], "Query Device Properties - Configuration": [[548, "query-device-properties-configuration"]], "Get a Set of Available Devices": [[548, "get-a-set-of-available-devices"]], "Working with Properties in Your Code": [[548, "working-with-properties-in-your-code"]], "Working with Properties via Core": [[548, "working-with-properties-via-core"]], "Getting Device Properties": [[548, "getting-device-properties"]], "Configure a Work with a Model": [[548, "configure-a-work-with-a-model"]], "Setting Properties Globally": [[548, "setting-properties-globally"]], "Properties on CompiledModel Level": [[548, "properties-on-compiledmodel-level"]], "Getting Property": [[548, "getting-property"]], "Setting Properties for Compiled Model": [[548, "setting-properties-for-compiled-model"]], "Integrate OpenVINO\u2122 with Your Application": [[549, "integrate-openvino-with-your-application"]], "Step 1. Create OpenVINO Runtime Core": [[549, "step-1-create-openvino-runtime-core"]], "Step 2. Compile the Model": [[549, "step-2-compile-the-model"]], "Step 3. Create an Inference Request": [[549, "step-3-create-an-inference-request"]], "Step 4. Set Inputs": [[549, "step-4-set-inputs"]], "Step 5. Start Inference": [[549, "step-5-start-inference"]], "Step 6. Process the Inference Results": [[549, "step-6-process-the-inference-results"]], "Step 7. Release the allocated objects (only for C)": [[549, "step-7-release-the-allocated-objects-only-for-c"]], "Step 8. Link and Build Your Application with OpenVINO\u2122 Runtime (example)": [[549, "step-8-link-and-build-your-application-with-openvino-runtime-example"]], "Create Structure for project:": [[549, "create-structure-for-project"]], "Create Cmake Script": [[549, "create-cmake-script"]], "Build Project": [[549, "build-project"]], "OpenVINO\u2122 Inference Request": [[550, "openvino-inference-request"]], "Creating Infer Request": [[550, "creating-infer-request"]], "Run Inference": [[550, "run-inference"]], "Synchronous Mode": [[550, "synchronous-mode"]], "Asynchronous Mode": [[550, "asynchronous-mode"]], "Working with Input and Output tensors": [[550, "working-with-input-and-output-tensors"]], "Examples of Infer Request Usages": [[550, "examples-of-infer-request-usages"]], "Cascade of Models": [[550, "cascade-of-models"]], "Using of ROI Tensors": [[550, "using-of-roi-tensors"]], "Using Remote Tensors": [[550, "using-remote-tensors"]], "Model Representation in OpenVINO\u2122 Runtime": [[551, "model-representation-in-openvino-runtime"]], "How OpenVINO Runtime Works with Models": [[551, "how-openvino-runtime-works-with-models"]], "Representation of Shapes": [[551, "representation-of-shapes"]], "Representation of Operations": [[551, "representation-of-operations"]], "Representation of Operation Sets": [[551, "representation-of-operation-sets"]], "Building a Model in OpenVINO\u2122 Runtime": [[551, "building-a-model-in-openvino-runtime"]], "Model Debugging Capabilities": [[551, "model-debugging-capabilities"]], "OpenVINO\u2122 Runtime Python API Advanced Inference": [[552, "openvino-runtime-python-api-advanced-inference"]], "Direct Inference with CompiledModel": [[552, "direct-inference-with-compiledmodel"]], "Shared Memory on Inputs and Outputs": [[552, "shared-memory-on-inputs-and-outputs"]], "Hiding Latency with Asynchronous Calls": [[552, "hiding-latency-with-asynchronous-calls"]], "\u201cPostponed Return\u201d with Asynchronous Calls": [[552, "postponed-return-with-asynchronous-calls"]], "OpenVINO\u2122 Python API Exclusives": [[553, "openvino-python-api-exclusives"]], "Easier Model Compilation": [[553, "easier-model-compilation"]], "Model/CompiledModel Inputs and Outputs": [[553, "model-compiledmodel-inputs-and-outputs"]], "Working with Tensor": [[553, "working-with-tensor"]], "Shared Memory Mode": [[553, "shared-memory-mode"]], "Running Inference": [[553, "running-inference"]], "Synchronous Mode - Extended": [[553, "synchronous-mode-extended"]], "Inference Results - OVDict": [[553, "inference-results-ovdict"]], "AsyncInferQueue": [[553, "asyncinferqueue"]], "Acquiring Results from Requests": [[553, "acquiring-results-from-requests"]], "Setting Callbacks": [[553, "setting-callbacks"]], "Working with u1, u4 and i4 Element Types": [[553, "working-with-u1-u4-and-i4-element-types"]], "Release of GIL": [[553, "release-of-gil"]], "List of Functions that Release the GIL": [[553, "list-of-functions-that-release-the-gil"]], "Optimize Inference": [[554, "optimize-inference"]], "Performance-Portable Inference": [[554, "performance-portable-inference"]], "General Optimizations": [[555, "general-optimizations"]], "Inputs Pre-Processing with OpenVINO": [[555, "inputs-pre-processing-with-openvino"]], "Prefer OpenVINO Async API": [[555, "prefer-openvino-async-api"]], "Notes on Callbacks": [[555, "notes-on-callbacks"]], "The \u201cget_tensor\u201d Idiom": [[555, "the-get-tensor-idiom"]], "High-level Performance Hints": [[556, "high-level-performance-hints"]], "Performance Hints: Latency and Throughput": [[556, "performance-hints-latency-and-throughput"]], "Performance Hints: How It Works": [[556, "performance-hints-how-it-works"]], "Using the Performance Hints: Basic API": [[556, "using-the-performance-hints-basic-api"]], "Additional (Optional) Hints from the App": [[556, "additional-optional-hints-from-the-app"]], "Optimal Number of Inference Requests": [[556, "optimal-number-of-inference-requests"]], "Prefer Async API": [[556, "prefer-async-api"]], "Combining the Hints and Individual Low-Level Settings": [[556, "combining-the-hints-and-individual-low-level-settings"]], "Testing Performance of the Hints with the Benchmark_App": [[556, "testing-performance-of-the-hints-with-the-benchmark-app"]], "Optimize Preprocessing": [[557, "optimize-preprocessing"]], "Preprocessing API": [[557, "preprocessing-api"]], "PrePostProcessor Object": [[557, "prepostprocessor-object"]], "Declare User\u2019s Data Format": [[557, "declare-user-s-data-format"]], "Declaring Model Layout": [[557, "declaring-model-layout"]], "Preprocessing Steps": [[557, "preprocessing-steps"]], "Integrating Steps into a Model": [[557, "integrating-steps-into-a-model"]], "Use Case - Integrate and Save Preprocessing Steps Into IR": [[558, "use-case-integrate-and-save-preprocessing-steps-into-ir"]], "Code example - Saving Model with Preprocessing to OpenVINO IR": [[558, "code-example-saving-model-with-preprocessing-to-openvino-ir"]], "Application Code - Load Model to Target Device": [[558, "application-code-load-model-to-target-device"]], "Layout API Overview": [[559, "layout-api-overview"]], "Syntax of Layout": [[559, "syntax-of-layout"]], "Short Syntax": [[559, "short-syntax"]], "Advanced Syntax": [[559, "advanced-syntax"]], "Partially Defined Layout": [[559, "partially-defined-layout"]], "Dynamic Layout": [[559, "dynamic-layout"]], "Predefined Names": [[559, "predefined-names"]], "Equality": [[559, "equality"]], "Dump Layout": [[559, "dump-layout"]], "Get layout from Model Input/Output": [[559, "get-layout-from-model-input-output"]], "Preprocessing API - details": [[560, "preprocessing-api-details"]], "Pre-processing Capabilities": [[560, "pre-processing-capabilities"]], "Addressing Particular Input/Output": [[560, "addressing-particular-input-output"]], "Supported Pre-processing Operations": [[560, "supported-pre-processing-operations"]], "Mean/Scale Normalization": [[560, "mean-scale-normalization"]], "Converting Precision": [[560, "converting-precision"]], "Converting layout (transposing)": [[560, "converting-layout-transposing"]], "Resizing Image": [[560, "resizing-image"]], "Color Conversion": [[560, "color-conversion"]], "Color Conversion - NV12/I420": [[560, "color-conversion-nv12-i420"]], "Custom Operations": [[560, "custom-operations"]], "Post-processing": [[560, "post-processing"]], "Torchvision preprocessing converter": [[561, "torchvision-preprocessing-converter"]], "Optimizing for Latency": [[562, "optimizing-for-latency"]], "Model Caching Overview": [[563, "model-caching-overview"]], "Set \u201ccache_dir\u201d config option to enable model caching": [[563, "set-cache-dir-config-option-to-enable-model-caching"]], "Make it even faster: use compile_model(modelPath)": [[563, "make-it-even-faster-use-compile-model-modelpath"]], "Advanced Examples": [[563, "advanced-examples"]], "Further Low-Level Implementation Details": [[564, "further-low-level-implementation-details"]], "Throughput on the CPU: Internals": [[564, "throughput-on-the-cpu-internals"]], "Automatic Batching Internals": [[564, "automatic-batching-internals"]], "Optimizing memory usage": [[565, "optimizing-memory-usage"]], "Optimizing for Throughput": [[566, "optimizing-for-throughput"]], "Basic and Advanced Ways of Leveraging Throughput": [[566, "basic-and-advanced-ways-of-leveraging-throughput"]], "Throughput-Oriented Application Design": [[566, "throughput-oriented-application-design"]], "Multi-Device Execution": [[566, "multi-device-execution"]], "Advanced Throughput Options: Streams and Batching": [[567, "advanced-throughput-options-streams-and-batching"]], "OpenVINO Streams": [[567, "openvino-streams"]], "Batching": [[567, "batching"]], "Choosing the Number of Streams and/or Batch Size": [[567, "choosing-the-number-of-streams-and-or-batch-size"]], "Number of Streams Considerations": [[567, "number-of-streams-considerations"]], "Batch Size Considerations": [[567, "batch-size-considerations"]], "A Few Device-specific Details": [[567, "a-few-device-specific-details"]], "Precision Control": [[568, "precision-control"]], "Execution Mode": [[568, "execution-mode"]], "Inference Precision": [[568, "inference-precision"]], "Stateful models and State API": [[569, "stateful-models-and-state-api"]], "OpenVINO Stateful Model Representation": [[569, "openvino-stateful-model-representation"]], "Running Inference of Stateful Models": [[569, "running-inference-of-stateful-models"]], "Stateful Model Application Example": [[569, "stateful-model-application-example"]], "Obtaining a Stateful OpenVINO Model": [[570, "obtaining-a-stateful-openvino-model"]], "MakeStateful Transformation": [[570, "makestateful-transformation"]], "LowLatency2 Transformation": [[570, "lowlatency2-transformation"]], "Applying LowLatency2 Transformation": [[570, "applying-lowlatency2-transformation"]], "Obtaining TensorIterator/Loop Operations using Model Optimizer": [[570, "obtaining-tensoriterator-loop-operations-using-model-optimizer"]], "Creating a Model via OpenVINO API": [[570, "creating-a-model-via-openvino-api"]], "String Tensors": [[571, "string-tensors"]], "Representation": [[571, "representation"]], "Create a String Tensor": [[571, "create-a-string-tensor"]], "Accessing Elements": [[571, "accessing-elements"]], "PyTorch Deployment via \u201ctorch.compile\u201d": [[572, "pytorch-deployment-via-torch-compile"]], "How to Use": [[572, "how-to-use"]], "Options": [[572, "options"]], "Windows support": [[572, "windows-support"]], "Support for Automatic1111 Stable Diffusion WebUI": [[572, "support-for-automatic1111-stable-diffusion-webui"]]}, "indexentries": {"module": [[17, "module-openvino"], [26, "module-openvino.properties.intel_gpu.hint"], [31, "module-openvino.runtime.op.util"], [37, "module-openvino.runtime.opset14"], [46, "module-openvino.runtime.passes"]], "openvino": [[17, "module-openvino"]], "openvino.properties.intel_gpu.hint": [[26, "module-openvino.properties.intel_gpu.hint"]], "openvino.runtime.op.util": [[31, "module-openvino.runtime.op.util"]], "openvino.runtime.opset14": [[37, "module-openvino.runtime.opset14"]], "openvino.runtime.passes": [[46, "module-openvino.runtime.passes"]]}})